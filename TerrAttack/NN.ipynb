{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import pickle\n",
    "from time import time\n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#每次可以输出多个变量\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14, 6\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#中文字体\n",
    "import matplotlib\n",
    "matplotlib.use('qt4agg')\n",
    "#指定默认字体\n",
    "matplotlib.rcParams['font.sans-serif'] = ['SimHei']\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "#解决负号'-'显示为方块的问题\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import xavier_initializer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import math\n",
    "import logging\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "from scipy.sparse.lil import lil_matrix\n",
    "from scipy.sparse import hstack, vstack\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "#每次可以输出多个变量\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(inp, hidden_dims):\n",
    "    x = tf.layers.Dense(hidden_dims[0], kernel_initializer=tf.keras.initializers.he_normal(), dtype=tf.float32, activation=tf.nn.relu)(inp)\n",
    "    x = tf.layers.BatchNormalization(dtype=tf.float32)(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    for i, dim in enumerate(hidden_dims):\n",
    "        if i > 0:\n",
    "            x = tf.layers.Dense(dim, kernel_initializer=tf.keras.initializers.he_normal(), dtype=tf.float32, activation=tf.nn.relu)(x)\n",
    "            x = tf.layers.BatchNormalization(dtype=tf.float32)(x)\n",
    "            x = tf.nn.relu(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, learning_rate, embedding_size, dnn_layers, att_layer, cross_layer_num, conti_fea_cnt,\n",
    "                 cate_embedding_uni_cnt_list, cate_embedding_w_list=None, fm_embedding_w=None, no_nan_w=None,\n",
    "                 nan_w=None, fm_drop_outs=[1, 1]):\n",
    "        self.lr = learning_rate\n",
    "        self.conti_fea_cnt = conti_fea_cnt\n",
    "        self.embedding_size = embedding_size\n",
    "        self.fm_drop_outs = fm_drop_outs\n",
    "        self.dnn_layers = dnn_layers\n",
    "        self.att_layer = att_layer\n",
    "        self.cross_layer_num = cross_layer_num\n",
    "        # cate_embedding_uni_cnt_list离散特征计数\n",
    "        self.cate_embedding_uni_cnt_list = cate_embedding_uni_cnt_list\n",
    "        self.cate_embedding_w_list = cate_embedding_w_list\n",
    "\n",
    "        self.fm_embedding_w = fm_embedding_w\n",
    "        self.no_nan_w = no_nan_w\n",
    "        self.nan_w = nan_w\n",
    "\n",
    "        self.build()\n",
    "\n",
    "    def build(self):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            config = tf.ConfigProto()\n",
    "            config.gpu_options.allow_growth = True\n",
    "            self.sess = tf.Session(config=config)\n",
    "\n",
    "            self.input_vecs = []\n",
    "\n",
    "            self.conti_vec = tf.placeholder(tf.float32, shape=[None, self.conti_fea_cnt], name='conti_vec')\n",
    "            self.cate_indexs = tf.placeholder(tf.int16, shape=[None, sum(self.cate_embedding_uni_cnt_list)],\n",
    "                                              name='cate_indexs')\n",
    "            self.label = tf.placeholder(dtype=tf.int8, shape=[None, 1], name='label')\n",
    "\n",
    "            self.cate_embeddings = []\n",
    "            self.fm_fea_size = 0\n",
    "\n",
    "            # 第一层embedding：降维\n",
    "            cate_offset = 0\n",
    "            for cate_idx, uni_cnt in enumerate(self.cate_embedding_uni_cnt_list):\n",
    "                w = self.cate_embedding_w_list[cate_idx] if self.cate_embedding_w_list else tf.keras.initializers.he_normal()\n",
    "                embedding_k = uni_cnt if int(2 * np.power(uni_cnt, 1 / 4)) > uni_cnt else int(\n",
    "                    2 * np.power(uni_cnt, 1 / 4))\n",
    "                self.fm_fea_size += embedding_k\n",
    "                # embedding矩阵\n",
    "                self.cate_embeddings.append(\n",
    "                    tf.get_variable('cate_%d_embedding' % cate_idx, shape=[uni_cnt, embedding_k], dtype=tf.float32,\n",
    "                                    initializer=w))\n",
    "\n",
    "                crt_vec_index = self.cate_indexs[:, cate_offset:cate_offset + uni_cnt]  # None * uni_cnt\n",
    "                cate_offset += uni_cnt\n",
    "                crt_vec_index = tf.Print(crt_vec_index, [crt_vec_index], message='Debug:', summarize=50)\n",
    "\n",
    "                crt_vec = tf.nn.embedding_lookup(self.cate_embeddings[cate_idx],\n",
    "                                                 [i for i in range(uni_cnt)])  # uni_cnt * K\n",
    "                # 等于1的加起来，求平均（embedding相当于多行相加，multi-hot要除1的个数保证一致）\n",
    "                crt_vec = tf.matmul(tf.cast(crt_vec_index, tf.float32), crt_vec)  # None * K\n",
    "                one_cnt = tf.cast(tf.reduce_sum(crt_vec_index, axis=1, keep_dims=True), dtype=tf.float32)  # None * 1\n",
    "                crt_vec = tf.div(crt_vec, one_cnt)  # None * K\n",
    "                self.input_vecs.append(crt_vec)\n",
    "\n",
    "            mv_conti_vec = self.conti_vec\n",
    "\n",
    "            self.input_vecs.append(mv_conti_vec)\n",
    "            self.fm_fea_size += self.conti_fea_cnt\n",
    "\n",
    "            # 准备输入-----------------------------------------------------------------------------------------------------\n",
    "#             print(self.fm_fea_size)\n",
    "            fm_fea = tf.concat(self.input_vecs, axis=-1)\n",
    "\n",
    "            self.feat_index = [i for i in range(self.fm_fea_size)]\n",
    "            if self.fm_embedding_w is not None:\n",
    "                self.fea_embedding = tf.Variable(self.fm_embedding_w, name='fea_embedding', dtype=tf.float32)\n",
    "            else:\n",
    "                self.fea_embedding = tf.get_variable('fea_embedding', shape=[self.fm_fea_size, self.embedding_size],\n",
    "                                                     initializer=tf.keras.initializers.he_normal(), dtype=tf.float32)\n",
    "            # FM一阶部分权重\n",
    "            self.feature_bias = tf.get_variable('fea_bias', shape=[self.fm_fea_size, 1],\n",
    "                                                initializer=tf.keras.initializers.he_normal(), dtype=tf.float32)\n",
    "            # attention部分权重\n",
    "            self.attention_h = tf.Variable(np.random.normal(loc=0, scale=1, size=[self.att_layer]), \n",
    "                                           dtype=np.float32, name='attention_h')\n",
    "            self.attention_p = tf.Variable(np.ones([self.embedding_size, 1], dtype=np.float32), \n",
    "                                           dtype=tf.float32, name='attention_p')\n",
    "            # cross部分权重\n",
    "            self.cross_w = [tf.get_variable(name='cross_weight_%d' % i, shape=[self.fm_fea_size, 1],\n",
    "                                            initializer=tf.keras.initializers.he_normal(), dtype=tf.float32) for i in\n",
    "                            range(self.cross_layer_num)]\n",
    "            self.cross_b = [tf.get_variable(name='cross_bias_%d' % i, shape=[self.fm_fea_size, 1],\n",
    "                                            initializer=tf.keras.initializers.he_normal(), dtype=tf.float32) for i in\n",
    "                            range(self.cross_layer_num)]\n",
    "\n",
    "            # 构造输入\n",
    "            # 第二层embedding：潜在隐变量\n",
    "            embeddings = tf.nn.embedding_lookup(self.fea_embedding, self.feat_index)  # None * F * K\n",
    "            feat_value = tf.reshape(fm_fea, shape=[-1, self.fm_fea_size, 1])\n",
    "            embeddings = tf.multiply(embeddings, feat_value)  # None * F * K\n",
    "#             print(embeddings)\n",
    "#             embeddings = tf.Print(embeddings, [embeddings], message='Debug:', summarize=30)\n",
    "\n",
    "            # 搭建网络-----------------------------------------------------------------------------------------------------\n",
    "            # DNN部分\n",
    "            with tf.variable_scope('Deep-part'):\n",
    "                y_deep = tf.reshape(embeddings, shape=[-1, self.fm_fea_size * self.embedding_size])  # None*(F*K)\n",
    "                y_deep = MLP(y_deep, self.dnn_layers)\n",
    "\n",
    "            last_input = tf.concat([y_deep], axis=-1) # DNN\n",
    "\n",
    "            self.y_pre = tf.layers.Dense(5, activation=tf.nn.softmax, kernel_initializer=tf.keras.initializers.he_normal())(\n",
    "            last_input) # 多分类\n",
    "\n",
    "            # 损失函数(二分类交叉熵等同于logloss)\n",
    "            self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=tf.one_hot(tf.cast(self.label, tf.int32), depth=5, on_value=1, off_value=None), logits=self.y_pre)) # 多分类\n",
    "\n",
    "            # 优化方法\n",
    "            self.opt = tf.train.AdamOptimizer(self.lr).minimize(self.loss)\n",
    "            self.saver = tf.train.Saver()\n",
    "            \n",
    "    def save_model(self, model_path):\n",
    "        self.saver.save(self.sess, model_path)\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        self.saver.restore(self.sess, model_path)\n",
    "\n",
    "    def shuffle_csr_and_list(self, my_array, rng_state):\n",
    "        np.random.set_state(rng_state)\n",
    "        if type(my_array) == csr_matrix:\n",
    "            index = np.arange(np.shape(my_array)[0])\n",
    "            np.random.shuffle(index)\n",
    "            print('shuffle csr_matrix ' + str(my_array.shape))\n",
    "            return my_array[index, :]\n",
    "        else:\n",
    "            np.random.shuffle(my_array)\n",
    "            return my_array\n",
    "\n",
    "    def shuffle(self, cate_feas, conti_feas, labels):\n",
    "        rng_state = np.random.get_state()\n",
    "        cate_feas = self.shuffle_csr_and_list(cate_feas, rng_state)\n",
    "        conti_feas = self.shuffle_csr_and_list(conti_feas, rng_state)\n",
    "        labels = self.shuffle_csr_and_list(labels, rng_state)\n",
    "        return cate_feas, conti_feas, labels\n",
    "\n",
    "    def get_feed_dict(self, cate_feas, conti_feas, labels=None):\n",
    "        feed_dict = {\n",
    "            self.conti_vec: conti_feas,\n",
    "            self.cate_indexs: cate_feas.todense(),\n",
    "        }\n",
    "        if labels is not None:\n",
    "            feed_dict[self.label] = labels\n",
    "        return feed_dict\n",
    "\n",
    "    def gene_data(self, cate_feas, conti_feas, labels, bs, shuffle=False):\n",
    "        if shuffle:\n",
    "            cate_feas, conti_feas, labels = self.shuffle(cate_feas, conti_feas, labels)\n",
    "        bm = math.ceil(cate_feas.shape[0] / bs)\n",
    "        for j in range(bm):\n",
    "            a = cate_feas[j * bs:(j + 1) * bs]\n",
    "            b = conti_feas[j * bs:(j + 1) * bs]\n",
    "            c = labels[j * bs:(j + 1) * bs]\n",
    "            yield a, b, c\n",
    "\n",
    "    def gene_balance_data(self, cate_feas, conti_feas, labels, bs, shuffle=False):\n",
    "        pos_flag = np.array([l[0] == 1 for l in labels])\n",
    "        pos_indexing, neg_indexing = np.arange(len(labels))[pos_flag], np.arange(len(labels))[~pos_flag]\n",
    "        np.random.shuffle(neg_indexing)\n",
    "\n",
    "        bm = math.ceil(sum(~pos_flag) / bs)\n",
    "        for j in range(bm):\n",
    "            need_cnt = int(bs / 2)\n",
    "            crt_indexing = np.random.choice(pos_indexing, need_cnt).tolist() + neg_indexing[\n",
    "                                                                               j * need_cnt:(j + 1) * need_cnt].tolist()\n",
    "\n",
    "            a = cate_feas[crt_indexing, :]\n",
    "            b = np.take(conti_feas, crt_indexing, axis=0)\n",
    "            c = np.take(labels, crt_indexing, axis=0)\n",
    "            yield a, b, c\n",
    "\n",
    "    def fit(self, model_path, batch_size, epoch, cate_feas, conti_feas, labels, v_cate_feas, v_conti_feas, v_labels,\n",
    "            es=5):\n",
    "        print('start training ---------------------------------------------------')\n",
    "        logging.info('start train')\n",
    "        with self.graph.as_default():\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            best_auc = 0.0 # 二分类/多分类\n",
    "            no_num = 0\n",
    "            writer = tf.summary.FileWriter('./logs', self.sess.graph)\n",
    "            for i in range(epoch):\n",
    "                t1 = time()\n",
    "                epoch_losses = []\n",
    "                for cate_feas_batch, conti_feas_batch, labels_batch in self.gene_data(cate_feas, conti_feas,\n",
    "                                                                                      labels, batch_size,\n",
    "                                                                                      shuffle=False):\n",
    "                    feed = self.get_feed_dict(cate_feas_batch, conti_feas_batch, labels_batch)\n",
    "                    loss, _ = self.sess.run([self.loss, self.opt], feed_dict=feed)\n",
    "                    epoch_losses.append(loss)\n",
    "                # 多分类\n",
    "                v_auc = self.eval(batch_size, v_cate_feas, v_conti_feas, v_labels)\n",
    "                logging.info('epoch: %s---valid accuracy: %.4f'\n",
    "                             % ((i + 1), v_auc))\n",
    "                print('epoch: %s---valid accuracy: %.4f [%.1f s]'\n",
    "                      % ((i + 1), v_auc, time() - t1))\n",
    "                if v_auc > best_auc:\n",
    "                    no_num = 0\n",
    "                    self.lr = self.lr * 0.9\n",
    "                    self.save_model(model_path)\n",
    "                    logging.info('---------- accuracy from %.4f to %.4f, saving model' % (best_auc, v_auc))\n",
    "                    print('---------- accuracy from %.4f to %.4f, saving model' % (best_auc, v_auc))\n",
    "                    best_auc = v_auc\n",
    "                else:\n",
    "                    no_num += 1\n",
    "                    self.lr = self.lr / 2\n",
    "                    if no_num >= es:\n",
    "                        break\n",
    "\n",
    "    def eval(self, batch_size, cate_feas, conti_feas, labels):\n",
    "        with self.graph.as_default():\n",
    "            y_pre = []\n",
    "            for cate_feas_batch, conti_feas_batch, label_batch in self.gene_data(cate_feas, conti_feas, labels,\n",
    "                                                                                 batch_size, shuffle=False):\n",
    "                feed = self.get_feed_dict(cate_feas_batch, conti_feas_batch, label_batch)\n",
    "                y_ = self.sess.run([self.y_pre], feed_dict=feed)[0]\n",
    "                y_pre += y_.tolist()\n",
    "            y_pre = np.array(y_pre)\n",
    "            # 多分类\n",
    "            y_pre = np.reshape(y_pre, [y_pre.shape[0], 5])\n",
    "            labels = self.sess.run(tf.reduce_sum(tf.one_hot(tf.cast(labels, tf.int32), 5), axis=1))\n",
    "#             print(y_pre[:5], labels[:5])\n",
    "            print(self.sess.run([tf.argmax(y_pre, 1)[:5], tf.argmax(labels, 1)[:5]]))\n",
    "            correctPred = tf.equal(tf.argmax(y_pre, 1), tf.argmax(labels, 1))\n",
    "            acc = self.sess.run(tf.reduce_mean(tf.cast(correctPred, tf.float32)))\n",
    "            return acc\n",
    "            \n",
    "\n",
    "    def predict(self, cate_feas, conti_feas, batch_size):\n",
    "        def gd(cate_feas, conti_feas, bs):\n",
    "            bm = math.ceil(len(conti_feas) / bs)\n",
    "            for j in range(bm):\n",
    "                a = cate_feas[j * bs: (j + 1) * bs]\n",
    "                b = conti_feas[j * bs: (j + 1) * bs]\n",
    "                yield a, b\n",
    "\n",
    "        with self.graph.as_default():\n",
    "            y_pre = []\n",
    "            for cate_feas_batch, conti_feas_batch in gd(cate_feas, conti_feas, batch_size):\n",
    "                feed = self.get_feed_dict(cate_feas_batch, conti_feas_batch)\n",
    "                y_ = self.sess.run([self.y_pre], feed_dict=feed)[0]\n",
    "                y_pre += y_.tolist()\n",
    "            y_pre = np.array(y_pre)\n",
    "            y_pre = np.reshape(y_pre, (y_pre.shape[0],))\n",
    "            return y_pre\n",
    "\n",
    "    def embedding_weights(self):\n",
    "        cate_embeddings, fea_embedding = self.sess.run([self.cate_embeddings, self.fea_embedding])\n",
    "        return cate_embeddings, fea_embedding\n",
    "\n",
    "    def miss_value_layer_w(self):\n",
    "        nan_embeddings, no_nan_embedding = self.sess.run([self.nan_w, self.no_nan_w])\n",
    "        return nan_embeddings, no_nan_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114183, 2734)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./feature/df_preprocess.csv', encoding='gbk')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = ['eventid', 'weapdetail']\n",
    "many_onehot_col = ['corp1', 'target1', 'gname', 'provstate', 'city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2093"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_col = [i for i in df.columns if 'w2v' in i and 'gname' not in i]\n",
    "len(w2v_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[w2v_col]\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114183, 48)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('./feature/df_fillna.csv', encoding='gbk')\n",
    "df2.shape\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df2], axis=1)\n",
    "\n",
    "del df2\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列分类\n",
    "zeroone_col = ['extended', 'crit1', 'crit2', 'crit3', 'success', 'suicide', 'weapdetail', 'individual']\n",
    "onehot_col = ['specificity', 'country', 'region', 'vicinity', 'doubtterr', 'multiple',\n",
    "              'attacktype1', 'targtype1', 'targsubtype1', 'guncertain1', 'weaptype1', 'weapsubtype1', 'property', 'propextent', \n",
    "              'ishostkid', 'dbsource', 'natlty1', 'INT_LOG', 'INT_MISC', 'INT_ANY', 'INT_IDEO']\n",
    "many_onehot_col = ['corp1', 'target1', 'provstate', 'city']\n",
    "txt_col = ['location', 'summary', 'scite1', 'scite2', 'scite3', 'motive', 'propcomment']\n",
    "cont_col = ['iyear', 'imonth', 'iday', 'latitude', 'longitude', 'nperps', 'nperpcap', 'nkill', 'nkillus', 'nkillter', 'nwound', \n",
    "            'nwoundus', 'nwoundte']\n",
    "target = ['claimed', 'gname']\n",
    "\n",
    "full_col = zeroone_col+onehot_col+many_onehot_col+txt_col+cont_col\n",
    "len(full_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1583"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2.gname.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.claimed.unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114183, 2141)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-28-480de3530bed>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-28-480de3530bed>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    test =\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "flag = (df.iyear == 2015 or df.iyear == 2016) and ()\n",
    "\n",
    "train = df[]\n",
    "# test = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
