{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.445 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from utils import jieba, get_stop_word_set, load_word_embeddings, get_word2id\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'embedding_dim':64,\n",
    "    'n_class': 4,\n",
    "    'batch_size': 1024,\n",
    "    'pre_processed': 0,\n",
    "    'max_aspect_len': 1,\n",
    "    'max_context_len': 90, \n",
    "\n",
    "    'n_epoch': 5,\n",
    "    'n_hidden': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'l2_reg': 0.001,   \n",
    "    'dropout': 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19325 127\n"
     ]
    }
   ],
   "source": [
    "subjects = ['动力', '价格', '内饰', '配置', '安全性', '外观', '操控', '油耗', '空间', '舒适性']\n",
    "word2id, max_len = get_word2id('../data/', subjects, False, 'train', 'test_public', filter_stop_ws=True)\n",
    "print(len(word2id), max_len)\n",
    "config['max_context_len'] = max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82900\n"
     ]
    }
   ],
   "source": [
    "def read_train_data(word2id, max_context_len, data_path, fname, all_aspect, pre_processed):\n",
    "#     '''return aspects, contents, labels, aspect_lens, content_lens'''\n",
    "    '''sentences, aspects, sentence_lens, sentence_locs, labels'''\n",
    "    if pre_processed:\n",
    "        pass\n",
    "    else:\n",
    "        stop_words = get_stop_word_set()\n",
    "        aspects, contents, labels, content_lens, aspects_locs = [], [], [], [], []\n",
    "        data = pd.read_csv(data_path + fname + '.csv')\n",
    "        id2label = data.groupby('content_id').apply(lambda x:dict([(item[0], item[1]) for item in x[['subject', 'sentiment_value']].values])).to_dict()\n",
    "        data = data.drop_duplicates('content_id')\n",
    "        data.reset_index(drop=True, inplace=True)\n",
    "        f_w = open(data_path + fname + '_info_without_stopword.txt', 'w')\n",
    "        for item in data[['content_id', 'content']].values:\n",
    "#             print(item[0])\n",
    "            words = [word2id[x] for x in filter(lambda x:x not in stop_words and len(x.strip())>0, jieba.cut(item[1].strip()))]\n",
    "            f_w.write(str(words) + '\\n')\n",
    "            if len(words) < max_context_len:\n",
    "                crt_content_lens = len(words)\n",
    "                words = words + [0] * (max_context_len-len(words))\n",
    "            else:\n",
    "                crt_content_lens = max_context_len\n",
    "                words = words[:max_context_len]\n",
    "            \n",
    "            crt_subject_value = id2label[item[0]]\n",
    "            f_w.write(str(crt_subject_value) + '\\n')\n",
    "            for suj in all_aspect:\n",
    "                if suj in crt_subject_value:\n",
    "                    contents.append(words)\n",
    "                    aspects.append([word2id[suj]])\n",
    "                    content_lens.append(crt_content_lens)\n",
    "                    aspects_locs.append([1/crt_content_lens] * crt_content_lens + [0.] * (config['max_context_len'] - crt_content_lens))\n",
    "                    crt_label = [0] * 4\n",
    "                    crt_label[crt_subject_value[suj]+1] = 1\n",
    "                    labels.append(crt_label)\n",
    "                else:\n",
    "                    contents.append(words)\n",
    "                    aspects.append([word2id[suj]])\n",
    "                    content_lens.append(crt_content_lens)\n",
    "                    aspects_locs.append([1/crt_content_lens] * crt_content_lens + [0.] * (config['max_context_len'] - crt_content_lens))                    \n",
    "                    labels.append([0] * 3 + [1])\n",
    "    \n",
    "    return np.asarray(contents), np.asarray(aspects), np.asarray(content_lens), np.asarray(aspects_locs), np.asarray(labels)\n",
    "            \n",
    "train = read_train_data(word2id, config['max_context_len'], '../data/', 'train',subjects, False)\n",
    "print(len(train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def read_test_data(word2id, max_context_len, data_path, fname, all_aspect, pre_processed):\n",
    "#     '''return aspects, contents, aspect_lens, content_lens'''\n",
    "#     if pre_processed:\n",
    "#         pass\n",
    "#     else:\n",
    "#         stop_words = get_stop_word_set()\n",
    "#         aspects, contents, content_lens = [], [], []\n",
    "#         data = pd.read_csv(data_path + fname + '.csv')\n",
    "#         data = data.drop_duplicates('content_id')\n",
    "#         data.reset_index(drop=True, inplace=True)\n",
    "#         f_w = open(data_path + fname + '_info_without_stopword.txt', 'w')\n",
    "#         for item in data[['content_id', 'content']].values:\n",
    "#             words = [word2id[x] for x in filter(lambda x:x not in stop_words and len(x.strip())>0, jieba.cut(item[1].strip()))]\n",
    "#             f_w.write(str(words) + '\\n')\n",
    "#             if len(words) < max_context_len:\n",
    "#                 crt_content_lens = len(words)\n",
    "#                 words = words + [0] * (max_context_len-len(words))\n",
    "#             else:\n",
    "#                 crt_content_lens = max_context_len\n",
    "#                 words = words[:max_context_len]\n",
    "            \n",
    "#             for suj in all_aspect:\n",
    "#                 contents.append(words)\n",
    "#                 aspects.append([word2id[suj]])\n",
    "#                 content_lens.append(crt_content_lens)\n",
    "    \n",
    "#     return np.asarray(aspects), np.asarray(contents), np.ones(len(aspects)), np.asarray(content_lens)\n",
    "# test = read_test_data(word2id, config['max_context_len'], '../data/', 'test_public',subjects, False)\n",
    "# print(len(test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config['embedding_matrix'], config['embedding_dim'] = load_word_embeddings(word2id, is_64_dim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config['early_stop'] = 1\n",
    "config['n_epoch'] = 20\n",
    "config['learning_rate'] = 0.01\n",
    "config['n_hidden'] = 70\n",
    "config['batch_size'] = 1024\n",
    "config['n_hop'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_flag, val_flag = train_test_split(range(int(len(train[0])/10)), test_size=0.2, random_state=2018)\n",
    "train_flag = np.concatenate([[10*i + x for x in range(10)] for i in train_flag])\n",
    "val_flag = np.concatenate([[10*i + x for x in range(10)] for i in val_flag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "[0.24395107 0.24702409 0.25125816 0.25776672]\n",
      "[0.19191936 0.2270088  0.20928296 0.3717889 ]\n",
      "[0.00575636 0.05072621 0.00556204 0.93795544]\n",
      "[0.1223937  0.2770491  0.12818941 0.47236776]\n",
      "[0.14378841 0.3316381  0.15220656 0.37236688]\n",
      "[0.12705709 0.35429093 0.13852076 0.3801312 ]\n",
      "[0.14053017 0.3529563  0.14413314 0.36238042]\n",
      "[0.08569728 0.36931267 0.0986122  0.44637778]\n",
      "[0.04917261 0.2909787  0.06370202 0.59614664]\n",
      "[0.04498645 0.26422012 0.05276005 0.6380334 ]\n",
      "[0.08526476 0.2560477  0.10068561 0.55800194]\n",
      "[0.10497721 0.28438407 0.09403244 0.51660633]\n",
      "[0.07955251 0.29471582 0.09166328 0.5340684 ]\n",
      "[0.08117111 0.2962359  0.08839735 0.53419566]\n",
      "[0.07512515 0.2851086  0.08501395 0.55475235]\n",
      "[0.12824601 0.23114802 0.13996454 0.50064147]\n",
      "[0.05426405 0.2911977  0.05567986 0.5988584 ]\n",
      "[0.05492367 0.27844402 0.04633115 0.6203012 ]\n",
      "[0.10164973 0.2452534  0.10785585 0.54524106]\n",
      "[0.04076622 0.29321396 0.02827565 0.6377442 ]\n",
      "[0.10300025 0.28556693 0.0737497  0.5376832 ]\n",
      "[0.08927833 0.28281438 0.10106567 0.5268416 ]\n",
      "[0.09062674 0.28379467 0.09579357 0.529785  ]\n",
      "[0.05634313 0.31451705 0.03159742 0.59754235]\n",
      "[0.06478087 0.31870648 0.03604265 0.58046997]\n",
      "[0.09068754 0.1727931  0.1884805  0.54803884]\n",
      "[0.1496035  0.21498044 0.14514127 0.4902747 ]\n",
      "[0.03353231 0.3583447  0.00937916 0.59874386]\n",
      "[0.05022538 0.31351757 0.0583937  0.5778633 ]\n",
      "[0.10165534 0.26299602 0.09951735 0.5358313 ]\n",
      "[0.16009428 0.21353695 0.12958246 0.4967863 ]\n",
      "[0.0294125  0.35141176 0.01571588 0.60345984]\n",
      "[0.0777192  0.25061914 0.1373773  0.53428435]\n",
      "[0.03229632 0.41224274 0.01273383 0.5427272 ]\n",
      "[0.02030156 0.35546595 0.01229399 0.6119385 ]\n",
      "[0.06628308 0.26887286 0.1917651  0.47307897]\n",
      "[0.16646129 0.25758874 0.06949054 0.5064595 ]\n",
      "[0.13393518 0.25805223 0.09427283 0.5137397 ]\n",
      "[0.12606135 0.27122316 0.01553004 0.5871855 ]\n",
      "[0.06783123 0.21559696 0.25470185 0.46186993]\n",
      "[0.04891608 0.28948498 0.12181877 0.53978014]\n",
      "[0.20012683 0.19163367 0.14981112 0.45842835]\n",
      "[0.02075865 0.33240902 0.03319062 0.61364174]\n",
      "[0.11724158 0.30774787 0.05295596 0.5220546 ]\n",
      "[0.24564573 0.17921242 0.12405281 0.45108905]\n",
      "[0.12671745 0.2068866  0.2298006  0.4365954 ]\n",
      "[0.04840542 0.25643772 0.13692032 0.55823654]\n",
      "[0.07791944 0.3286068  0.01028135 0.5831924 ]\n",
      "[0.07023725 0.17851718 0.32357866 0.42766702]\n",
      "[0.12328632 0.28382927 0.08632908 0.5065553 ]\n",
      "[0.06273604 0.33375654 0.03674094 0.56676644]\n",
      "[0.05705837 0.32383877 0.03996663 0.5791362 ]\n",
      "[0.08992046 0.29164195 0.06933979 0.54909784]\n",
      "[0.06964912 0.3565636  0.02134264 0.55244464]\n",
      "[0.05405292 0.28849563 0.08648369 0.57096785]\n",
      "[0.04210562 0.33469358 0.01928779 0.603913  ]\n",
      "[0.06056091 0.21471898 0.10921951 0.61550057]\n",
      "[0.02420164 0.4328891  0.00667294 0.53623635]\n",
      "[0.08426635 0.29851976 0.11448095 0.502733  ]\n",
      "[0.02059451 0.38665652 0.00974038 0.58300865]\n",
      "[0.11513544 0.26900932 0.10926346 0.5065918 ]\n",
      "[0.05315948 0.30965707 0.03539779 0.6017857 ]\n",
      "[0.1591368  0.2575691  0.07286179 0.5104323 ]\n",
      "[0.15025471 0.15033016 0.2605257  0.43888944]\n",
      "[0.04930443 0.14918664 0.35502982 0.44647917]\n",
      "[0.11620424 0.2729295  0.11025164 0.5006147 ]\n",
      "[0.10990285 0.24337316 0.10961944 0.5371046 ]\n",
      "[0.15403885 0.23777488 0.02088249 0.5873038 ]\n",
      "[0.05736867 0.2806441  0.01497178 0.6470155 ]\n",
      "[0.23222987 0.18457685 0.14283073 0.44036254]\n",
      "[0.04206113 0.30883726 0.05316798 0.5959336 ]\n",
      "[0.1745976  0.21260238 0.11796884 0.4948312 ]\n",
      "[0.09491047 0.34050763 0.02938173 0.5352002 ]\n",
      "[0.0826098  0.3193388  0.03290962 0.56514174]\n",
      "[0.1812358  0.19392942 0.15863624 0.46619856]\n",
      "[0.1283023  0.27252868 0.03153048 0.5676386 ]\n",
      "[0.06259227 0.1761675  0.3142181  0.44702223]\n",
      "[0.03667812 0.23720172 0.19782954 0.52829057]\n",
      "[0.02939087 0.36184606 0.01558176 0.5931813 ]\n",
      "[0.08121978 0.30003333 0.05143587 0.56731105]\n",
      "[0.04252772 0.35649925 0.02352265 0.57745034]\n",
      "[0.11495186 0.31479892 0.00563709 0.5646121 ]\n",
      "[0.14745307 0.28122032 0.02114145 0.5501852 ]\n",
      "[0.11063998 0.19444922 0.24548712 0.44942367]\n",
      "[0.06797489 0.32235086 0.05351571 0.55615854]\n",
      "[0.02192356 0.31735325 0.04538889 0.61533433]\n",
      "[0.16184127 0.15284584 0.1612061  0.52410674]\n",
      "[0.1924769  0.16465126 0.19214812 0.4507237 ]\n",
      "[0.04392686 0.27433264 0.14299622 0.5387443 ]\n",
      "[0.02669204 0.3744408  0.00770368 0.5911635 ]\n",
      "[0.1569086  0.16274837 0.26565987 0.4146832 ]\n",
      "[0.11437673 0.19392365 0.2606828  0.43101683]\n",
      "[0.03471446 0.33344322 0.03351091 0.59833133]\n",
      "[0.12996492 0.28510535 0.05498087 0.5299489 ]\n",
      "[0.03438434 0.3311951  0.02552233 0.6088983 ]\n",
      "[0.05088708 0.29917145 0.04013752 0.609804  ]\n",
      "[0.08014876 0.28773963 0.07575113 0.5563604 ]\n",
      "[0.1405305  0.23137587 0.09489449 0.53319913]\n",
      "[0.02360071 0.30552763 0.13117504 0.53969663]\n",
      "[0.11430022 0.2344383  0.12194632 0.5293152 ]\n",
      "[0.05697612 0.25968704 0.16762163 0.5157152 ]\n",
      "[0.0165306  0.34736022 0.06583819 0.57027096]\n",
      "[0.11005818 0.2655269  0.09066844 0.5337465 ]\n",
      "[0.18194376 0.2457655  0.07780881 0.49448186]\n",
      "[0.14788745 0.24596359 0.11830355 0.4878454 ]\n",
      "[[0.01126758 0.44825947 0.01840391 0.52206904]\n",
      " [0.01126758 0.44825947 0.0184039  0.52206904]\n",
      " [0.01126758 0.44825947 0.01840391 0.52206904]\n",
      " [0.01126758 0.44825947 0.01840391 0.52206904]\n",
      " [0.01126758 0.44825953 0.01840391 0.522069  ]]\n",
      "tp=576, fp=4524, fn=7209; p=0.11294117647058824, r=0.07398843930635839, f1=0.08940628637951106\n",
      "[[0.21131961 0.24243204 0.04046478 0.50578356]\n",
      " [0.2113197  0.242432   0.04046478 0.50578356]\n",
      " [0.21131966 0.24243204 0.04046478 0.50578356]\n",
      " [0.21131968 0.24243201 0.04046478 0.50578356]\n",
      " [0.21131971 0.24243201 0.04046477 0.50578356]]\n",
      "tp=134, fp=1226, fn=1811; p=0.09852941176470588, r=0.06889460154241646, f1=0.081089258698941\n",
      "epoch 0: train-loss=1.077015; train-acc=0.089406; test-loss=0.789434; test-acc=0.081089;\n",
      "[0.12653013 0.22643241 0.22862042 0.418417  ]\n",
      "[0.22261028 0.27729568 0.04578369 0.45431036]\n",
      "[0.01510369 0.30387503 0.22620568 0.4548156 ]\n",
      "[0.134151   0.28401348 0.01857244 0.5632631 ]\n",
      "[0.19954886 0.21811748 0.03210142 0.55023223]\n",
      "[0.08728084 0.2718995  0.09006895 0.55075073]\n",
      "[0.0160133  0.27946943 0.01087099 0.6936464 ]\n",
      "[0.02692259 0.24867894 0.007586   0.7168125 ]\n",
      "[0.06606476 0.28099218 0.10736925 0.54557383]\n",
      "[0.05879262 0.3204446  0.03445144 0.5863113 ]\n",
      "[0.05015043 0.37773958 0.01476951 0.55734044]\n",
      "[0.09079647 0.34533817 0.01237736 0.551488  ]\n",
      "[0.05300144 0.32484943 0.11212026 0.51002884]\n",
      "[0.01459253 0.43282762 0.01199927 0.5405806 ]\n",
      "[0.13742767 0.31467688 0.04978364 0.49811178]\n",
      "[0.02186544 0.36191872 0.00703978 0.60917604]\n",
      "[0.12441504 0.2847254  0.05238273 0.5384768 ]\n",
      "[0.01984266 0.21993987 0.25919396 0.5010235 ]\n",
      "[0.08320086 0.23517704 0.07741646 0.6042056 ]\n",
      "[0.1673866  0.21787788 0.05854653 0.556189  ]\n",
      "[0.04105271 0.35004723 0.03536463 0.5735354 ]\n",
      "[0.08937188 0.32381505 0.00863466 0.57817835]\n",
      "[0.06329381 0.33125955 0.03051896 0.5749276 ]\n",
      "[0.01389666 0.28222182 0.25056764 0.4533139 ]\n",
      "[0.04813879 0.3184375  0.10670538 0.5267183 ]\n",
      "[0.00588565 0.38434708 0.02627585 0.5834914 ]\n",
      "[0.04849241 0.3245296  0.02349013 0.60348785]\n",
      "[0.17767575 0.20982777 0.01939462 0.5931019 ]\n",
      "[0.11484256 0.2632752  0.06205704 0.5598251 ]\n",
      "[0.12852503 0.25424007 0.00449271 0.61274225]\n",
      "[0.05609497 0.30256346 0.09432864 0.5470129 ]\n",
      "[0.05683972 0.3079003  0.06812496 0.56713504]\n",
      "[0.1208391  0.24399681 0.1470045  0.48815957]\n",
      "[0.07070092 0.29224977 0.07758887 0.55946046]\n",
      "[0.05669031 0.34692657 0.00604855 0.5903346 ]\n",
      "[0.03288626 0.27119526 0.09929789 0.59662056]\n",
      "[0.20577122 0.20524955 0.06486069 0.52411854]\n",
      "[0.13621257 0.22477396 0.1889701  0.45004335]\n",
      "[0.06929928 0.2647477  0.09522972 0.57072324]\n",
      "[0.04917319 0.30604392 0.06040834 0.58437455]\n",
      "[0.02146955 0.13302237 0.41087034 0.43463773]\n",
      "[0.08650497 0.19297543 0.30796495 0.41255465]\n",
      "[0.03433806 0.33384869 0.09126306 0.54055023]\n",
      "[0.00051552 0.51101846 0.00381468 0.48465133]\n",
      "[0.08443708 0.2909429  0.0840684  0.54055166]\n",
      "[0.05112367 0.3532869  0.02290101 0.5726884 ]\n",
      "[0.07578748 0.27328742 0.06829745 0.58262765]\n",
      "[0.06251375 0.32302114 0.02262393 0.5918412 ]\n",
      "[0.11055404 0.24484254 0.10109881 0.5435046 ]\n",
      "[0.09906405 0.17895505 0.26331028 0.45867068]\n",
      "[0.14359073 0.21428895 0.08659065 0.55552965]\n",
      "[0.04324082 0.179827   0.3530983  0.42383388]\n",
      "[0.04095739 0.29357943 0.11086816 0.55459505]\n",
      "[0.06757002 0.34483594 0.02912573 0.55846834]\n",
      "[0.0304731  0.3768859  0.02889463 0.5637464 ]\n",
      "[0.10148667 0.30289808 0.02557106 0.5700442 ]\n",
      "[0.12063745 0.20506763 0.2223628  0.45193213]\n",
      "[0.06589574 0.33237997 0.05401291 0.54771143]\n",
      "[0.04510989 0.2513271  0.27301472 0.43054837]\n",
      "[0.11187819 0.2669525  0.06547263 0.5556966 ]\n",
      "[0.20860979 0.22575651 0.05836955 0.50726414]\n",
      "[0.03333758 0.36456725 0.01406415 0.58803105]\n",
      "[0.04972797 0.3218499  0.05174009 0.5766821 ]\n",
      "[0.0644851  0.29298085 0.01891134 0.6236228 ]\n",
      "[0.28121072 0.17706586 0.04844876 0.49327472]\n",
      "[0.0306803  0.3495239  0.03025362 0.5895422 ]\n",
      "[0.3772431  0.1220909  0.0310414  0.46962452]\n",
      "[0.02024287 0.3500789  0.03316265 0.5965156 ]\n",
      "[0.06766938 0.14269717 0.3504214  0.43921202]\n",
      "[0.02516369 0.35068464 0.04674021 0.5774114 ]\n",
      "[0.00261241 0.42069793 0.00691873 0.569771  ]\n",
      "[0.06521787 0.29879814 0.07206485 0.5639191 ]\n",
      "[0.09466097 0.30593824 0.05537182 0.544029  ]\n",
      "[0.17108314 0.15899608 0.22541033 0.4445105 ]\n",
      "[0.12629111 0.16312021 0.25268686 0.4579018 ]\n",
      "[0.14364263 0.27546546 0.06939593 0.511496  ]\n",
      "[0.15925756 0.19623932 0.21057789 0.43392515]\n",
      "[0.05575851 0.320917   0.01477696 0.6085475 ]\n",
      "[0.01240018 0.39310995 0.01243987 0.58204997]\n",
      "[0.00885882 0.38709423 0.00660939 0.59743756]\n",
      "[0.07102832 0.3201927  0.03660611 0.5721729 ]\n",
      "[0.09759972 0.32727003 0.02681887 0.54831135]\n",
      "[0.06157206 0.30619186 0.02441931 0.60781676]\n",
      "[0.17986053 0.22668505 0.00399794 0.58945644]\n",
      "[0.16899198 0.18531895 0.19295081 0.45273823]\n",
      "[0.11297721 0.24116929 0.004737   0.6411165 ]\n",
      "[0.14442591 0.26819107 0.03451076 0.55287224]\n",
      "[0.09216901 0.19334215 0.20674923 0.5077396 ]\n",
      "[0.09990803 0.18214142 0.25018328 0.4677672 ]\n",
      "[0.07124785 0.28196618 0.09957139 0.5472146 ]\n",
      "[0.26259974 0.09009617 0.05572249 0.5915816 ]\n",
      "[0.08513322 0.28253603 0.10442837 0.52790236]\n",
      "[0.03432395 0.1708283  0.3016576  0.49319014]\n",
      "[0.11138233 0.14554939 0.18104447 0.5620238 ]\n",
      "[0.02682455 0.35691196 0.05118315 0.5650804 ]\n",
      "[0.12265522 0.2530913  0.09541669 0.52883685]\n",
      "[0.0424902  0.32210612 0.06316963 0.57223403]\n",
      "[0.35493585 0.15048467 0.04403149 0.450548  ]\n",
      "[0.0403389  0.32688636 0.03488559 0.5978892 ]\n",
      "[0.03070505 0.3521445  0.07716218 0.5399883 ]\n",
      "[0.00970289 0.31824633 0.03522098 0.63682973]\n",
      "[0.07087733 0.22952063 0.21862921 0.48097286]\n",
      "[0.05411351 0.3201289  0.07295222 0.55280536]\n",
      "[0.06111083 0.30343643 0.03253722 0.6029156 ]\n",
      "[0.07448789 0.30730864 0.04861315 0.5695904 ]\n",
      "[[0.00905285 0.42605036 0.02757164 0.53732514]\n",
      " [0.00905285 0.42605036 0.02757164 0.53732514]\n",
      " [0.00905285 0.42605036 0.02757164 0.53732514]\n",
      " [0.00905285 0.4260503  0.02757166 0.5373252 ]\n",
      " [0.00905285 0.42605034 0.02757165 0.53732514]]\n",
      "tp=805, fp=6025, fn=6960; p=0.11786237188872621, r=0.10367031551835158, f1=0.11031175059952038\n",
      "[[0.32566133 0.14954765 0.05551176 0.46927932]\n",
      " [0.32566133 0.14954764 0.05551174 0.46927932]\n",
      " [0.32566127 0.14954767 0.05551177 0.46927932]\n",
      " [0.32566124 0.14954768 0.05551177 0.46927932]\n",
      " [0.3256613  0.14954765 0.05551174 0.46927932]]\n",
      "tp=161, fp=1439, fn=1783; p=0.100625, r=0.08281893004115226, f1=0.09085778781038374\n",
      "epoch 1: train-loss=1.035559; train-acc=0.110312; test-loss=0.789638; test-acc=0.090858;\n",
      "[0.13145298 0.3144267  0.04009735 0.51402295]\n",
      "[0.5330346  0.02697333 0.00059939 0.43939266]\n",
      "[0.05875795 0.12188321 0.42411917 0.39523965]\n",
      "[0.19483712 0.18880832 0.18711159 0.42924297]\n",
      "[0.05115174 0.34052655 0.01802913 0.5902926 ]\n",
      "[0.06105116 0.22188291 0.23392276 0.4831432 ]\n",
      "[0.11638767 0.23307376 0.10028703 0.55025154]\n",
      "[0.06326944 0.29363313 0.00695506 0.63614243]\n",
      "[0.04286398 0.21521243 0.2635121  0.47841147]\n",
      "[0.02024439 0.23407911 0.18190676 0.56376976]\n",
      "[0.09298525 0.34264567 0.02517715 0.53919184]\n",
      "[0.41899464 0.12392621 0.04988715 0.40719193]\n",
      "[0.03513823 0.3700328  0.00673942 0.58808964]\n",
      "[0.01666976 0.3297391  0.07692863 0.5766625 ]\n",
      "[0.01672281 0.34532398 0.00644216 0.6315111 ]\n",
      "[0.12005685 0.2262624  0.15564583 0.49803483]\n",
      "[0.03952508 0.3375461  0.00884456 0.61408424]\n",
      "[0.09601025 0.2962402  0.01583113 0.59191847]\n",
      "[0.02942917 0.33881062 0.03652828 0.59523195]\n",
      "[0.06876296 0.23100348 0.14113814 0.55909544]\n",
      "[0.07005352 0.29127863 0.00817786 0.63048995]\n",
      "[0.03758261 0.35975525 0.0186001  0.5840621 ]\n",
      "[0.08362057 0.2643098  0.15324575 0.4988239 ]\n",
      "[0.04538406 0.16210324 0.40170893 0.3908038 ]\n",
      "[0.14429662 0.24658825 0.00567104 0.6034441 ]\n",
      "[0.33448595 0.10492118 0.08533956 0.4752533 ]\n",
      "[0.02174002 0.41012046 0.00809887 0.5600407 ]\n",
      "[0.16363224 0.25374785 0.01446804 0.56815183]\n",
      "[0.1364649  0.2110324  0.04105366 0.61144906]\n",
      "[0.20276625 0.21893325 0.01803383 0.5602666 ]\n",
      "[0.08928271 0.17169815 0.20443444 0.53458476]\n",
      "[0.01432599 0.36590973 0.02551056 0.5942538 ]\n",
      "[0.08404417 0.33687446 0.02742725 0.5516541 ]\n",
      "[0.08377826 0.08398486 0.37569866 0.45653823]\n",
      "[0.15118739 0.29173285 0.01366074 0.543419  ]\n",
      "[0.17831576 0.2910075  0.0080699  0.5226068 ]\n",
      "[0.0523365  0.2569465  0.19659507 0.49412185]\n",
      "[0.08291018 0.2985396  0.11221278 0.5063374 ]\n",
      "[0.10406782 0.29012135 0.05995514 0.54585564]\n",
      "[0.41053227 0.11403389 0.014138   0.46129587]\n",
      "[0.13461165 0.17736223 0.29116768 0.39685836]\n",
      "[0.03885875 0.30736893 0.02532861 0.6284438 ]\n",
      "[0.05691231 0.14572713 0.2986502  0.49871033]\n",
      "[0.06686123 0.3345874  0.02595453 0.57259685]\n",
      "[0.25770414 0.18335725 0.02424999 0.53468853]\n",
      "[0.3677671  0.14401115 0.00780836 0.4804134 ]\n",
      "[0.01450151 0.3977553  0.02040866 0.56733453]\n",
      "[0.03920407 0.32201743 0.04143816 0.59734035]\n",
      "[0.1331994  0.33637312 0.0037572  0.5266703 ]\n",
      "[0.06744172 0.26060236 0.21918213 0.45277375]\n",
      "[0.116042   0.30126113 0.03361181 0.549085  ]\n",
      "[0.1468701  0.23766385 0.14907078 0.46639517]\n",
      "[0.42255056 0.05437397 0.07661478 0.44646075]\n",
      "[0.21977341 0.22098555 0.06071241 0.49852854]\n",
      "[0.02723398 0.31409758 0.04952307 0.6091454 ]\n",
      "[0.07938305 0.25481504 0.13554664 0.5302553 ]\n",
      "[0.21652308 0.1432107  0.18959835 0.45066792]\n",
      "[0.04119236 0.32043114 0.00682919 0.6315473 ]\n",
      "[0.02942483 0.37833995 0.00586321 0.586372  ]\n",
      "[0.07713941 0.32399118 0.03371088 0.56515855]\n",
      "[0.3455211  0.11948767 0.12028232 0.41470894]\n",
      "[0.03368735 0.38334182 0.03236433 0.5506065 ]\n",
      "[0.24905032 0.1489776  0.07349797 0.52847415]\n",
      "[0.06979217 0.32047683 0.01877709 0.59095395]\n",
      "[0.05991049 0.16527738 0.31666234 0.45814982]\n",
      "[0.06471781 0.24704546 0.2439711  0.44426566]\n",
      "[0.01971422 0.39752457 0.01173158 0.5710296 ]\n",
      "[0.00469483 0.10020991 0.41589183 0.47920346]\n",
      "[0.00986421 0.40170872 0.00099126 0.5874358 ]\n",
      "[0.01066688 0.31710628 0.13170631 0.54052055]\n",
      "[0.03624494 0.33639324 0.03832932 0.5890325 ]\n",
      "[0.02977568 0.37567988 0.0264697  0.56807476]\n",
      "[0.03053056 0.20515499 0.30698624 0.4573283 ]\n",
      "[0.09784951 0.1558438  0.23527616 0.51103055]\n",
      "[0.00672604 0.3810583  0.01451734 0.5976983 ]\n",
      "[0.03911766 0.31653574 0.02508138 0.6192652 ]\n",
      "[0.14364271 0.28371313 0.01515643 0.5574877 ]\n",
      "[0.14672266 0.20924044 0.2292751  0.4147618 ]\n",
      "[0.05234448 0.28286812 0.11686791 0.5479195 ]\n",
      "[0.03686662 0.35687134 0.00262694 0.60363513]\n",
      "[0.02092143 0.12122357 0.3986921  0.45916292]\n",
      "[0.01383237 0.3121451  0.1186647  0.5553578 ]\n",
      "[0.0898177  0.31023377 0.01544708 0.5845015 ]\n",
      "[0.06565945 0.26845998 0.16009086 0.5057897 ]\n",
      "[0.03319912 0.29110914 0.08521146 0.5904803 ]\n",
      "[0.01397507 0.37910128 0.02338902 0.58353466]\n",
      "[0.05758337 0.33650368 0.00891376 0.5969991 ]\n",
      "[0.3460966  0.10727841 0.01037881 0.5362462 ]\n",
      "[0.12396897 0.16510515 0.24360062 0.46732536]\n",
      "[0.06861683 0.27131543 0.07325703 0.5868107 ]\n",
      "[0.00208618 0.3584504  0.02417044 0.61529297]\n",
      "[0.02876954 0.35905492 0.01273315 0.59944236]\n",
      "[0.2483669  0.17196418 0.04030181 0.5393671 ]\n",
      "[0.01710755 0.37647462 0.01226042 0.59415734]\n",
      "[0.1551937  0.26333296 0.03017258 0.55130076]\n",
      "[0.12556654 0.21814506 0.13788198 0.5184064 ]\n",
      "[0.17879246 0.22570652 0.12924707 0.466254  ]\n",
      "[0.07829019 0.3186557  0.00844677 0.5946074 ]\n",
      "[0.43941966 0.1213735  0.04091056 0.39829633]\n",
      "[0.12904061 0.10328578 0.37424946 0.39342415]\n",
      "[0.07011556 0.30610833 0.02060189 0.6031743 ]\n",
      "[0.17755507 0.14356638 0.27509418 0.40378436]\n",
      "[0.05928575 0.3028005  0.0810506  0.5568631 ]\n",
      "[0.13812143 0.2023988  0.24371594 0.41576385]\n",
      "[0.05112185 0.21204971 0.31397378 0.42285463]\n",
      "[[0.00209332 0.479823   0.03408652 0.48399717]\n",
      " [0.00209331 0.47982317 0.03408641 0.4839971 ]\n",
      " [0.00209332 0.47982317 0.03408646 0.4839971 ]\n",
      " [0.00209332 0.4798231  0.03408645 0.48399717]\n",
      " [0.00209332 0.4798231  0.03408645 0.48399717]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ac7b743b6f21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m model.run((train[0][train_flag], train[1][train_flag], train[2][train_flag], train[3][train_flag], train[4][train_flag]),\n\u001b[0;32m---> 15\u001b[0;31m           (train[0][val_flag], train[1][val_flag], train[2][val_flag], train[3][val_flag], train[4][val_flag]))\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m# model.run((train[0][val_flag], train[1][val_flag], train[2][val_flag], train[3][val_flag], train[4][val_flag]),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#           (train[0][train_flag], train[1][train_flag], train[2][train_flag], train[3][train_flag], train[4][train_flag]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cjy/car_opinion_emotion/code/RAM_model.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, train_data, test_data, is_analyzing)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mmax_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cjy/car_opinion_emotion/code/RAM_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cjy/car_opinion_emotion/code/RAM_model.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_sm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_summary_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0mfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from imp import reload\n",
    "import RAM_model\n",
    "reload(RAM_model)\n",
    "from RAM_model import RAM\n",
    "\n",
    "# sess.close()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session();\n",
    "\n",
    "# 1616,  6661,  1670, 72953\n",
    "model = RAM(config, sess)\n",
    "model.build_model()\n",
    "model.run((train[0][train_flag], train[1][train_flag], train[2][train_flag], train[3][train_flag], train[4][train_flag]),\n",
    "          (train[0][val_flag], train[1][val_flag], train[2][val_flag], train[3][val_flag], train[4][val_flag]))\n",
    "# model.run((train[0][val_flag], train[1][val_flag], train[2][val_flag], train[3][val_flag], train[4][val_flag]),\n",
    "#           (train[0][train_flag], train[1][train_flag], train[2][train_flag], train[3][train_flag], train[4][train_flag]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "0338ecfe1d894127b7e0e64b6ac4fd22": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "07a2028dbab5439cb556bf1732510715": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "0a62d9fc6de14854bb553b0fa36c613f": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "1689adf44752471482d2767022f47752": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "1ba448aef0014a0c9d703163ba13a93d": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "1ef2b381d14a4b0c9ee9f24e53d1208b": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "2ad3cd05d3cb4d838cf6b4a86ce0d529": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "3068bb9bec7b467db91e54b626d66f56": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "337b7019a1ac4c7bbb1f6d0345e44613": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "352c23f37f964c9287f588f004189302": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "36b6cbbc79234e018e32e4cde5c96f27": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "36d42005816b421da6e4e049f041a6eb": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "37e9b2d605584e4e81f260a1c2d50283": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "39ca248cf3a045cc9ca9383a98edacc6": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "4906d8fbcdd0421e9e127cc9c7ed30ad": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "4a1ad745d5384a46a189c5ba7e72f8cc": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "52caf3ebffe94cd1beaa21fea9005fe5": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "54e1648c7c194efa92d0e7162845a81f": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "55cb6b56a91140c8b7c0a040d8a84bbd": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "5e406260d2ea41198495c904afe62fb2": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "64264bc56bf74615947a3b808362d0ad": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "6891c8924f854da49536bc037f7cfa46": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "6beeefb9057c45039e3298b616f67801": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "70801192cdc74cc988da435abdc45178": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "74e51ad7454b4a42ba4dcb7aa851956b": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "76863966c34a4aec82e2491a0b9571b5": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "856ff65c6eeb47f4b7be1496a9d96202": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "8a5ecb3b1640453f997bfa958ea1ce22": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "8fea61b3e48a4d7493090c7145a537d9": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "969e4dd79a2b4fdb8267aff40de103e6": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "9a276cd09b2f41ad9cc40cbf96203295": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "9bac910223cb4a3cb6a73c739d359e1e": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a06956821c5745058a9bada3bd85eafd": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a09688a02f4a45f6a1eab827471fb523": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a15b63262b8a4b2a9a18cc7b226b6720": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a3c070f751bb41ca8b2d4fbe16c93ae6": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a46b5b9b24b34b9094dfa8369afe446b": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a4a3530f93b746f5a28c0d5b739c9265": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a66cafb0a1054b9b8588d6704bb1b995": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a75f5f37f6594007a2d9f614bc24d423": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a9692da18f164533a1d3b130a71e1c8c": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "adcafaca4d614666a01f94ee1d924304": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "b6af2940438d408d85f1e1e6121b10c6": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "b7429649973f480f81c58e9e276c1a0b": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "bac83427ae4546ff9c0b55dc0a457e44": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "bfb1b011297f45e4945239cfc7455a51": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "c9be794235bb4afca8a6c5c58e1dacc2": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "d3fdf9f8775341d488e6b42d33137564": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "d551e19d88bb4e7b9abd39073516ea70": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "e761c0755d48417a8d2f07bf295c0c5a": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "ea0ef36f3a7e413e8bdc517ba80e1d84": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "ea308af59f574c9dbbe7dac28d8327e4": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "ebdb2a756ef142f0a8bc8f1f3d08e3ea": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "ef4819def6af4f4898cc38dcedaf74a5": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "f3aa6270bb46496fac89429c8c8af349": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "f58f0550c22d4309907db61b59863b8d": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "f5dc3c37984c4916abdf4bb513b6cb58": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "f7135d4d54f84811bf9af53d5938535e": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "faa46fa938e440bd88a58430d000a075": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "fc11e58e443a4ccfa57b2da201168937": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
