{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "#每次可以输出多个变量\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14, 6\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#中文字体\n",
    "import matplotlib\n",
    "matplotlib.use('qt4agg')\n",
    "#指定默认字体\n",
    "matplotlib.rcParams['font.sans-serif'] = ['SimHei']\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "#解决负号'-'显示为方块的问题\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2265879, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid</th>\n",
       "      <th>uid</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1790</td>\n",
       "      <td>55374290</td>\n",
       "      <td>0.009278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1918</td>\n",
       "      <td>30704418</td>\n",
       "      <td>0.043932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1904</td>\n",
       "      <td>44454952</td>\n",
       "      <td>0.045259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>562</td>\n",
       "      <td>30747797</td>\n",
       "      <td>0.050961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>886</td>\n",
       "      <td>19138638</td>\n",
       "      <td>0.019318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    aid       uid     score\n",
       "0  1790  55374290  0.009278\n",
       "1  1918  30704418  0.043932\n",
       "2  1904  44454952  0.045259\n",
       "3   562  30747797  0.050961\n",
       "4   886  19138638  0.019318"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.read_csv('./submit/submission_test2_0.75.csv')\n",
    "\n",
    "result.shape\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05042170168964725"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise = np.random.rand(result.shape[0]) / 10\n",
    "noise = np.random.normal(loc=0.05, scale=0.05, size=result.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.009278\n",
       "1    0.043932\n",
       "2    0.045259\n",
       "3    0.050961\n",
       "4    0.019318\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0    0.011516\n",
       "1    0.045723\n",
       "2    0.046714\n",
       "3    0.049851\n",
       "4    0.021742\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result.score[:5]\n",
    "result.score = result.score * 0.95 + noise * 0.05\n",
    "# result.score[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_zip_name = 'lgb005_new'\n",
    "result['score'] = result['score'].apply(lambda x: float('%.8f' % x))\n",
    "result.to_csv('submission.csv', index=False)\n",
    "os.system('zip -j '+sub_zip_name+'.zip submission.csv')\n",
    "os.system('mv submission.csv ./submit/'+sub_zip_name+'.csv')\n",
    "os.system('mv '+sub_zip_name+'.zip ./submit/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11064803, 156)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('df_b.csv')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8798814, 156)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2265989, 156)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'][df.label == -1] = 0\n",
    "\n",
    "train = df[df.label != -99]\n",
    "test = df[df.label == -99]\n",
    "\n",
    "train.shape\n",
    "test.shape\n",
    "\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "by = ['aid', 'uid']\n",
    "target = ['label']\n",
    "predictors = list(set(train.columns) - set(by) - set(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_cv\n",
    "params = {\n",
    "    'objective':'binary',\n",
    "        # metric='binary_error',\n",
    "        'num_leaves':7,\n",
    "        'max_depth':3,\n",
    "        'learning_rate':0.05,\n",
    "        'reg_alpha' : .4,\n",
    "        'reg_lambda' : .2,\n",
    "        'random_state':1024,\n",
    "        'colsample_bytree':0.8,\n",
    "        'subsample':0.9,\n",
    "#         'n_estimators':20000,\n",
    "        'n_jobs': 31,\n",
    "#         'device':'gpu',\n",
    "        'histogram_pool_size':30270,\n",
    "        'max_bin':63,\n",
    "        'gpu_use_dp':True\n",
    "}\n",
    "        \n",
    "len(predictors)\n",
    "\n",
    "lgb_train = lgb.Dataset(train[predictors],label = train['label'])\n",
    "print('Start training')\n",
    "cv = lgb.cv(params,lgb_train,num_boost_round=10000,nfold=3,early_stopping_rounds=50,seed=1024,verbose_eval=100)\n",
    "\n",
    "print('Baseline->' + str(len(cv['binary_logloss-mean'])) + ':' + str(cv['binary_logloss-mean'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_online = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        metric='binary_logloss',\n",
    "        num_leaves=7,#35,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.05, # small_eta\n",
    "        reg_alpha = .4,\n",
    "        reg_lambda = .2,\n",
    "        colsample_bytree = .8,\n",
    "        subsample = .9,\n",
    "        random_state=1024,\n",
    "        n_estimators=4000,\n",
    "        n_jobs = 31,\n",
    "        histogram_pool_size=30270,\n",
    "        max_bin=63\n",
    "    )\n",
    "len(predictors)\n",
    "\n",
    "# submit_model = lgb_online.fit(train[predictors], train['label'])\n",
    "\n",
    "test['score'] = submit_model.predict_proba(test[predictors])[:,1]\n",
    "test['score'] = test['score'].apply(lambda x: float('%.8f' % x))\n",
    "sub_zip_name = 'lgb'\n",
    "test[['aid', 'uid','score']].to_csv('submission.csv', index=False)\n",
    "os.system('zip -j '+sub_zip_name+'.zip submission.csv')\n",
    "os.system('mv submission.csv ./submit/'+sub_zip_name+'.csv')\n",
    "os.system('mv '+sub_zip_name+'.zip ./submit/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2265879, 172)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2265879, 172)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2265879, 172)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2265879, 172)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2265879, 172)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = pd.read_csv('test_kflod_b0')\n",
    "test2 = pd.read_csv('test_kflod_b1')\n",
    "test3 = pd.read_csv('test_kflod_b2')\n",
    "test4 = pd.read_csv('test_kflod_b3')\n",
    "test5 = pd.read_csv('test_kflod_b4')\n",
    "\n",
    "test1.shape\n",
    "test2.shape\n",
    "test3.shape\n",
    "test4.shape\n",
    "test5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2265879, 155)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test1 + test2 + test3 + test4 + test5\n",
    "test = test[predictors + by]\n",
    "test = test / 5\n",
    "\n",
    "test.shape\n",
    "\n",
    "# test1.head()\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test1\n",
    "del test2\n",
    "del test3\n",
    "del test4\n",
    "del test5\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
