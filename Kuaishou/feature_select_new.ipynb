{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "# from notify import send_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    f1s = []\n",
    "    # 实验证明在分类阈值在0.4左右比较好.\n",
    "    for limit in np.arange(0.4, 0.44, 0.01):\n",
    "        pred = [int(i>limit) for i in preds]\n",
    "        f1s.append(f1_score(labels, pred))\n",
    "    \n",
    "    \n",
    "#     pred = [1. if i>0.45 else 0. for i in preds]\n",
    "    # return a pair metric_name, result\n",
    "    # since preds are margin(before logistic transformation, cutoff at 0)\n",
    "    return 'f1', -1*max(f1s) #-1*f1_score(labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def model_train(train, val, cols, r, es):\n",
    "    params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eta': 0.05,\n",
    "            'min_child_weight': 17,\n",
    "            'max_depth': 5,\n",
    "            'verbose_eval': False,\n",
    "            'seed': 2018,\n",
    "            'missing': -1,\n",
    "            'n_jobs':4,\n",
    "            'eval_metric':'auc',\n",
    "            'tree_method':'gpu_hist',\n",
    "            'max_bin':64,\n",
    "            'gpu_device':0\n",
    "    }\n",
    "    dtrain = xgb.DMatrix(train[cols], label=train[['label']])\n",
    "    dval = xgb.DMatrix(val[cols], label=val[['label']])\n",
    "    # 这里没有用feval，用了之后会变成单核在跑，有没有什么办法改进一下\n",
    "    model = xgb.train(params, dtrain, num_boost_round=r, early_stopping_rounds=es, evals=[(dval, 'val')], verbose_eval=False)\n",
    "    preds = model.predict(dval, ntree_limit=model.best_ntree_limit)\n",
    "    f1_dict = {}\n",
    "    # 因此用这种方式来代替feval，最终确定模型轮数的时候还是用feval来确定\n",
    "    for limit in np.arange(0.4, 0.44, 0.01):\n",
    "        pred = [int(i>limit) for i in preds]\n",
    "        f1 = f1_score(dval.get_label(), pred)\n",
    "        f1_dict[limit] = f1\n",
    "    best_f1 = sorted(f1_dict.items(), key=lambda x:x[1], reverse=True)[0]\n",
    "    return best_f1[1], model.best_iteration\n",
    "#     return model.best_score, model.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def feature_select(train, val, basic_cols, add_cols, reverse=False, add_step=10):\n",
    "    num_boost_rounds = 78\n",
    "    early_stop_rounds = 200\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "#     params = {\n",
    "#         'objective': 'binary:logistic',\n",
    "#         'eta': 0.05,\n",
    "#         'colsample_bytree': 0.8,\n",
    "#         'subsample':0.6,\n",
    "#         'min_child_weight': 5,\n",
    "#         'max_depth': 3,\n",
    "#         'verbose_eval': 100,\n",
    "#         'seed': 2018,\n",
    "#         'missing': -1,\n",
    "#         'n_jobs':8,\n",
    "#         'eval_metric':'auc'\n",
    "#     }\n",
    "    # basic score\n",
    "    basic_score = model_train(train, val, basic_cols, num_boost_rounds, early_stop_rounds)[0]\n",
    "    print('base -> ', basic_score)\n",
    "    base_score = basic_score\n",
    "    \n",
    "    print('start calcuate %d features score'%len(add_cols))\n",
    "    # one-feature scoring\n",
    "    fea_importance = {}\n",
    "    for col in tqdm(add_cols):\n",
    "        if col in basic_cols:\n",
    "            continue\n",
    "        tmp_cols = basic_cols + [col]\n",
    "        fea_score = model_train(train, val, tmp_cols, num_boost_rounds, early_stop_rounds)[0]\n",
    "    #     print(col,'->',model.best_score,model.best_iteration)\n",
    "        fea_importance[col] = fea_score\n",
    "    \n",
    "    # sort by score\n",
    "    select1 = []\n",
    "    for f in fea_importance:\n",
    "        if reverse:\n",
    "            if abs(fea_importance[f]) > abs(base_score):\n",
    "                select1.append(f)\n",
    "        else:\n",
    "            if abs(fea_importance[f]) < abs(base_score):\n",
    "                select1.append(f)\n",
    "    select1.sort(key=lambda x:abs(fea_importance[x]),reverse=reverse)\n",
    "    \n",
    "    print('good features: ', len(select1), 'trying add...')\n",
    "    # try add features\n",
    "    best_i = 1\n",
    "    best_score = base_score\n",
    "    for i in tqdm(range(1,len(select1)+add_step-1,add_step)):\n",
    "        tmp_cols = basic_cols + select1[:i]\n",
    "        tmp_score, tmp_iter = model_train(train, val, tmp_cols, num_boost_rounds, early_stop_rounds)\n",
    "        if reverse:\n",
    "            if abs(tmp_score) > abs(best_score):\n",
    "                print(i,'->',tmp_score, tmp_iter)\n",
    "                best_score = tmp_score\n",
    "                best_i = i\n",
    "        else:\n",
    "            if abs(tmp_score) < abs(best_score):\n",
    "                print(i,'->',tmp_score, tmp_iter)\n",
    "                best_score = tmp_score\n",
    "                best_i = i\n",
    "    # best_i before-after\n",
    "    for i in range(max(0,best_i-add_step),best_i+add_step,1):\n",
    "        tmp_cols = basic_cols + select1[:i]\n",
    "        tmp_score, tmp_iter = model_train(train, val, tmp_cols, num_boost_rounds, early_stop_rounds)\n",
    "        if reverse:\n",
    "            if abs(tmp_score) > abs(best_score):\n",
    "                print(i,'->',tmp_score, tmp_iter)\n",
    "                best_score = tmp_score\n",
    "                best_i = i\n",
    "        else:\n",
    "            if abs(tmp_score) < abs(best_score):\n",
    "                print(i,'->',tmp_score, tmp_iter)\n",
    "                best_score = tmp_score\n",
    "                best_i = i\n",
    "    \n",
    "    usecols = basic_cols + select1[:best_i]\n",
    "    print('add finished, selected top',best_i, 'total :', len(usecols))\n",
    "    #try drop features\n",
    "    dropped = []\n",
    "    while True:\n",
    "        flag = False\n",
    "        for f in tqdm(usecols[::-1]):\n",
    "            if f in dropped:\n",
    "                continue\n",
    "            tmp_cols = usecols\n",
    "            tmp_cols = [each for each in tmp_cols if each not in dropped and each !=f]\n",
    "            tmp_score, tmp_iter = model_train(train, val, tmp_cols, num_boost_rounds, early_stop_rounds)\n",
    "            if reverse:\n",
    "                if abs(tmp_score) > abs(best_score):\n",
    "                    print(f,'->',tmp_score, tmp_iter)\n",
    "                    best_score = tmp_score\n",
    "                    dropped.append(f)\n",
    "                    flag = True\n",
    "            else:\n",
    "                if abs(tmp_score) < abs(best_score):\n",
    "                    print(f,'->',tmp_score, tmp_iter)\n",
    "                    best_score = tmp_score\n",
    "                    dropped.append(f)\n",
    "                    flag = True\n",
    "        if not flag:\n",
    "            break\n",
    "    print('dropped %d features'%len(dropped))\n",
    "    usecols = [each for each in usecols if each not in dropped]\n",
    "    return usecols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def feature_select2(train, val, basic_cols, add_cols, reverse=False):\n",
    "    num_boost_rounds = 78\n",
    "    early_stop_rounds = 200\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "    base_score = model_train(train, val, basic_cols, num_boost_rounds, early_stop_rounds)[0]\n",
    "    print('base -> ',base_score)\n",
    "    global_best = base_score\n",
    "    to_select = add_cols\n",
    "    selected = []\n",
    "    stop_flag = 0\n",
    "    while True:\n",
    "        fea_imp = {}\n",
    "        part_best = None\n",
    "        part_best_fea = ''\n",
    "        \n",
    "        for col in tqdm(to_select):\n",
    "            if col in selected:\n",
    "                continue\n",
    "            tmp_cols = basic_cols + selected + [col]\n",
    "            best_s, best_iter = model_train(train, val, tmp_cols, num_boost_rounds, early_stop_rounds)\n",
    "            fea_imp[col] = best_s\n",
    "            if part_best is None:\n",
    "                part_best = best_s\n",
    "                part_best_fea = col\n",
    "            else:\n",
    "                if reverse:\n",
    "                    if abs(best_s) > abs(part_best):\n",
    "                        part_best = best_s\n",
    "                        part_best_fea = col\n",
    "                else:\n",
    "                    if abs(best_s) < abs(part_best):\n",
    "                        part_best = best_s\n",
    "                        part_best_fea = col\n",
    "        if reverse:\n",
    "            if abs(part_best) > abs(global_best):\n",
    "                stop_flag = 0\n",
    "                global_best = part_best\n",
    "                selected.append(part_best_fea)\n",
    "                print(part_best_fea, '->', part_best)\n",
    "            else:\n",
    "                stop_flag += 1\n",
    "                selected.append(part_best_fea)\n",
    "                print('[stop flag + 1]', part_best_fea, part_best)\n",
    "                \n",
    "        else:\n",
    "            if abs(part_best) < abs(global_best):\n",
    "                stop_flag = 0\n",
    "                global_best = part_best\n",
    "                selected.append(part_best_fea)\n",
    "                print(part_best_fea, '->', part_best)\n",
    "            else:\n",
    "                stop_flag += 1\n",
    "                selected.append(part_best_fea)\n",
    "                print('[stop flag + 1]', part_best_fea, part_best)\n",
    "        new_select = []\n",
    "        for each in fea_imp:\n",
    "            if abs(fea_imp[each]) > abs(base_score):\n",
    "                new_select.append(each)\n",
    "        to_select = new_select\n",
    "        if stop_flag >= 2:\n",
    "            break        \n",
    "        if len(selected) == len(add_cols) or len(add_cols) == 0:\n",
    "            break\n",
    "    print('finished.',len(selected),'selected.','stop_flag =',stop_flag)\n",
    "    usecols = basic_cols + selected[:-stop_flag]\n",
    "    #try drop features\n",
    "    dropped = []\n",
    "    while True:\n",
    "        flag = False\n",
    "        for f in tqdm(usecols[::-1]):\n",
    "            if f in dropped:\n",
    "                continue\n",
    "            tmp_cols = usecols\n",
    "            tmp_cols = [each for each in tmp_cols if each not in dropped and each !=f]\n",
    "            tmp_score, tmp_iter = model_train(train, val, tmp_cols, num_boost_rounds, early_stop_rounds)\n",
    "            if reverse:\n",
    "                if abs(tmp_score) > abs(global_best):\n",
    "                    print(f,'->',tmp_score, tmp_iter)\n",
    "                    global_best = tmp_score\n",
    "                    dropped.append(f)\n",
    "                    flag = True\n",
    "            else:\n",
    "                if abs(tmp_score) < abs(global_best):\n",
    "                    print(f,'->',tmp_score, tmp_iter)\n",
    "                    global_best = tmp_score\n",
    "                    dropped.append(f)\n",
    "                    flag = True\n",
    "        if not flag:\n",
    "            break\n",
    "    print('dropped %d features'%len(dropped))\n",
    "    usecols = [each for each in usecols if each not in dropped]\n",
    "    return usecols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../features/baseline_features9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[(df.data_weeknum <= 1)] #& (df.data_weeknum>0)]\n",
    "val = df[df.data_weeknum == 2]\n",
    "test = df[df.data_weeknum == 3]\n",
    "trainval = df[df.data_weeknum <=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cols = ['register_type', 'device_type', 'user_reg_days']\n",
    "usecols = ['register_type', 'device_type', 'user_reg_days', 'user_lastweek_launchday', 'user_launch_days_lastweek', 'user_launch_times_lastweek', 'user_last_launch_dist', 'user_hist_launch_freq', 'user_hist_launchday', 'user_launch_days_hist', 'user_launch_times_hist', 'user_mean_continue_launch_times_lastweek', 'user_max_continue_launch_times_lastweek', 'user_activity_days_hist', 'user_activity_days_lastweek', 'user_min_continue_launch_times_lastweek', 'user_mean_continue_launch_days_lastweek', 'user_max_continue_launch_days_lastweek', 'user_mean_continue_activity_days_lastweek', 'user_max_continue_activity_days_lastweek', 'user_lastweek_act_0_freq', 'user_lastweek_actcount', 'user_activity_times_lastweek', 'user_lastweek_act_video_uniquecount', 'user_max_continue_launch_times_hist', 'user_min_continue_launch_days_lastweek', 'user_mean_continue_launch_times_hist', 'user_min_continue_activity_days_lastweek', 'user_hist_act_0_count', 'user_hist_actcount', 'user_activity_times_hist', 'user_mean_continue_activity_days_hist', 'user_max_continue_launch_days_hist', 'user_hist_act_freq', 'user_mean_continue_launch_days_hist', 'user_hist_act_author_count', 'user_mean_no_launch_days_hist', 'user_min_activity_daytimes_lastweek', 'user_lastweek_act', 'user_lastweek_act_0', 'user_mean_continue_activity_times_hist', 'user_max_launch_daytimes_lastweek', 'user_mean_launch_daytimes_lastweek', 'user_min_launch_daytimes_lastweek', 'user_lastweek_launch', 'user_lastweek_act_page_3_count', 'user_lastweek_act_page_1_count', 'user_max_no_launch_days_hist', 'user_last_act_date', 'user_lastweek_act_2_freq', 'user_lastweek_video_freq', 'user_lastweek_act_2_count']\n",
    "add1 = ['user_lastweek_launch_freq', 'user_max_no_activity_days_lastweek_hist_dist','user_lastweek_act_page_2_count','user_var_continue_activity_times_lastweek','user_kurt_continue_activity_days_hist']\n",
    "add2 = ['user_launch_range_percent','user_activity_div_launch_days_hist','user_hist_act_video_meancount','user_hist_video_activity_types']\n",
    "usecols += add1\n",
    "usecols += add2\n",
    "#usecols version1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usecols version2.\n",
    "usecols = ['register_type', 'device_type', 'user_reg_days', 'user_lastweek_launchday', 'user_last_launch_dist', 'user_hist_launch_freq', 'user_hist_launchday', 'user_mean_continue_launch_times_lastweek', 'user_max_continue_launch_times_lastweek', 'user_activity_days_hist', 'user_activity_days_lastweek', 'user_min_continue_launch_times_lastweek', 'user_mean_continue_launch_days_lastweek', 'user_max_continue_launch_days_lastweek', 'user_mean_continue_activity_days_lastweek', 'user_max_continue_activity_days_lastweek', 'user_lastweek_act_0_freq', 'user_lastweek_actcount', 'user_lastweek_act_video_uniquecount', 'user_max_continue_launch_times_hist', 'user_min_continue_launch_days_lastweek', 'user_mean_continue_launch_times_hist', 'user_min_continue_activity_days_lastweek', 'user_hist_act_0_count', 'user_hist_actcount', 'user_mean_continue_activity_days_hist', 'user_max_continue_launch_days_hist', 'user_hist_act_freq', 'user_mean_continue_launch_days_hist', 'user_hist_act_author_count', 'user_mean_no_launch_days_hist', 'user_min_activity_daytimes_lastweek', 'user_lastweek_act', 'user_lastweek_act_0', 'user_mean_continue_activity_times_hist', 'user_max_launch_daytimes_lastweek', 'user_lastweek_launch', 'user_lastweek_act_page_3_count', 'user_lastweek_act_page_1_count', 'user_max_no_launch_days_hist', 'user_last_act_date', 'user_lastweek_act_2_freq', 'user_lastweek_video_freq', 'user_lastweek_act_2_count', 'user_lastweek_launch_freq', 'user_max_no_activity_days_lastweek_hist_dist', 'user_lastweek_act_page_2_count', 'user_var_continue_activity_times_lastweek', 'user_kurt_continue_activity_days_hist', 'user_launch_range_percent', 'user_activity_div_launch_days_hist', 'user_hist_act_video_meancount', 'user_hist_video_activity_types', 'user_activity_range_percent', 'user_5daybefore_act_page_1_count', 'user_min_continue_activity_times_5daywin', 'user_lastweek_hist_act_3_count_dist', 'user_lastweek_hist_act_page_3_count_dist', 'user_mean_createvideo_date_lastweek_hist_dist', 'user_4daybefore_act_page_4_count', 'user_kurt_no_launch_days_6daywin', 'user_max_continue_createvideo_days_4daywin', 'user_2daybefore_act_1_count', 'user_max_continue_createvideo_days_hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_select = [col for col in df.columns.tolist()[9:] if col not in usecols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_lastweek_launchday user_launch_days_lastweek\n",
      "user_lastweek_launchday user_launch_times_lastweek\n",
      "user_launch_days_lastweek user_launch_times_lastweek\n",
      "user_hist_launchday user_launch_days_hist\n",
      "user_hist_launchday user_launch_times_hist\n",
      "user_launch_days_hist user_launch_times_hist\n",
      "user_lastweek_actcount user_activity_times_lastweek\n",
      "user_hist_actcount user_activity_times_hist\n",
      "user_max_launch_daytimes_lastweek user_mean_launch_daytimes_lastweek\n",
      "user_max_launch_daytimes_lastweek user_min_launch_daytimes_lastweek\n",
      "user_mean_launch_daytimes_lastweek user_min_launch_daytimes_lastweek\n"
     ]
    }
   ],
   "source": [
    "# from scipy.stats import pearsonr\n",
    "# for i in range(len(usecols)):\n",
    "#     for j in range(i+1, len(usecols)):\n",
    "#         if pearsonr(df[usecols[i]], df[usecols[j]])[0] == 1:\n",
    "#             print(usecols[i], usecols[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base ->  0.806753637471795\n",
      "start calcuate 1267 features score\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0a0d26fbe34c08a297a66ccfed062a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1267), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "good features:  170 trying add...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ac377fca254aaca08d31118f47b435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -> 0.8071999379315694 77\n",
      "\n",
      "add finished, selected top 1 total : 66\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8415e08e9e342dea1e3bf72b8e37c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=66), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_lastweek_hist_act_page_3_dist -> 0.8072924747866563 77\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be189a44e6764a878ddc0b6af56699dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=66), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dropped 1 features\n"
     ]
    }
   ],
   "source": [
    "feas = feature_select(train, val, usecols, to_select, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base ->  0.8084760857038086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e04d4c9c074a969dcd24ccccea4cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1268), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feas = feature_select2(train, val, usecols, to_select, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_msg('%s'%(model_train(train, val, feas, 20000, 500),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
