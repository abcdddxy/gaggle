{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import pickle\n",
    "from time import time\n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#每次可以输出多个变量\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14, 6\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#中文字体\n",
    "import matplotlib\n",
    "matplotlib.use('qt4agg')\n",
    "#指定默认字体\n",
    "matplotlib.rcParams['font.sans-serif'] = ['SimHei']\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "#解决负号'-'显示为方块的问题\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import xavier_initializer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import math\n",
    "import logging\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "from scipy.sparse.lil import lil_matrix\n",
    "from scipy.sparse import hstack, vstack\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "#每次可以输出多个变量\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xDeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MLP(inp, hidden_dims):\n",
    "    x = tf.layers.Dense(hidden_dims[0], kernel_initializer=tf.keras.initializers.he_normal(), dtype=tf.float32, activation=tf.nn.relu)(inp)\n",
    "    x = tf.layers.BatchNormalization(dtype=tf.float32)(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    for i, dim in enumerate(hidden_dims):\n",
    "        if i > 0:\n",
    "            x = tf.layers.Dense(dim, kernel_initializer=tf.keras.initializers.he_normal(), dtype=tf.float32, activation=tf.nn.relu)(x)\n",
    "            x = tf.layers.BatchNormalization(dtype=tf.float32)(x)\n",
    "            x = tf.nn.relu(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Res_Network(inp, hidden_dims):\n",
    "    x = inp\n",
    "    res = inp\n",
    "    for i, dim in enumerate(hidden_dims):\n",
    "        res = tf.layers.Dense(hidden_dims[i], kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                              dtype=tf.float32, activation=tf.nn.relu, name='Dense_inp' + str(i))(res)\n",
    "        res = tf.layers.BatchNormalization(dtype=tf.float32, name='BN_inp' + str(i))(res)\n",
    "        res = tf.nn.relu(res)\n",
    "        res = tf.layers.Dense(dim, kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                              dtype=tf.float32, activation=tf.nn.relu, name='Dense_res' + str(i))(res)\n",
    "        res = tf.concat([res, x], axis=1)\n",
    "        x = res\n",
    "        res = tf.layers.BatchNormalization(dtype=tf.float32, name='BN_res' + str(i))(res)\n",
    "        res = tf.nn.relu(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class xDeepFM:\n",
    "    def __init__(self, learning_rate, embedding_size, dnn_layers, cross_layers, res_layers, conti_fea_cnt,\n",
    "                 cate_embedding_uni_cnt_list, cate_embedding_w_list=None, fm_embedding_w=None):\n",
    "        self.lr = learning_rate\n",
    "        self.embedding_size = embedding_size\n",
    "        self.dnn_layers = dnn_layers\n",
    "        self.cross_layers = cross_layers\n",
    "        self.res_layers = res_layers\n",
    "        self.conti_fea_cnt = conti_fea_cnt\n",
    "        # cate_embedding_uni_cnt_list离散特征计数\n",
    "        self.cate_embedding_uni_cnt_list = cate_embedding_uni_cnt_list\n",
    "        self.cate_embedding_w_list = cate_embedding_w_list\n",
    "        self.fm_embedding_w = fm_embedding_w\n",
    "        \n",
    "        self.build()\n",
    "\n",
    "    def build(self):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            config = tf.ConfigProto()\n",
    "            config.gpu_options.allow_growth = True\n",
    "            self.sess = tf.Session(config=config)\n",
    "\n",
    "            self.input_vecs = []\n",
    "\n",
    "            self.conti_vec = tf.placeholder(tf.float32, shape=[None, self.conti_fea_cnt], name='conti_vec')\n",
    "            self.cate_indexs = tf.placeholder(tf.int16, shape=[None, sum(self.cate_embedding_uni_cnt_list)], name='cate_indexs')\n",
    "            self.label = tf.placeholder(dtype=tf.int8, shape=[None, 1], name='label')\n",
    "\n",
    "            self.cate_embeddings = []\n",
    "            self.fm_fea_size = 0\n",
    "\n",
    "            # 第一层embedding：降维\n",
    "            cate_offset = 0\n",
    "            for cate_idx, uni_cnt in enumerate(self.cate_embedding_uni_cnt_list):\n",
    "                w = self.cate_embedding_w_list[cate_idx] if self.cate_embedding_w_list else tf.keras.initializers.he_normal()\n",
    "                embedding_k = uni_cnt if int(2 * np.power(uni_cnt, 1 / 4)) > uni_cnt else int(2 * np.power(uni_cnt, 1 / 4))\n",
    "                self.fm_fea_size += embedding_k\n",
    "                # embedding矩阵\n",
    "                self.cate_embeddings.append(\n",
    "                    tf.get_variable('cate_%d_embedding' % cate_idx, shape=[uni_cnt, embedding_k], dtype=tf.float32,\n",
    "                                    initializer=w))\n",
    "\n",
    "                crt_vec_index = self.cate_indexs[:, cate_offset:cate_offset + uni_cnt]  # None * uni_cnt\n",
    "                cate_offset += uni_cnt\n",
    "\n",
    "                crt_vec = tf.nn.embedding_lookup(self.cate_embeddings[cate_idx], [i for i in range(uni_cnt)])  # uni_cnt * K\n",
    "                crt_vec = tf.matmul(tf.cast(crt_vec_index, tf.float32), crt_vec)  # None * K\n",
    "                self.input_vecs.append(crt_vec)\n",
    "\n",
    "            mv_conti_vec = self.conti_vec\n",
    "\n",
    "            self.input_vecs.append(mv_conti_vec)\n",
    "            self.fm_fea_size += self.conti_fea_cnt\n",
    "\n",
    "            # 准备输入-----------------------------------------------------------------------------------------------------\n",
    "            fm_fea = tf.concat(self.input_vecs, axis=-1)\n",
    "\n",
    "            self.feat_index = [i for i in range(self.fm_fea_size)]\n",
    "            if self.fm_embedding_w is not None:\n",
    "                self.fea_embedding = tf.Variable(self.fm_embedding_w, name='fea_embedding', dtype=tf.float32)\n",
    "            else:\n",
    "                self.fea_embedding = tf.get_variable('fea_embedding', shape=[self.fm_fea_size, self.embedding_size],\n",
    "                                                     initializer=tf.keras.initializers.he_normal(), dtype=tf.float32)\n",
    "\n",
    "            # 构造输入\n",
    "            # 第二层embedding：潜在隐变量\n",
    "            embeddings = tf.nn.embedding_lookup(self.fea_embedding, self.feat_index)  # None * F * K\n",
    "            feat_value = tf.reshape(fm_fea, shape=[-1, self.fm_fea_size, 1])\n",
    "            embeddings = tf.multiply(embeddings, feat_value)  # None * F * K\n",
    "#             print(embeddings)\n",
    "\n",
    "            # 搭建网络-----------------------------------------------------------------------------------------------------\n",
    "            # CIN部分\n",
    "            with tf.variable_scope('CIN-part'):\n",
    "                # step 1:x(0) dot x(k) = z(k+1)\n",
    "                cin_layers = []\n",
    "                field_nums = []\n",
    "                final_result = []\n",
    "                final_len = 0\n",
    "                cin_input = tf.reshape(embeddings, [-1, self.fm_fea_size, self.embedding_size]) # None * F * K\n",
    "                cin_layers.append(cin_input)\n",
    "                field_nums.append(self.fm_fea_size)\n",
    "                split_tensor0 = tf.split(cin_layers[0], self.embedding_size * [1], 2) # (None * F * 1) * K\n",
    "                for i, layer_size in enumerate(self.cross_layers):\n",
    "                    split_tensor = tf.split(cin_layers[-1], self.embedding_size * [1], 2) # (None * L(k) * 1) * K\n",
    "                    dot_result = tf.matmul(split_tensor0, split_tensor, transpose_b=True) # K * None * F * L(k)\n",
    "                    dot_result = tf.reshape(dot_result, shape=[self.embedding_size, -1, field_nums[0]*field_nums[-1]]) # K * None * (F * L(k))\n",
    "                    dot_result = tf.transpose(dot_result, [1, 0 ,2]) # None * K * (F * L(k))\n",
    "                # step 2:z(k+1) * cross_w(k+1) = x(k+1)\n",
    "                    filter_k = tf.get_variable('filter_k'+str(i), shape=[1, field_nums[0]*field_nums[-1], layer_size]) # 1 * (F*L(k)) * K\n",
    "                    cross_out = tf.nn.conv1d(dot_result, filter_k, stride=1, padding='VALID') # None * K * L(k+1)\n",
    "                    cross_b = tf.get_variable('cross_b'+str(i), shape=[layer_size], initializer=tf.keras.initializers.he_normal(), dtype=tf.float32)\n",
    "                    cross_out = tf.nn.bias_add(cross_out, cross_b) # None * K * L(k+1)\n",
    "                    cross_out = tf.nn.relu(cross_out)\n",
    "                    cross_out = tf.transpose(cross_out, [0, 2, 1]) # None * L(k+1) * K\n",
    "                    # direct connect\n",
    "#                     direct_connect = cross_out\n",
    "#                     next_hidden = cross_out\n",
    "#                     final_len += layer_size\n",
    "#                     field_nums.append(int(layer_size))\n",
    "                    # split connect\n",
    "                    if i != len(self.cross_layers) - 1:\n",
    "                        next_hidden, direct_connect = tf.split(cross_out, 2 * [int(layer_size / 2)], 1)\n",
    "                        final_len += int(layer_size / 2)\n",
    "                    else:\n",
    "                        direct_connect = cross_out\n",
    "                        next_hidden = 0\n",
    "                        final_len += layer_size\n",
    "                    field_nums.append(int(layer_size / 2))\n",
    "                    final_result.append(direct_connect)\n",
    "                    cin_layers.append(next_hidden)\n",
    "                # step 3:sum pooling\n",
    "                result = tf.concat(final_result, 1) # None * sum(layer_size) * K\n",
    "                y_cin = tf.reduce_sum(result, -1) # None * sum(layer_size)\n",
    "\n",
    "            # DNN部分\n",
    "            with tf.variable_scope('Deep-part'):\n",
    "                y_deep = tf.reshape(embeddings, shape=[-1, self.fm_fea_size * self.embedding_size])  # None*(F*K)\n",
    "                y_deep = MLP(y_deep, self.dnn_layers)\n",
    "\n",
    "                # 合并\n",
    "            print('y_deep:{}, y_cin:{}'.format(y_deep, y_cin))\n",
    "#             last_input = tf.concat([y_deep], axis=-1) # DNN\n",
    "            last_input = tf.concat([y_deep, y_cin], axis=-1) # xDeepFM\n",
    "\n",
    "            # dense\n",
    "#             self.y_pre = tf.layers.Dense(1, activation=tf.nn.sigmoid,\n",
    "#                                          kernel_initializer=tf.keras.initializers.he_normal())(last_input)  # 二分类\n",
    "            # residual network\n",
    "            with tf.variable_scope('Res-network'):\n",
    "                with tf.variable_scope('Res'):\n",
    "                    res = Res_Network(last_input, self.res_layers)\n",
    "                with tf.variable_scope('MLP'):\n",
    "                    res = MLP(res, [1024, 256, 64])\n",
    "                    print(res)\n",
    "                \n",
    "            self.y_pre = tf.layers.Dense(1, activation=tf.nn.sigmoid,\n",
    "                                         kernel_initializer=tf.keras.initializers.he_normal())(res)  # 二分类\n",
    "\n",
    "            # 损失函数(二分类交叉熵等同于logloss)\n",
    "            self.loss = tf.losses.log_loss(self.label, self.y_pre)  # 二分类\n",
    "\n",
    "            # 优化方法\n",
    "            self.opt = tf.train.AdamOptimizer(self.lr).minimize(self.loss)\n",
    "            self.saver = tf.train.Saver()\n",
    "\n",
    "    def save_model(self, model_path):\n",
    "        self.saver.save(self.sess, model_path)\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        self.saver.restore(self.sess, model_path)\n",
    "\n",
    "    def shuffle_csr_and_list(self, my_array, rng_state):\n",
    "        np.random.set_state(rng_state)\n",
    "        if type(my_array) == csr_matrix:\n",
    "            index = np.arange(np.shape(my_array)[0])\n",
    "            np.random.shuffle(index)\n",
    "            print('shuffle csr_matrix ' + str(my_array.shape))\n",
    "            return my_array[index, :]\n",
    "        else:\n",
    "            np.random.shuffle(my_array)\n",
    "            return my_array\n",
    "\n",
    "    def shuffle(self, cate_feas, conti_feas, labels):\n",
    "        rng_state = np.random.get_state()\n",
    "        cate_feas = self.shuffle_csr_and_list(cate_feas, rng_state)\n",
    "        conti_feas = self.shuffle_csr_and_list(conti_feas, rng_state)\n",
    "        labels = self.shuffle_csr_and_list(labels, rng_state)\n",
    "        return cate_feas, conti_feas, labels\n",
    "\n",
    "    def get_feed_dict(self, cate_feas, conti_feas, labels=None):\n",
    "        feed_dict = {\n",
    "            self.conti_vec: conti_feas,\n",
    "            self.cate_indexs: cate_feas.todense(),\n",
    "        }\n",
    "        if labels is not None:\n",
    "            feed_dict[self.label] = labels\n",
    "        return feed_dict\n",
    "\n",
    "    def gene_data(self, cate_feas, conti_feas, labels, bs, shuffle=False):\n",
    "        if shuffle:\n",
    "            cate_feas, conti_feas, labels = self.shuffle(cate_feas, conti_feas, labels)\n",
    "        bm = math.ceil(cate_feas.shape[0] / bs)\n",
    "        for j in range(bm):\n",
    "            a = cate_feas[j * bs:(j + 1) * bs]\n",
    "            b = conti_feas[j * bs:(j + 1) * bs]\n",
    "            c = labels[j * bs:(j + 1) * bs]\n",
    "            yield a, b, c\n",
    "\n",
    "    def gene_balance_data(self, cate_feas, conti_feas, labels, bs, shuffle=False):\n",
    "        pos_flag = np.array([l[0] == 1 for l in labels])\n",
    "        pos_indexing, neg_indexing = np.arange(len(labels))[pos_flag], np.arange(len(labels))[~pos_flag]\n",
    "        np.random.shuffle(neg_indexing)\n",
    "\n",
    "        bm = math.ceil(sum(~pos_flag) / bs)\n",
    "        for j in range(bm):\n",
    "            need_cnt = int(bs / 2)\n",
    "            crt_indexing = np.random.choice(pos_indexing, need_cnt).tolist() + neg_indexing[\n",
    "                                                                               j * need_cnt:(j + 1) * need_cnt].tolist()\n",
    "\n",
    "            a = cate_feas[crt_indexing, :]\n",
    "            b = np.take(conti_feas, crt_indexing, axis=0)\n",
    "            c = np.take(labels, crt_indexing, axis=0)\n",
    "            yield a, b, c\n",
    "\n",
    "    def fit(self, model_path, batch_size, epoch, cate_feas, conti_feas, labels, v_cate_feas, v_conti_feas, v_labels,\n",
    "            es=5):\n",
    "        print('start training ---------------------------------------------------')\n",
    "        logging.info('start train')\n",
    "        with self.graph.as_default():\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            best_f1 = 0.0  # 二分类\n",
    "            no_num = 0\n",
    "            writer = tf.summary.FileWriter('./logs', self.sess.graph)\n",
    "            for i in range(epoch):\n",
    "                t1 = time()\n",
    "                epoch_losses = []\n",
    "                for cate_feas_batch, conti_feas_batch, labels_batch in self.gene_data(cate_feas, conti_feas,\n",
    "                                                                                      labels, batch_size,\n",
    "                                                                                      shuffle=False):\n",
    "                    feed = self.get_feed_dict(cate_feas_batch, conti_feas_batch, labels_batch)\n",
    "                    loss, _ = self.sess.run([self.loss, self.opt], feed_dict=feed)\n",
    "                    epoch_losses.append(loss)\n",
    "\n",
    "                # 二分类\n",
    "                v_loss, v_f1 = self.eval(batch_size, v_cate_feas, v_conti_feas, v_labels)\n",
    "                t_loss = np.mean(np.array(epoch_losses))\n",
    "                logging.info('epoch: %s---train loss %.4f---valid loss: %.4f---valid f1: %.4f'\n",
    "                             % ((i + 1), t_loss, v_loss, v_f1))\n",
    "                print('epoch: %s---train loss %.4f---valid loss: %.4f---valid f1: %.4f [%.1f s]'\n",
    "                      % ((i + 1), t_loss, v_loss, v_f1, time() - t1))\n",
    "                if v_f1 > best_f1:\n",
    "                    no_num = 0\n",
    "                    self.lr = self.lr * 0.8\n",
    "                    self.save_model(model_path)\n",
    "                    logging.info('---------- f1 from %.4f to %.4f, saving model' % (best_f1, v_f1))\n",
    "                    print('---------- f1 from %.4f to %.4f, saving model' % (best_f1, v_f1))\n",
    "                    best_f1 = v_f1\n",
    "                else:\n",
    "                    no_num += 1\n",
    "                    self.lr = self.lr / 2\n",
    "                    if no_num >= es:\n",
    "                        break\n",
    "\n",
    "    def eval(self, batch_size, cate_feas, conti_feas, labels):\n",
    "        with self.graph.as_default():\n",
    "            y_pre = []\n",
    "            for cate_feas_batch, conti_feas_batch, label_batch in self.gene_data(cate_feas, conti_feas, labels,\n",
    "                                                                                 batch_size, shuffle=False):\n",
    "                feed = self.get_feed_dict(cate_feas_batch, conti_feas_batch, label_batch)\n",
    "                y_ = self.sess.run([self.y_pre], feed_dict=feed)[0]\n",
    "                y_pre += y_.tolist()\n",
    "            y_pre = np.array(y_pre)\n",
    "            # 二分类\n",
    "            y_pre = np.reshape(y_pre, (y_pre.shape[0],))\n",
    "#             print(y_pre)\n",
    "            labels = np.reshape(labels, (labels.shape[0],))\n",
    "            loss = log_loss(labels, y_pre)\n",
    "            f1s = []\n",
    "            for limit in np.arange(0.4, 0.44, 0.01):\n",
    "                pred = [int(i>limit) for i in y_pre]\n",
    "                f1s.append(f1_score(labels, pred))\n",
    "            return loss, max(f1s)\n",
    "\n",
    "    def predict(self, cate_feas, conti_feas, batch_size):\n",
    "        def gd(cate_feas, conti_feas, bs):\n",
    "            bm = math.ceil(len(conti_feas) / bs)\n",
    "            for j in range(bm):\n",
    "                a = cate_feas[j * bs: (j + 1) * bs]\n",
    "                b = conti_feas[j * bs: (j + 1) * bs]\n",
    "                yield a, b\n",
    "\n",
    "        with self.graph.as_default():\n",
    "            y_pre = []\n",
    "            for cate_feas_batch, conti_feas_batch in gd(cate_feas, conti_feas, batch_size):\n",
    "                feed = self.get_feed_dict(cate_feas_batch, conti_feas_batch)\n",
    "                y_ = self.sess.run([self.y_pre], feed_dict=feed)[0]\n",
    "                y_pre += y_.tolist()\n",
    "            y_pre = np.array(y_pre)\n",
    "            y_pre = np.reshape(y_pre, (y_pre.shape[0],))\n",
    "            return y_pre\n",
    "        \n",
    "    def embedding_weights(self):\n",
    "        cate_embeddings, fea_embedding = self.sess.run([self.cate_embeddings, self.fea_embedding])\n",
    "        return cate_embeddings, fea_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usecols = ['register_type', 'device_type', 'user_reg_days', 'user_lastweek_launchday', 'user_last_launch_dist', 'user_hist_launch_freq', 'user_hist_launchday', 'user_mean_continue_launch_times_lastweek', 'user_max_continue_launch_times_lastweek', 'user_activity_days_hist', 'user_activity_days_lastweek', 'user_min_continue_launch_times_lastweek', 'user_mean_continue_launch_days_lastweek', 'user_max_continue_launch_days_lastweek', 'user_mean_continue_activity_days_lastweek', 'user_max_continue_activity_days_lastweek', 'user_lastweek_act_0_freq', 'user_lastweek_actcount', 'user_lastweek_act_video_uniquecount', 'user_max_continue_launch_times_hist', 'user_min_continue_launch_days_lastweek', 'user_mean_continue_launch_times_hist', 'user_min_continue_activity_days_lastweek', 'user_hist_act_0_count', 'user_hist_actcount', 'user_mean_continue_activity_days_hist', 'user_max_continue_launch_days_hist', 'user_hist_act_freq', 'user_mean_continue_launch_days_hist', 'user_hist_act_author_count', 'user_mean_no_launch_days_hist', 'user_min_activity_daytimes_lastweek', 'user_lastweek_act', 'user_lastweek_act_0', 'user_mean_continue_activity_times_hist', 'user_max_launch_daytimes_lastweek', 'user_lastweek_launch', 'user_lastweek_act_page_3_count', 'user_lastweek_act_page_1_count', 'user_max_no_launch_days_hist', 'user_last_act_date', 'user_lastweek_act_2_freq', 'user_lastweek_video_freq', 'user_lastweek_act_2_count', 'user_lastweek_launch_freq', 'user_max_no_activity_days_lastweek_hist_dist', 'user_lastweek_act_page_2_count', 'user_var_continue_activity_times_lastweek', 'user_kurt_continue_activity_days_hist', 'user_launch_range_percent', 'user_activity_div_launch_days_hist', 'user_hist_act_video_meancount', 'user_hist_video_activity_types', 'user_activity_range_percent', 'user_5daybefore_act_page_1_count', 'user_min_continue_activity_times_5daywin', 'user_lastweek_hist_act_3_count_dist', 'user_lastweek_hist_act_page_3_count_dist', 'user_mean_createvideo_date_lastweek_hist_dist', 'user_4daybefore_act_page_4_count', 'user_kurt_no_launch_days_6daywin', 'user_max_continue_createvideo_days_4daywin', 'user_2daybefore_act_1_count', 'user_max_continue_createvideo_days_hist']\n",
    "by = ['user_id', 'data_weeknum']\n",
    "target = ['label']\n",
    "len(usecols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198057, 67)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./features/b/baseline_features12_ab.csv', usecols=usecols+by+target)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cate_feas = ['register_type', 'device_type']\n",
    "conti_feas = list(set(usecols) - set(cate_feas))\n",
    "cate_long_feas = ['device_type']\n",
    "cate_embedding_uni_cnt = {'register_type':12, 'device_type':4760}\n",
    "cate_embedding_uni_cnt_list = [cate_embedding_uni_cnt[i] for i in cate_feas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "conti_cols = conti_feas\n",
    "data = df[conti_cols]\n",
    "for fea in conti_cols:\n",
    "    scaler_val = data[fea][~data[fea].isnull()].values\n",
    "    scaler = StandardScaler().fit(scaler_val.reshape((len(scaler_val), 1)))\n",
    "    data[fea].fillna(scaler.mean_[0], inplace=True)\n",
    "    data[fea] = scaler.transform(data[fea].values.reshape((len(data), 1))).reshape((len(data),)).tolist()\n",
    "df = pd.concat([data, df[cate_feas+by+target]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_feature(values):\n",
    "    uniq = values.unique()\n",
    "    mapping = dict(zip(uniq,range(1,len(uniq) + 1)))\n",
    "    return values.map(mapping)\n",
    "\n",
    "for i in cate_feas:\n",
    "    df[i] = encode_feature(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in list(set(cate_feas) - set(cate_long_feas)):\n",
    "    df = pd.concat([df, pd.get_dummies(df[i], prefix=i)], axis=1)\n",
    "    usecols += list(pd.get_dummies(df[i], prefix=i).columns)\n",
    "    df = df.drop([i], axis=1)\n",
    "    usecols.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198057, 78)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_max_continue_activity_days_lastweek</th>\n",
       "      <th>user_min_continue_activity_days_lastweek</th>\n",
       "      <th>user_mean_continue_launch_times_lastweek</th>\n",
       "      <th>user_max_no_launch_days_hist</th>\n",
       "      <th>user_lastweek_act_video_uniquecount</th>\n",
       "      <th>user_lastweek_launchday</th>\n",
       "      <th>user_launch_range_percent</th>\n",
       "      <th>user_lastweek_actcount</th>\n",
       "      <th>user_max_continue_launch_times_hist</th>\n",
       "      <th>user_mean_no_launch_days_hist</th>\n",
       "      <th>user_var_continue_activity_times_lastweek</th>\n",
       "      <th>user_max_launch_daytimes_lastweek</th>\n",
       "      <th>user_lastweek_act_page_3_count</th>\n",
       "      <th>user_mean_continue_launch_days_hist</th>\n",
       "      <th>user_lastweek_video_freq</th>\n",
       "      <th>user_max_no_activity_days_lastweek_hist_dist</th>\n",
       "      <th>user_reg_days</th>\n",
       "      <th>user_hist_launchday</th>\n",
       "      <th>user_mean_continue_launch_times_hist</th>\n",
       "      <th>user_hist_act_author_count</th>\n",
       "      <th>user_hist_act_freq</th>\n",
       "      <th>user_4daybefore_act_page_4_count</th>\n",
       "      <th>user_max_continue_launch_days_hist</th>\n",
       "      <th>user_activity_days_hist</th>\n",
       "      <th>user_min_activity_daytimes_lastweek</th>\n",
       "      <th>user_lastweek_act_2_count</th>\n",
       "      <th>user_lastweek_act_0_freq</th>\n",
       "      <th>user_max_continue_createvideo_days_hist</th>\n",
       "      <th>user_mean_continue_activity_days_lastweek</th>\n",
       "      <th>user_lastweek_act</th>\n",
       "      <th>user_hist_actcount</th>\n",
       "      <th>user_lastweek_act_page_1_count</th>\n",
       "      <th>user_mean_continue_activity_days_hist</th>\n",
       "      <th>user_last_launch_dist</th>\n",
       "      <th>user_2daybefore_act_1_count</th>\n",
       "      <th>user_hist_act_0_count</th>\n",
       "      <th>user_lastweek_act_2_freq</th>\n",
       "      <th>user_min_continue_launch_times_lastweek</th>\n",
       "      <th>user_mean_continue_launch_days_lastweek</th>\n",
       "      <th>user_hist_launch_freq</th>\n",
       "      <th>user_activity_days_lastweek</th>\n",
       "      <th>user_lastweek_launch</th>\n",
       "      <th>user_lastweek_act_0</th>\n",
       "      <th>user_activity_div_launch_days_hist</th>\n",
       "      <th>user_mean_continue_activity_times_hist</th>\n",
       "      <th>user_last_act_date</th>\n",
       "      <th>user_hist_act_video_meancount</th>\n",
       "      <th>user_kurt_continue_activity_days_hist</th>\n",
       "      <th>user_5daybefore_act_page_1_count</th>\n",
       "      <th>user_lastweek_hist_act_3_count_dist</th>\n",
       "      <th>user_max_continue_createvideo_days_4daywin</th>\n",
       "      <th>user_kurt_no_launch_days_6daywin</th>\n",
       "      <th>user_lastweek_act_page_2_count</th>\n",
       "      <th>user_lastweek_launch_freq</th>\n",
       "      <th>user_max_continue_launch_days_lastweek</th>\n",
       "      <th>user_mean_createvideo_date_lastweek_hist_dist</th>\n",
       "      <th>user_min_continue_activity_times_5daywin</th>\n",
       "      <th>user_hist_video_activity_types</th>\n",
       "      <th>user_lastweek_hist_act_page_3_count_dist</th>\n",
       "      <th>user_min_continue_launch_days_lastweek</th>\n",
       "      <th>user_max_continue_launch_times_lastweek</th>\n",
       "      <th>user_activity_range_percent</th>\n",
       "      <th>device_type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>data_weeknum</th>\n",
       "      <th>label</th>\n",
       "      <th>register_type_1</th>\n",
       "      <th>register_type_2</th>\n",
       "      <th>register_type_3</th>\n",
       "      <th>register_type_4</th>\n",
       "      <th>register_type_5</th>\n",
       "      <th>register_type_6</th>\n",
       "      <th>register_type_7</th>\n",
       "      <th>register_type_8</th>\n",
       "      <th>register_type_9</th>\n",
       "      <th>register_type_10</th>\n",
       "      <th>register_type_11</th>\n",
       "      <th>register_type_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.247543</td>\n",
       "      <td>0.349208</td>\n",
       "      <td>0.379038</td>\n",
       "      <td>1.498626</td>\n",
       "      <td>-0.206576</td>\n",
       "      <td>-0.009945</td>\n",
       "      <td>1.034716</td>\n",
       "      <td>-0.249634</td>\n",
       "      <td>-0.045693</td>\n",
       "      <td>1.242095</td>\n",
       "      <td>-0.076443</td>\n",
       "      <td>1.004443</td>\n",
       "      <td>-0.315589</td>\n",
       "      <td>-0.335039</td>\n",
       "      <td>-0.166874</td>\n",
       "      <td>-1.638500</td>\n",
       "      <td>-0.17852</td>\n",
       "      <td>-0.215638</td>\n",
       "      <td>-0.064201</td>\n",
       "      <td>-0.108227</td>\n",
       "      <td>-0.343108</td>\n",
       "      <td>-0.073178</td>\n",
       "      <td>-0.278441</td>\n",
       "      <td>-0.094740</td>\n",
       "      <td>-0.185099</td>\n",
       "      <td>-0.238821</td>\n",
       "      <td>-0.318459</td>\n",
       "      <td>-0.293678</td>\n",
       "      <td>0.302160</td>\n",
       "      <td>0.770586</td>\n",
       "      <td>-0.281889</td>\n",
       "      <td>-0.281456</td>\n",
       "      <td>-0.219169</td>\n",
       "      <td>-0.609325</td>\n",
       "      <td>-0.131104</td>\n",
       "      <td>-0.276376</td>\n",
       "      <td>-0.210116</td>\n",
       "      <td>0.422373</td>\n",
       "      <td>0.158963</td>\n",
       "      <td>-0.409600</td>\n",
       "      <td>0.124359</td>\n",
       "      <td>0.614676</td>\n",
       "      <td>0.770660</td>\n",
       "      <td>0.588383</td>\n",
       "      <td>-0.269638</td>\n",
       "      <td>-0.661824</td>\n",
       "      <td>-0.059767</td>\n",
       "      <td>-0.320314</td>\n",
       "      <td>-0.187274</td>\n",
       "      <td>0.124720</td>\n",
       "      <td>-0.228157</td>\n",
       "      <td>-0.609547</td>\n",
       "      <td>-0.266604</td>\n",
       "      <td>-0.365386</td>\n",
       "      <td>0.107558</td>\n",
       "      <td>0.164084</td>\n",
       "      <td>-0.151078</td>\n",
       "      <td>-0.3402</td>\n",
       "      <td>0.246627</td>\n",
       "      <td>0.205738</td>\n",
       "      <td>0.329071</td>\n",
       "      <td>1.176723</td>\n",
       "      <td>1</td>\n",
       "      <td>744025_a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.806428</td>\n",
       "      <td>-0.748524</td>\n",
       "      <td>-0.490522</td>\n",
       "      <td>-0.313167</td>\n",
       "      <td>-0.438637</td>\n",
       "      <td>-0.956922</td>\n",
       "      <td>-0.734030</td>\n",
       "      <td>-0.435995</td>\n",
       "      <td>-0.045693</td>\n",
       "      <td>-0.120225</td>\n",
       "      <td>-0.076443</td>\n",
       "      <td>-0.190467</td>\n",
       "      <td>-0.326267</td>\n",
       "      <td>-0.166620</td>\n",
       "      <td>-0.166874</td>\n",
       "      <td>0.312403</td>\n",
       "      <td>-0.17852</td>\n",
       "      <td>-0.446747</td>\n",
       "      <td>0.079728</td>\n",
       "      <td>-0.389216</td>\n",
       "      <td>-0.384640</td>\n",
       "      <td>-0.073178</td>\n",
       "      <td>-0.278441</td>\n",
       "      <td>-0.334261</td>\n",
       "      <td>-0.327347</td>\n",
       "      <td>-0.238821</td>\n",
       "      <td>-0.464357</td>\n",
       "      <td>-0.293678</td>\n",
       "      <td>-0.787085</td>\n",
       "      <td>-1.297714</td>\n",
       "      <td>-0.317967</td>\n",
       "      <td>-0.281456</td>\n",
       "      <td>-0.038162</td>\n",
       "      <td>0.397620</td>\n",
       "      <td>-0.131104</td>\n",
       "      <td>-0.316652</td>\n",
       "      <td>-0.210116</td>\n",
       "      <td>-0.456650</td>\n",
       "      <td>-0.882014</td>\n",
       "      <td>-0.736365</td>\n",
       "      <td>-0.847477</td>\n",
       "      <td>-1.626874</td>\n",
       "      <td>-1.297588</td>\n",
       "      <td>0.588383</td>\n",
       "      <td>-0.218673</td>\n",
       "      <td>-1.288577</td>\n",
       "      <td>0.049961</td>\n",
       "      <td>-0.320314</td>\n",
       "      <td>-0.187274</td>\n",
       "      <td>-1.211189</td>\n",
       "      <td>-0.228157</td>\n",
       "      <td>1.440857</td>\n",
       "      <td>-0.266604</td>\n",
       "      <td>-1.117730</td>\n",
       "      <td>-0.905890</td>\n",
       "      <td>0.164084</td>\n",
       "      <td>-0.392555</td>\n",
       "      <td>-0.3402</td>\n",
       "      <td>0.164714</td>\n",
       "      <td>-0.836967</td>\n",
       "      <td>-0.516170</td>\n",
       "      <td>-0.611905</td>\n",
       "      <td>2</td>\n",
       "      <td>1270299_a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.806428</td>\n",
       "      <td>-0.748524</td>\n",
       "      <td>-0.490522</td>\n",
       "      <td>-0.313167</td>\n",
       "      <td>-0.438637</td>\n",
       "      <td>-0.956922</td>\n",
       "      <td>-0.734030</td>\n",
       "      <td>-0.435995</td>\n",
       "      <td>-0.045693</td>\n",
       "      <td>-0.120225</td>\n",
       "      <td>-0.076443</td>\n",
       "      <td>-0.190467</td>\n",
       "      <td>-0.326267</td>\n",
       "      <td>-0.166620</td>\n",
       "      <td>-0.166874</td>\n",
       "      <td>0.312403</td>\n",
       "      <td>-0.17852</td>\n",
       "      <td>-0.446747</td>\n",
       "      <td>0.079728</td>\n",
       "      <td>-0.293182</td>\n",
       "      <td>-0.407004</td>\n",
       "      <td>-0.073178</td>\n",
       "      <td>-0.278441</td>\n",
       "      <td>-0.334261</td>\n",
       "      <td>-0.327347</td>\n",
       "      <td>-0.238821</td>\n",
       "      <td>-0.464357</td>\n",
       "      <td>-0.293678</td>\n",
       "      <td>-0.787085</td>\n",
       "      <td>-1.297714</td>\n",
       "      <td>-0.337394</td>\n",
       "      <td>-0.281456</td>\n",
       "      <td>-0.038162</td>\n",
       "      <td>0.397620</td>\n",
       "      <td>-0.131104</td>\n",
       "      <td>-0.332474</td>\n",
       "      <td>-0.210116</td>\n",
       "      <td>-0.456650</td>\n",
       "      <td>-0.882014</td>\n",
       "      <td>-0.736365</td>\n",
       "      <td>-0.847477</td>\n",
       "      <td>-1.626874</td>\n",
       "      <td>-1.297588</td>\n",
       "      <td>0.588383</td>\n",
       "      <td>-0.242859</td>\n",
       "      <td>-1.288577</td>\n",
       "      <td>-0.040997</td>\n",
       "      <td>-0.320314</td>\n",
       "      <td>-0.187274</td>\n",
       "      <td>0.124720</td>\n",
       "      <td>-0.228157</td>\n",
       "      <td>1.440857</td>\n",
       "      <td>-0.266604</td>\n",
       "      <td>-1.117730</td>\n",
       "      <td>-0.905890</td>\n",
       "      <td>0.164084</td>\n",
       "      <td>-0.392555</td>\n",
       "      <td>-0.3402</td>\n",
       "      <td>0.173815</td>\n",
       "      <td>-0.836967</td>\n",
       "      <td>-0.516170</td>\n",
       "      <td>-0.611905</td>\n",
       "      <td>3</td>\n",
       "      <td>571220_a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.279443</td>\n",
       "      <td>-0.199658</td>\n",
       "      <td>-0.055742</td>\n",
       "      <td>0.049192</td>\n",
       "      <td>-0.363559</td>\n",
       "      <td>-0.009945</td>\n",
       "      <td>0.150343</td>\n",
       "      <td>-0.278507</td>\n",
       "      <td>0.206990</td>\n",
       "      <td>0.061418</td>\n",
       "      <td>-0.069360</td>\n",
       "      <td>1.004443</td>\n",
       "      <td>-0.144741</td>\n",
       "      <td>-0.166620</td>\n",
       "      <td>-0.166874</td>\n",
       "      <td>0.312403</td>\n",
       "      <td>-0.17852</td>\n",
       "      <td>0.015471</td>\n",
       "      <td>0.079728</td>\n",
       "      <td>-0.421227</td>\n",
       "      <td>-0.295185</td>\n",
       "      <td>-0.073178</td>\n",
       "      <td>0.013898</td>\n",
       "      <td>0.144782</td>\n",
       "      <td>0.070947</td>\n",
       "      <td>-0.238821</td>\n",
       "      <td>-0.378903</td>\n",
       "      <td>-0.293678</td>\n",
       "      <td>-0.242462</td>\n",
       "      <td>0.770586</td>\n",
       "      <td>-0.240261</td>\n",
       "      <td>0.160326</td>\n",
       "      <td>-0.038162</td>\n",
       "      <td>-0.105852</td>\n",
       "      <td>-0.131104</td>\n",
       "      <td>-0.257677</td>\n",
       "      <td>-0.210116</td>\n",
       "      <td>-0.017138</td>\n",
       "      <td>-0.361526</td>\n",
       "      <td>-0.082835</td>\n",
       "      <td>0.124359</td>\n",
       "      <td>0.614676</td>\n",
       "      <td>0.770660</td>\n",
       "      <td>0.588383</td>\n",
       "      <td>-0.243723</td>\n",
       "      <td>-0.975201</td>\n",
       "      <td>1.445931</td>\n",
       "      <td>-0.320314</td>\n",
       "      <td>1.156722</td>\n",
       "      <td>0.124720</td>\n",
       "      <td>-0.228157</td>\n",
       "      <td>-0.609547</td>\n",
       "      <td>-0.266604</td>\n",
       "      <td>-0.365386</td>\n",
       "      <td>-0.399166</td>\n",
       "      <td>0.164084</td>\n",
       "      <td>-0.344940</td>\n",
       "      <td>-0.3402</td>\n",
       "      <td>0.087352</td>\n",
       "      <td>-0.315615</td>\n",
       "      <td>-0.093549</td>\n",
       "      <td>0.282409</td>\n",
       "      <td>4</td>\n",
       "      <td>1308501_a</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.774528</td>\n",
       "      <td>0.898074</td>\n",
       "      <td>1.248598</td>\n",
       "      <td>0.049192</td>\n",
       "      <td>-0.380622</td>\n",
       "      <td>0.937032</td>\n",
       "      <td>0.739925</td>\n",
       "      <td>-0.367750</td>\n",
       "      <td>0.459673</td>\n",
       "      <td>-0.011239</td>\n",
       "      <td>-0.076443</td>\n",
       "      <td>1.004443</td>\n",
       "      <td>-0.326267</td>\n",
       "      <td>0.170219</td>\n",
       "      <td>-0.166874</td>\n",
       "      <td>-0.467958</td>\n",
       "      <td>-0.17852</td>\n",
       "      <td>0.477688</td>\n",
       "      <td>0.367587</td>\n",
       "      <td>-0.378545</td>\n",
       "      <td>-0.470900</td>\n",
       "      <td>-0.073178</td>\n",
       "      <td>0.306238</td>\n",
       "      <td>0.384303</td>\n",
       "      <td>-0.241998</td>\n",
       "      <td>-0.096063</td>\n",
       "      <td>-0.414335</td>\n",
       "      <td>-0.293678</td>\n",
       "      <td>0.846782</td>\n",
       "      <td>0.770586</td>\n",
       "      <td>-0.392898</td>\n",
       "      <td>-0.281456</td>\n",
       "      <td>0.142846</td>\n",
       "      <td>-0.441500</td>\n",
       "      <td>-0.131104</td>\n",
       "      <td>-0.391449</td>\n",
       "      <td>-0.132553</td>\n",
       "      <td>1.301396</td>\n",
       "      <td>1.199941</td>\n",
       "      <td>0.570694</td>\n",
       "      <td>0.610277</td>\n",
       "      <td>0.614676</td>\n",
       "      <td>0.770660</td>\n",
       "      <td>0.126150</td>\n",
       "      <td>-0.338743</td>\n",
       "      <td>-0.766283</td>\n",
       "      <td>0.096189</td>\n",
       "      <td>-0.320314</td>\n",
       "      <td>-0.187274</td>\n",
       "      <td>0.124720</td>\n",
       "      <td>-0.228157</td>\n",
       "      <td>-0.609547</td>\n",
       "      <td>0.190579</td>\n",
       "      <td>0.386958</td>\n",
       "      <td>1.121006</td>\n",
       "      <td>0.164084</td>\n",
       "      <td>-0.304127</td>\n",
       "      <td>-0.3402</td>\n",
       "      <td>0.246627</td>\n",
       "      <td>1.248444</td>\n",
       "      <td>1.174313</td>\n",
       "      <td>0.878618</td>\n",
       "      <td>5</td>\n",
       "      <td>745554_a</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_max_continue_activity_days_lastweek  \\\n",
       "0                                  0.247543   \n",
       "1                                 -0.806428   \n",
       "2                                 -0.806428   \n",
       "3                                 -0.279443   \n",
       "4                                  0.774528   \n",
       "\n",
       "   user_min_continue_activity_days_lastweek  \\\n",
       "0                                  0.349208   \n",
       "1                                 -0.748524   \n",
       "2                                 -0.748524   \n",
       "3                                 -0.199658   \n",
       "4                                  0.898074   \n",
       "\n",
       "   user_mean_continue_launch_times_lastweek  user_max_no_launch_days_hist  \\\n",
       "0                                  0.379038                      1.498626   \n",
       "1                                 -0.490522                     -0.313167   \n",
       "2                                 -0.490522                     -0.313167   \n",
       "3                                 -0.055742                      0.049192   \n",
       "4                                  1.248598                      0.049192   \n",
       "\n",
       "   user_lastweek_act_video_uniquecount  user_lastweek_launchday  \\\n",
       "0                            -0.206576                -0.009945   \n",
       "1                            -0.438637                -0.956922   \n",
       "2                            -0.438637                -0.956922   \n",
       "3                            -0.363559                -0.009945   \n",
       "4                            -0.380622                 0.937032   \n",
       "\n",
       "   user_launch_range_percent  user_lastweek_actcount  \\\n",
       "0                   1.034716               -0.249634   \n",
       "1                  -0.734030               -0.435995   \n",
       "2                  -0.734030               -0.435995   \n",
       "3                   0.150343               -0.278507   \n",
       "4                   0.739925               -0.367750   \n",
       "\n",
       "   user_max_continue_launch_times_hist  user_mean_no_launch_days_hist  \\\n",
       "0                            -0.045693                       1.242095   \n",
       "1                            -0.045693                      -0.120225   \n",
       "2                            -0.045693                      -0.120225   \n",
       "3                             0.206990                       0.061418   \n",
       "4                             0.459673                      -0.011239   \n",
       "\n",
       "   user_var_continue_activity_times_lastweek  \\\n",
       "0                                  -0.076443   \n",
       "1                                  -0.076443   \n",
       "2                                  -0.076443   \n",
       "3                                  -0.069360   \n",
       "4                                  -0.076443   \n",
       "\n",
       "   user_max_launch_daytimes_lastweek  user_lastweek_act_page_3_count  \\\n",
       "0                           1.004443                       -0.315589   \n",
       "1                          -0.190467                       -0.326267   \n",
       "2                          -0.190467                       -0.326267   \n",
       "3                           1.004443                       -0.144741   \n",
       "4                           1.004443                       -0.326267   \n",
       "\n",
       "   user_mean_continue_launch_days_hist  user_lastweek_video_freq  \\\n",
       "0                            -0.335039                 -0.166874   \n",
       "1                            -0.166620                 -0.166874   \n",
       "2                            -0.166620                 -0.166874   \n",
       "3                            -0.166620                 -0.166874   \n",
       "4                             0.170219                 -0.166874   \n",
       "\n",
       "   user_max_no_activity_days_lastweek_hist_dist  user_reg_days  \\\n",
       "0                                     -1.638500       -0.17852   \n",
       "1                                      0.312403       -0.17852   \n",
       "2                                      0.312403       -0.17852   \n",
       "3                                      0.312403       -0.17852   \n",
       "4                                     -0.467958       -0.17852   \n",
       "\n",
       "   user_hist_launchday  user_mean_continue_launch_times_hist  \\\n",
       "0            -0.215638                             -0.064201   \n",
       "1            -0.446747                              0.079728   \n",
       "2            -0.446747                              0.079728   \n",
       "3             0.015471                              0.079728   \n",
       "4             0.477688                              0.367587   \n",
       "\n",
       "   user_hist_act_author_count  user_hist_act_freq  \\\n",
       "0                   -0.108227           -0.343108   \n",
       "1                   -0.389216           -0.384640   \n",
       "2                   -0.293182           -0.407004   \n",
       "3                   -0.421227           -0.295185   \n",
       "4                   -0.378545           -0.470900   \n",
       "\n",
       "   user_4daybefore_act_page_4_count  user_max_continue_launch_days_hist  \\\n",
       "0                         -0.073178                           -0.278441   \n",
       "1                         -0.073178                           -0.278441   \n",
       "2                         -0.073178                           -0.278441   \n",
       "3                         -0.073178                            0.013898   \n",
       "4                         -0.073178                            0.306238   \n",
       "\n",
       "   user_activity_days_hist  user_min_activity_daytimes_lastweek  \\\n",
       "0                -0.094740                            -0.185099   \n",
       "1                -0.334261                            -0.327347   \n",
       "2                -0.334261                            -0.327347   \n",
       "3                 0.144782                             0.070947   \n",
       "4                 0.384303                            -0.241998   \n",
       "\n",
       "   user_lastweek_act_2_count  user_lastweek_act_0_freq  \\\n",
       "0                  -0.238821                 -0.318459   \n",
       "1                  -0.238821                 -0.464357   \n",
       "2                  -0.238821                 -0.464357   \n",
       "3                  -0.238821                 -0.378903   \n",
       "4                  -0.096063                 -0.414335   \n",
       "\n",
       "   user_max_continue_createvideo_days_hist  \\\n",
       "0                                -0.293678   \n",
       "1                                -0.293678   \n",
       "2                                -0.293678   \n",
       "3                                -0.293678   \n",
       "4                                -0.293678   \n",
       "\n",
       "   user_mean_continue_activity_days_lastweek  user_lastweek_act  \\\n",
       "0                                   0.302160           0.770586   \n",
       "1                                  -0.787085          -1.297714   \n",
       "2                                  -0.787085          -1.297714   \n",
       "3                                  -0.242462           0.770586   \n",
       "4                                   0.846782           0.770586   \n",
       "\n",
       "   user_hist_actcount  user_lastweek_act_page_1_count  \\\n",
       "0           -0.281889                       -0.281456   \n",
       "1           -0.317967                       -0.281456   \n",
       "2           -0.337394                       -0.281456   \n",
       "3           -0.240261                        0.160326   \n",
       "4           -0.392898                       -0.281456   \n",
       "\n",
       "   user_mean_continue_activity_days_hist  user_last_launch_dist  \\\n",
       "0                              -0.219169              -0.609325   \n",
       "1                              -0.038162               0.397620   \n",
       "2                              -0.038162               0.397620   \n",
       "3                              -0.038162              -0.105852   \n",
       "4                               0.142846              -0.441500   \n",
       "\n",
       "   user_2daybefore_act_1_count  user_hist_act_0_count  \\\n",
       "0                    -0.131104              -0.276376   \n",
       "1                    -0.131104              -0.316652   \n",
       "2                    -0.131104              -0.332474   \n",
       "3                    -0.131104              -0.257677   \n",
       "4                    -0.131104              -0.391449   \n",
       "\n",
       "   user_lastweek_act_2_freq  user_min_continue_launch_times_lastweek  \\\n",
       "0                 -0.210116                                 0.422373   \n",
       "1                 -0.210116                                -0.456650   \n",
       "2                 -0.210116                                -0.456650   \n",
       "3                 -0.210116                                -0.017138   \n",
       "4                 -0.132553                                 1.301396   \n",
       "\n",
       "   user_mean_continue_launch_days_lastweek  user_hist_launch_freq  \\\n",
       "0                                 0.158963              -0.409600   \n",
       "1                                -0.882014              -0.736365   \n",
       "2                                -0.882014              -0.736365   \n",
       "3                                -0.361526              -0.082835   \n",
       "4                                 1.199941               0.570694   \n",
       "\n",
       "   user_activity_days_lastweek  user_lastweek_launch  user_lastweek_act_0  \\\n",
       "0                     0.124359              0.614676             0.770660   \n",
       "1                    -0.847477             -1.626874            -1.297588   \n",
       "2                    -0.847477             -1.626874            -1.297588   \n",
       "3                     0.124359              0.614676             0.770660   \n",
       "4                     0.610277              0.614676             0.770660   \n",
       "\n",
       "   user_activity_div_launch_days_hist  user_mean_continue_activity_times_hist  \\\n",
       "0                            0.588383                               -0.269638   \n",
       "1                            0.588383                               -0.218673   \n",
       "2                            0.588383                               -0.242859   \n",
       "3                            0.588383                               -0.243723   \n",
       "4                            0.126150                               -0.338743   \n",
       "\n",
       "   user_last_act_date  user_hist_act_video_meancount  \\\n",
       "0           -0.661824                      -0.059767   \n",
       "1           -1.288577                       0.049961   \n",
       "2           -1.288577                      -0.040997   \n",
       "3           -0.975201                       1.445931   \n",
       "4           -0.766283                       0.096189   \n",
       "\n",
       "   user_kurt_continue_activity_days_hist  user_5daybefore_act_page_1_count  \\\n",
       "0                              -0.320314                         -0.187274   \n",
       "1                              -0.320314                         -0.187274   \n",
       "2                              -0.320314                         -0.187274   \n",
       "3                              -0.320314                          1.156722   \n",
       "4                              -0.320314                         -0.187274   \n",
       "\n",
       "   user_lastweek_hist_act_3_count_dist  \\\n",
       "0                             0.124720   \n",
       "1                            -1.211189   \n",
       "2                             0.124720   \n",
       "3                             0.124720   \n",
       "4                             0.124720   \n",
       "\n",
       "   user_max_continue_createvideo_days_4daywin  \\\n",
       "0                                   -0.228157   \n",
       "1                                   -0.228157   \n",
       "2                                   -0.228157   \n",
       "3                                   -0.228157   \n",
       "4                                   -0.228157   \n",
       "\n",
       "   user_kurt_no_launch_days_6daywin  user_lastweek_act_page_2_count  \\\n",
       "0                         -0.609547                       -0.266604   \n",
       "1                          1.440857                       -0.266604   \n",
       "2                          1.440857                       -0.266604   \n",
       "3                         -0.609547                       -0.266604   \n",
       "4                         -0.609547                        0.190579   \n",
       "\n",
       "   user_lastweek_launch_freq  user_max_continue_launch_days_lastweek  \\\n",
       "0                  -0.365386                                0.107558   \n",
       "1                  -1.117730                               -0.905890   \n",
       "2                  -1.117730                               -0.905890   \n",
       "3                  -0.365386                               -0.399166   \n",
       "4                   0.386958                                1.121006   \n",
       "\n",
       "   user_mean_createvideo_date_lastweek_hist_dist  \\\n",
       "0                                       0.164084   \n",
       "1                                       0.164084   \n",
       "2                                       0.164084   \n",
       "3                                       0.164084   \n",
       "4                                       0.164084   \n",
       "\n",
       "   user_min_continue_activity_times_5daywin  user_hist_video_activity_types  \\\n",
       "0                                 -0.151078                         -0.3402   \n",
       "1                                 -0.392555                         -0.3402   \n",
       "2                                 -0.392555                         -0.3402   \n",
       "3                                 -0.344940                         -0.3402   \n",
       "4                                 -0.304127                         -0.3402   \n",
       "\n",
       "   user_lastweek_hist_act_page_3_count_dist  \\\n",
       "0                                  0.246627   \n",
       "1                                  0.164714   \n",
       "2                                  0.173815   \n",
       "3                                  0.087352   \n",
       "4                                  0.246627   \n",
       "\n",
       "   user_min_continue_launch_days_lastweek  \\\n",
       "0                                0.205738   \n",
       "1                               -0.836967   \n",
       "2                               -0.836967   \n",
       "3                               -0.315615   \n",
       "4                                1.248444   \n",
       "\n",
       "   user_max_continue_launch_times_lastweek  user_activity_range_percent  \\\n",
       "0                                 0.329071                     1.176723   \n",
       "1                                -0.516170                    -0.611905   \n",
       "2                                -0.516170                    -0.611905   \n",
       "3                                -0.093549                     0.282409   \n",
       "4                                 1.174313                     0.878618   \n",
       "\n",
       "   device_type    user_id  data_weeknum  label  register_type_1  \\\n",
       "0            1   744025_a             0      0                1   \n",
       "1            2  1270299_a             0      0                1   \n",
       "2            3   571220_a             0      0                1   \n",
       "3            4  1308501_a             0      1                0   \n",
       "4            5   745554_a             0      1                0   \n",
       "\n",
       "   register_type_2  register_type_3  register_type_4  register_type_5  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                1                0                0                0   \n",
       "4                0                1                0                0   \n",
       "\n",
       "   register_type_6  register_type_7  register_type_8  register_type_9  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   register_type_10  register_type_11  register_type_12  \n",
       "0                 0                 0                 0  \n",
       "1                 0                 0                 0  \n",
       "2                 0                 0                 0  \n",
       "3                 0                 0                 0  \n",
       "4                 0                 0                 0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df['device_type'] = df['device_type'].apply(lambda x:2385 if x > 2384 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['user_id'] = df.user_id.astype(str)\n",
    "\n",
    "train = df[(df.data_weeknum < df.data_weeknum.max()-1)]\n",
    "val = df[(df.data_weeknum == df.data_weeknum.max()-1) & (df.user_id.map(lambda x:'_a' not in x))]\n",
    "test = df[df.data_weeknum == df.data_weeknum.max()]\n",
    "trainval = df[df.data_weeknum <df.data_weeknum.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全离散化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 连续特征转排名\n",
    "for fea in tqdm_notebook(usecols):\n",
    "    uniq = df[fea].unique()\n",
    "    uniq = sorted(uniq, reverse=True)\n",
    "    mapping = dict(zip(uniq, range(1,len(uniq) + 1)))\n",
    "    df[fea] = df[fea].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cate_feas = usecols\n",
    "conti_feas = []\n",
    "cate_long_feas = usecols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_uni_cnt_dict():\n",
    "    tmp_dict = {}\n",
    "    for i in cate_feas:\n",
    "        tmp_dict[i] = max(df[i])\n",
    "    return tmp_dict\n",
    "\n",
    "cate_embedding_uni_cnt = get_uni_cnt_dict()\n",
    "cate_embedding_uni_cnt_list = [cate_embedding_uni_cnt[i] for i in cate_feas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = df[(df.data_weeknum < df.data_weeknum.max()-1)] #& (df.data_weeknum>0)]\n",
    "val = df[df.data_weeknum == df.data_weeknum.max()-1]\n",
    "test = df[df.data_weeknum == df.data_weeknum.max()]\n",
    "trainval = df[df.data_weeknum <df.data_weeknum.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val = train[usecols], val[usecols]\n",
    "y_train, y_val = train['label'], val['label']\n",
    "\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_val.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_val.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_ori_cate_feas(data_list, cate_feas):\n",
    "    format_data_list = []\n",
    "    offset = 0\n",
    "    for ii, i in enumerate(cate_feas):\n",
    "        rows, cols, data = [], [], []\n",
    "        tmp_len = cate_embedding_uni_cnt[i]\n",
    "        for j in range(data_list.shape[0]):\n",
    "            if(df[i][j] != 0):\n",
    "                rows += [j]\n",
    "                cols += [data_list[i][j]-1]\n",
    "                data += [1]\n",
    "        if ii == 0:\n",
    "            tmp_csr = csr_matrix((data, (rows, cols)), shape=(data_list.shape[0], tmp_len))\n",
    "        else:\n",
    "            tmp_csr = hstack([tmp_csr, csr_matrix((data, (rows, cols)), shape=(data_list.shape[0], tmp_len))])\n",
    "    return tmp_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading conti data...\n",
      "train conti feas shape: (71796, 62), val conti feas shape: (37335, 62)\n",
      "loading ori cate data...\n",
      "train cate shape:(71796, 4772), val cate shape:(37335, 4772)\n",
      "training...\n",
      "y_deep:Tensor(\"Deep-part/Relu_2:0\", shape=(?, 128), dtype=float32), y_cin:Tensor(\"CIN-part/Sum:0\", shape=(?, 120), dtype=float32)\n",
      "Tensor(\"Res-network/MLP/Relu_2:0\", shape=(?, 64), dtype=float32)\n",
      "start training ---------------------------------------------------\n",
      "epoch: 1---train loss 0.5619---valid loss: 0.4556---valid f1: 0.8035 [7.4 s]\n",
      "---------- f1 from 0.0000 to 0.8035, saving model\n",
      "epoch: 2---train loss 0.4610---valid loss: 0.4429---valid f1: 0.8049 [6.7 s]\n",
      "---------- f1 from 0.8035 to 0.8049, saving model\n",
      "epoch: 3---train loss 0.4491---valid loss: 0.4406---valid f1: 0.8049 [6.9 s]\n",
      "epoch: 4---train loss 0.4449---valid loss: 0.4490---valid f1: 0.8055 [6.9 s]\n",
      "---------- f1 from 0.8049 to 0.8055, saving model\n",
      "epoch: 5---train loss 0.4402---valid loss: 0.4523---valid f1: 0.8062 [6.9 s]\n",
      "---------- f1 from 0.8055 to 0.8062, saving model\n",
      "epoch: 6---train loss 0.4354---valid loss: 0.4572---valid f1: 0.8052 [7.3 s]\n",
      "epoch: 7---train loss 0.4312---valid loss: 0.4613---valid f1: 0.8048 [7.0 s]\n"
     ]
    }
   ],
   "source": [
    "print('loading conti data...')\n",
    "# train_conti_feas, val_conti_feas = X_train[conti_feas].as_matrix(), X_val[conti_feas].as_matrix()\n",
    "print('train conti feas shape: {}, val conti feas shape: {}'.format(np.shape(train_conti_feas),\n",
    "                                                                    np.shape(val_conti_feas)))\n",
    "\n",
    "print('loading ori cate data...')\n",
    "# train_cate_csr = build_ori_cate_feas(X_train, cate_long_feas)\n",
    "# train_cate_csr = hstack([train_cate_csr, csr_matrix(X_train.iloc[:, -sum([cate_embedding_uni_cnt[i] for i in list(set(cate_feas)-set(cate_long_feas))]):].as_matrix())])\n",
    "# train_cate_csr = csr_matrix(train_cate_csr)\n",
    "# val_cate_csr = build_ori_cate_feas(X_val, cate_long_feas)\n",
    "# val_cate_csr = hstack([val_cate_csr, csr_matrix(X_val.iloc[:, -sum([cate_embedding_uni_cnt[i] for i in list(set(cate_feas)-set(cate_long_feas))]):].as_matrix())])\n",
    "# val_cate_csr = csr_matrix(val_cate_csr)\n",
    "print('train cate shape:{}, val cate shape:{}'.format(train_cate_csr.shape, val_cate_csr.shape))\n",
    "\n",
    "print('training...')\n",
    "model_name = 'kuaishou'\n",
    "cate_embedding_w_list, fm_embedding_w = None, None\n",
    "\n",
    "dcfn_params = {\n",
    "    'learning_rate': 0.0005,\n",
    "    'embedding_size': 8,\n",
    "    'dnn_layers': [2048, 512, 128],\n",
    "    'cross_layers': [60, 60, 60],\n",
    "    'res_layers': [128, 64, 32],\n",
    "    'conti_fea_cnt': train_conti_feas.shape[1],\n",
    "    'cate_embedding_uni_cnt_list': cate_embedding_uni_cnt_list,\n",
    "    'cate_embedding_w_list': cate_embedding_w_list,\n",
    "    'fm_embedding_w': fm_embedding_w\n",
    "}\n",
    "model = xDeepFM(**dcfn_params)\n",
    "\n",
    "fit_params = {\n",
    "    'model_path': './model/nn/xdeepfm_%s.ckpt' % model_name,\n",
    "    'batch_size': 4096,\n",
    "    'epoch': 100,\n",
    "    'cate_feas': train_cate_csr,\n",
    "    'conti_feas': train_conti_feas,\n",
    "    'labels': y_train.values.reshape(-1, 1),\n",
    "    'v_cate_feas': val_cate_csr,\n",
    "    'v_conti_feas': val_conti_feas,\n",
    "    'v_labels': y_val.values.reshape(-1, 1),\n",
    "    'es': 2\n",
    "}\n",
    "\n",
    "model.fit(**fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start:epoch: 2---train loss 0.4466---valid loss: 0.4388---valid f1: 0.8047 [3.4 s]\n",
    "'cross_layers': [50, 50, 25]:epoch: 2---train loss 0.4463---valid loss: 0.4346---valid f1: 0.8042 [4.1 s]\n",
    "'cross_layers': [100, 100, 50]:epoch: 2---train loss 0.4473---valid loss: 0.4313---valid f1: 0.8035 [5.1 s]\n",
    "'cross_layers': [30, 30, 15]:epoch: 2---train loss 0.4472---valid loss: 0.4325---valid f1: 0.8034 [3.8 s]\n",
    "'cross_layers': [200, 200, 100]:epoch: 3---train loss 0.4322---valid loss: 0.4435---valid f1: 0.8025 [7.0 s]\n",
    "'cross_layers': [70, 50, 30]:epoch: 2---train loss 0.4466---valid loss: 0.4371---valid f1: 0.8041 [3.7 s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# b\n",
    "epoch: 5---train loss 0.4511---valid loss: 0.4203---valid f1: 0.8108 [6.1 s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_trainval, X_test = trainval[usecols], test[usecols]\n",
    "y_trainval = trainval['label']\n",
    "\n",
    "X_trainval.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_trainval.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading conti data...\n",
      "trainval conti feas shape: (146577, 62), test conti feas shape: (51480, 62)\n",
      "loading ori cate data...\n",
      "trainval cate shape:(146577, 4772), test cate shape:(51480, 4772)\n",
      "submitting...\n",
      "y_deep:Tensor(\"Deep-part/Relu_2:0\", shape=(?, 128), dtype=float32), y_cin:Tensor(\"CIN-part/Sum:0\", shape=(?, 120), dtype=float32)\n",
      "Tensor(\"Res-network/MLP/Relu_2:0\", shape=(?, 64), dtype=float32)\n",
      "start training ---------------------------------------------------\n",
      "epoch: 1---train loss 0.4780---valid loss: 0.4253---valid f1: 0.8105 [12.8 s]\n",
      "---------- f1 from 0.0000 to 0.8105, saving model\n",
      "epoch: 2---train loss 0.4349---valid loss: 0.4137---valid f1: 0.8126 [12.3 s]\n",
      "---------- f1 from 0.8105 to 0.8126, saving model\n",
      "epoch: 3---train loss 0.4296---valid loss: 0.4099---valid f1: 0.8144 [12.0 s]\n",
      "---------- f1 from 0.8126 to 0.8144, saving model\n",
      "epoch: 4---train loss 0.4256---valid loss: 0.4059---valid f1: 0.8167 [11.9 s]\n",
      "---------- f1 from 0.8144 to 0.8167, saving model\n"
     ]
    }
   ],
   "source": [
    "print('loading conti data...')\n",
    "# trainval_conti_feas, test_conti_feas = X_trainval[conti_feas].as_matrix(), X_test[conti_feas].as_matrix()\n",
    "print('trainval conti feas shape: {}, test conti feas shape: {}'.format(np.shape(trainval_conti_feas),\n",
    "                                                                        np.shape(test_conti_feas)))\n",
    "\n",
    "print('loading ori cate data...')\n",
    "# trainval_cate_csr = build_ori_cate_feas(X_trainval, cate_long_feas)\n",
    "# trainval_cate_csr = hstack([trainval_cate_csr, csr_matrix(X_trainval.iloc[:, -sum([cate_embedding_uni_cnt[i] for i in list(set(cate_feas)-set(cate_long_feas))]):].as_matrix())])\n",
    "# trainval_cate_csr = csr_matrix(trainval_cate_csr)\n",
    "# test_cate_csr = build_ori_cate_feas(X_test, cate_long_feas)\n",
    "# test_cate_csr = hstack([test_cate_csr, csr_matrix(X_test.iloc[:, -sum([cate_embedding_uni_cnt[i] for i in list(set(cate_feas)-set(cate_long_feas))]):].as_matrix())])\n",
    "# test_cate_csr = csr_matrix(test_cate_csr)\n",
    "print('trainval cate shape:{}, test cate shape:{}'.format(trainval_cate_csr.shape, test_cate_csr.shape))\n",
    "\n",
    "print('submitting...')\n",
    "model_name = 'kuaishou'\n",
    "cate_embedding_w_list, fm_embedding_w = None, None\n",
    "\n",
    "dcfn_params = {\n",
    "    'learning_rate': 0.0005,\n",
    "    'embedding_size': 8,\n",
    "    'dnn_layers': [2048, 512, 128],\n",
    "    'cross_layers': [60, 60, 60],\n",
    "    'res_layers': [128, 64, 32],\n",
    "    'conti_fea_cnt': trainval_conti_feas.shape[1],\n",
    "    'cate_embedding_uni_cnt_list': cate_embedding_uni_cnt_list,\n",
    "    'cate_embedding_w_list': cate_embedding_w_list,\n",
    "    'fm_embedding_w': fm_embedding_w\n",
    "}\n",
    "model = xDeepFM(**dcfn_params)\n",
    "\n",
    "submit_params = {\n",
    "    'model_path': './model/nn/xdeepfm_%s.ckpt' % model_name,\n",
    "    'batch_size': 4096,\n",
    "    'epoch': 8,\n",
    "    'cate_feas': trainval_cate_csr,\n",
    "    'conti_feas': trainval_conti_feas,\n",
    "    'labels': y_trainval.values.reshape(-1, 1),\n",
    "    'v_cate_feas': val_cate_csr,\n",
    "    'v_conti_feas': val_conti_feas,\n",
    "    'v_labels': y_val.values.reshape(-1, 1),\n",
    "    'es': 2\n",
    "}\n",
    "\n",
    "pre_params = {\n",
    "    'batch_size': 4096,\n",
    "    'cate_feas': test_cate_csr,\n",
    "    'conti_feas': test_conti_feas\n",
    "}\n",
    "\n",
    "for i in range(114, 115):\n",
    "    submit_params['epoch'] = i // 100 + 3\n",
    "    model.fit(**submit_params)\n",
    "    result = pd.DataFrame(model.predict(**pre_params))\n",
    "    result.to_csv('./result/b/nn/submit_' + str(i) + '.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame()\n",
    "for i in tqdm_notebook(range(300)):\n",
    "    tmp = pd.read_csv('./result/b/nn/submit_' + str(i) + '.csv', header=None)\n",
    "    if i == 0:\n",
    "        result = tmp\n",
    "    else:\n",
    "        result = result + tmp\n",
    "result = result / 300\n",
    "result.columns = ['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51480, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167777</td>\n",
       "      <td>0.027161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>886972</td>\n",
       "      <td>0.064350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>921231</td>\n",
       "      <td>0.045289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>904908</td>\n",
       "      <td>0.919658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>460291</td>\n",
       "      <td>0.997321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id      pred\n",
       "0  167777  0.027161\n",
       "1  886972  0.064350\n",
       "2  921231  0.045289\n",
       "3  904908  0.919658\n",
       "4  460291  0.997321"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.reset_index(drop=True, inplace=True)\n",
    "submit = pd.concat([test[['user_id']], result], axis=1)\n",
    "submit.shape\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit.to_csv('./result/b/xdeepfm_zero.csv',index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23962, 1)\n"
     ]
    }
   ],
   "source": [
    "save = submit[submit.pred>0.41].sort_values('pred', ascending=False)[['user_id']]\n",
    "print(save.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save.to_csv('./result/b/xdeepfm_zero_0627_limit041.csv',index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a:23726/51709\n",
    "b:23678/51480"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "c3075ca0814e4213af4c1ba0d310d782": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "e4181701830f4ea4b739e058070552d0": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "fd7a2018eadd45a9be403a62aa76bae9": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
