{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler,MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from multiprocessing import Pool,Process\n",
    "import stats as sts\n",
    "from notify import send_msg\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_user_reg = pd.read_csv('../data/user_register_log.txt',sep='\\t',header=None,names=['user_id','register_day','register_type','device_type'])\n",
    "df_app_launch = pd.read_csv('../data/app_launch_log.txt',sep='\\t',header=None,names=['user_id','day'])\n",
    "df_video_create = pd.read_csv('../data/video_create_log.txt',sep='\\t',header=None,names=['user_id','day'])\n",
    "df_user_activity = pd.read_csv('../data/user_activity_log.txt',sep='\\t',header=None,names=['user_id','day','page','video_id','author_id','action_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19798261\n",
       "1      555671\n",
       "2      206079\n",
       "3       46078\n",
       "5         982\n",
       "4         157\n",
       "Name: action_type, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_activity.action_type.value_counts()\n",
    "# “播放“、”关注“、”点赞“、”转发“、”举报“和”减少此类作品“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    51709.000000\n",
       "mean         4.872324\n",
       "std          5.543451\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          2.000000\n",
       "75%          6.000000\n",
       "max         30.000000\n",
       "Name: day, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_app_launch.groupby('user_id').day.count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7606.000000\n",
       "mean        4.621483\n",
       "std         8.541389\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         5.000000\n",
       "max       236.000000\n",
       "Name: day, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_video_create.groupby('user_id').day.count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    43708.000000\n",
       "mean       471.474970\n",
       "std        955.013699\n",
       "min          1.000000\n",
       "25%         23.000000\n",
       "50%        118.000000\n",
       "75%        476.000000\n",
       "max      37882.000000\n",
       "Name: day, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_activity.groupby('user_id').day.count().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_active_users(d_start,d_end, hist_registers=None):\n",
    "    actives = set()\n",
    "    for df in [df_app_launch, df_video_create, df_user_activity]:\n",
    "        actives.update(df[(df.day>=d_start) & (df.day<=d_end)].user_id.unique())\n",
    "    if hist_registers:\n",
    "        actives = actives&set(hist_registers)\n",
    "    return actives\n",
    "\n",
    "def build_train(train_weeks=[(10,16),(17,23),(24,30),(31,37)], train_end=30):\n",
    "# def build_train(train_weeks=[(17,23),(24,30),(31,37)], train_end=30):\n",
    "    df_train = pd.DataFrame()\n",
    "    week_num = 0\n",
    "    for week_start,week_end in train_weeks:\n",
    "        # 选择这周之前注册的用户\n",
    "        df_user = df_user_reg[df_user_reg.register_day<week_start]\n",
    "        df_tmp = pd.DataFrame(df_user['user_id']).drop_duplicates(['user_id'])\n",
    "        df_tmp['data_weeknum'] = week_num\n",
    "        df_tmp['data_weekstart'] = week_start\n",
    "        df_tmp['data_weekend'] = week_end\n",
    "        if week_start <= train_end:\n",
    "            # 查看用户活跃\n",
    "            active_users = get_active_users(week_start, week_end, hist_registers=df_tmp.user_id.unique().tolist())\n",
    "            df_tmp['label'] = df_tmp.user_id.map(lambda x:int(x in active_users))\n",
    "        else:\n",
    "            df_tmp['label'] = -1\n",
    "        df_train = pd.concat([df_train, df_tmp])\n",
    "        week_num += 1\n",
    "    return df_train\n",
    "df = build_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125057, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基础特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5062987402519497"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.label==1).sum()/(df.label!=-1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 用户基础特征\n",
    "df = df.merge(df_user_reg, on='user_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['user_reg_days'] = df['data_weekstart'] - df['register_day']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 历史特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'data_weeknum', 'data_weekstart', 'data_weekend', 'label',\n",
       "       'register_day', 'register_type', 'device_type', 'user_reg_days'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_continuedays(x, df_name, suffix='_hist'):\n",
    "    ret = {}\n",
    "    ret['user_id'] = x['user_id'].unique()[0]\n",
    "    # 天数\n",
    "    days = sorted(x.day.unique())\n",
    "    ret['user_%s_days'%df_name + suffix] = len(days)\n",
    "#     ret['user_max_%s_date'%df_name + suffix] = np.max(days)\n",
    "    ret['user_mean_%s_date'%df_name + suffix] = np.mean(days)\n",
    "    ret['user_min_%s_date'%df_name + suffix] = np.min(days)\n",
    "    ret['user_range_%s_date'%df_name + suffix] = np.max(days) - np.min(days)\n",
    "    \n",
    "    if len(days) > 1:\n",
    "        days_dist = np.diff(days, 1) - 1\n",
    "        ret['user_max_no_%s_days'%df_name + suffix] = np.max(days_dist)\n",
    "        ret['user_mean_no_%s_days'%df_name + suffix] = np.mean(days_dist)\n",
    "        ret['user_min_no_%s_days'%df_name + suffix] = np.min(days_dist)\n",
    "        ret['user_var_no_%s_days'%df_name + suffix] = np.var(days_dist)\n",
    "        ret['user_median_no_%s_days'%df_name + suffix] = np.median(days_dist)\n",
    "        try:\n",
    "            ret['user_kurt_no_%s_days'%df_name + suffix] = sts.kurtosis(days_dist)\n",
    "        except:\n",
    "            ret['user_kurt_no_%s_days'%df_name + suffix] = -1\n",
    "        try:\n",
    "            ret['user_skew_no_%s_days'%df_name + suffix] = sts.skewness(days_dist)\n",
    "        except:\n",
    "            ret['user_skew_no_%s_days'%df_name + suffix] = -1\n",
    "        continue_days = []\n",
    "        count = 1\n",
    "        for i in range(days_dist.shape[0]):\n",
    "            if days_dist[i] == 0:\n",
    "                count += 1\n",
    "            else:\n",
    "                if count > 0:\n",
    "                    continue_days.append(count)\n",
    "                count = 1\n",
    "        continue_days.append(count)\n",
    "        ret['user_continue_%s_dayslices'%df_name + suffix] = len(continue_days)\n",
    "        ret['user_max_continue_%s_days'%df_name + suffix] = np.max(continue_days)\n",
    "        ret['user_mean_continue_%s_days'%df_name + suffix] = np.mean(continue_days)\n",
    "        ret['user_min_continue_%s_days'%df_name + suffix] = np.min(continue_days)\n",
    "        ret['user_var_continue_%s_days'%df_name + suffix] = np.var(continue_days)\n",
    "        ret['user_median_continue_%s_days'%df_name + suffix] = np.median(continue_days)\n",
    "        try:\n",
    "            ret['user_kurt_continue_%s_days'%df_name + suffix] = sts.kurtosis(continue_days)\n",
    "        except:\n",
    "            ret['user_kurt_continue_%s_days'%df_name + suffix] = -1\n",
    "        try:\n",
    "            ret['user_skew_continue_%s_days'%df_name + suffix] = sts.skewness(continue_days)\n",
    "        except:\n",
    "            ret['user_skew_continue_%s_days'%df_name + suffix] = -1\n",
    "    else:\n",
    "        ret['user_continue_%s_slices'%df_name + suffix] = 1\n",
    "        ret['user_max_no_%s_days'%df_name + suffix] = -1\n",
    "        ret['user_mean_no_%s_days'%df_name+ suffix] = -1\n",
    "        ret['user_min_no_%s_days'%df_name+ suffix] = -1\n",
    "        ret['user_median_no_%s_days'%df_name + suffix] = -1\n",
    "        ret['user_var_no_%s_days'%df_name+ suffix] = 0\n",
    "        ret['user_kurt_no_%s_days'%df_name + suffix] = -1\n",
    "        ret['user_skew_no_%s_days'%df_name + suffix] = -1\n",
    "        \n",
    "        ret['user_max_continue_%s_days'%df_name+ suffix] = 1\n",
    "        ret['user_mean_continue_%s_days'%df_name+ suffix] = 1\n",
    "        ret['user_min_continue_%s_days'%df_name+ suffix] = 1\n",
    "        ret['user_median_continue_%s_days'%df_name + suffix] = 1\n",
    "        ret['user_var_continue_%s_days'%df_name+ suffix] = 0\n",
    "        ret['user_kurt_continue_%s_days'%df_name + suffix] = -1\n",
    "        ret['user_skew_continue_%s_days'%df_name + suffix] = -1\n",
    "    # 次数\n",
    "    days = sorted(x.day.values)\n",
    "    ret['user_%s_times'%df_name+ suffix] = len(days)\n",
    "    if len(days)>1:\n",
    "        days_dist = np.diff(days, 1)\n",
    "        count = 1\n",
    "        continue_times = []\n",
    "        for i in range(days_dist.shape[0]):\n",
    "            if days_dist[i] <=1:\n",
    "                count += 1\n",
    "            else:\n",
    "                if count > 0:\n",
    "                    continue_times.append(count)\n",
    "                count = 1\n",
    "        continue_times.append(count)\n",
    "        ret['user_max_continue_%s_times'%df_name + suffix]  = np.max(continue_times)\n",
    "        ret['user_min_continue_%s_times'%df_name + suffix]  = np.min(continue_times)\n",
    "        ret['user_mean_continue_%s_times'%df_name + suffix] = np.mean(continue_times)\n",
    "        ret['user_var_continue_%s_times'%df_name + suffix]  = np.var(continue_times)\n",
    "        ret['user_median_continue_%s_times'%df_name + suffix]  = np.median(continue_times)\n",
    "        try:\n",
    "            ret['user_kurt_continue_%s_times'%df_name + suffix]  = sts.kurtosis(continue_times)\n",
    "        except:\n",
    "            ret['user_kurt_continue_%s_times'%df_name + suffix]  = -1\n",
    "        try:\n",
    "            ret['user_skew_continue_%s_times'%df_name + suffix]  = sts.skewness(continue_times)\n",
    "        except:\n",
    "            ret['user_skew_continue_%s_times'%df_name + suffix]  = -1\n",
    "    else:\n",
    "        ret['user_max_continue_%s_times'%df_name + suffix]  = -1\n",
    "        ret['user_min_continue_%s_times'%df_name + suffix]  = -1\n",
    "        ret['user_mean_continue_%s_times'%df_name + suffix] = -1\n",
    "        ret['user_var_continue_%s_times'%df_name + suffix]  = 0\n",
    "        ret['user_median_continue_%s_times'%df_name + suffix]  = -1\n",
    "        ret['user_kurt_continue_%s_times'%df_name + suffix]  = -1\n",
    "        ret['user_skew_continue_%s_times'%df_name + suffix]  = -1\n",
    "    daytimes = x.groupby('day').user_id.count().tolist()\n",
    "    if len(daytimes) > 1:\n",
    "        ret['user_max_%s_daytimes'%df_name+suffix] = np.max(daytimes)\n",
    "        ret['user_min_%s_daytimes'%df_name+suffix] = np.min(daytimes)\n",
    "        ret['user_mean_%s_daytimes'%df_name+suffix]= np.mean(daytimes)\n",
    "        ret['user_var_%s_daytimes'%df_name+suffix] = np.var(daytimes)\n",
    "        ret['user_median_%s_daytimes'%df_name+suffix] = np.median(daytimes)\n",
    "        try:\n",
    "            ret['user_kurt_%s_daytimes'%df_name+suffix] = sts.kurtosis(daytimes)\n",
    "        except:\n",
    "            ret['user_kurt_%s_daytimes'%df_name+suffix] = -1\n",
    "        try:\n",
    "            ret['user_skew_%s_daytimes'%df_name+suffix] = sts.skewness(daytimes)\n",
    "        except:\n",
    "            ret['user_skew_%s_daytimes'%df_name+suffix] = -1\n",
    "        # 日活次数变化趋势\n",
    "        daytimes_diff = np.diff(daytimes, 1)\n",
    "        ret['user_%s_daytimes_diff1_mean'%df_name+suffix] = np.mean(daytimes_diff)\n",
    "    else:\n",
    "        ret['user_max_%s_daytimes'%df_name+suffix] = -1\n",
    "        ret['user_min_%s_daytimes'%df_name+suffix] = -1\n",
    "        ret['user_mean_%s_daytimes'%df_name+suffix]= -1\n",
    "        ret['user_var_%s_daytimes'%df_name+suffix] = 0\n",
    "        ret['user_median_%s_daytimes'%df_name+suffix] = -1\n",
    "        ret['user_kurt_%s_daytimes'%df_name+suffix] = -1\n",
    "        ret['user_skew_%s_daytimes'%df_name+suffix] = -1\n",
    "        ret['user_%s_daytimes_diff1_mean'%df_name+suffix] = -1\n",
    "    return pd.DataFrame([ret])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python36\\lib\\site-packages\\stats.py:1660: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  n, total = _generalised_sum(data, lambda x: ((x-m)/s)**4)\n",
      "C:\\Program Files\\Python36\\lib\\site-packages\\stats.py:1614: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  n, total = _generalised_sum(data, lambda x: ((x-m)/s)**3)\n"
     ]
    }
   ],
   "source": [
    "# 按照开始日期滑窗造特征\n",
    "def get_history(df):\n",
    "    ret = pd.DataFrame()\n",
    "    for w in sorted(df.data_weeknum.unique()):\n",
    "        # 历史数据\n",
    "        start = sorted(df.data_weekstart.unique())[w]\n",
    "        launch_hist = df_app_launch[(df_app_launch.day<start)]\n",
    "        video_hist  = df_video_create[(df_video_create.day<start)]\n",
    "        activity    = df_user_activity[(df_user_activity.day<start)]\n",
    "        # 用户数据\n",
    "        df_tmp = df[df.data_weeknum==w][['user_id','data_weeknum']]\n",
    "        origin_shape = df_tmp.shape[0]\n",
    "        \n",
    "        # 历史/上周 统计启动天数、上传视频数量、交互数\n",
    "        user_launch = launch_hist.groupby('user_id').apply(lambda x:get_user_continuedays(x, df_name='launch', suffix='_hist'))\n",
    "        launch_hist_tmp = launch_hist.groupby(['user_id']).day.count().reset_index().rename(columns={'day':'user_hist_launchday'})\n",
    "        launch_week_tmp = launch_hist[launch_hist.day>=start-7]\n",
    "        user_launch_week = launch_week_tmp.groupby('user_id').apply(lambda x: get_user_continuedays(x, df_name='launch', suffix='_lastweek'))\n",
    "        launch_week_tmp = launch_week_tmp.groupby(['user_id']).day.count().reset_index().rename(columns={'day':'user_lastweek_launchday'})\n",
    "        df_tmp = df_tmp.merge(launch_hist_tmp, on='user_id',how='left')\n",
    "        df_tmp = df_tmp.merge(launch_week_tmp, on='user_id',how='left')\n",
    "        df_tmp = df_tmp.merge(user_launch, on='user_id', how='left')\n",
    "        df_tmp = df_tmp.merge(user_launch_week, on='user_id', how='left')\n",
    "        \n",
    "        user_video = video_hist.groupby('user_id').apply(lambda x:get_user_continuedays(x, df_name='createvideo', suffix='_hist'))\n",
    "        video_hist_tmp = video_hist.groupby(['user_id']).day.count().reset_index().rename(columns={'day':'user_hist_videocount'})\n",
    "        video_week_tmp = video_hist[video_hist.day>=start-7]\n",
    "        user_video_week = video_week_tmp.groupby('user_id').apply(lambda x: get_user_continuedays(x, df_name='createvideo', suffix='_lastweek'))\n",
    "        video_week_tmp = video_week_tmp.groupby(['user_id']).day.count().reset_index().rename(columns={'day':'user_lastweek_videocount'})\n",
    "        df_tmp = df_tmp.merge(video_hist_tmp, on='user_id',how='left')\n",
    "        df_tmp = df_tmp.merge(video_week_tmp, on='user_id',how='left')\n",
    "        df_tmp = df_tmp.merge(user_video, on='user_id', how='left')\n",
    "        df_tmp = df_tmp.merge(user_video_week, on='user_id', how='left')\n",
    "        \n",
    "        user_active = activity.groupby(['user_id']).apply(lambda x:get_user_continuedays(x, df_name='activity', suffix='_hist'))\n",
    "        active_hist_tmp = activity.groupby(['user_id']).day.count().reset_index().rename(columns={'day':'user_hist_actcount'})\n",
    "        active_week = activity[activity.day>=start-7]\n",
    "        user_active_week = active_week.groupby('user_id').apply(lambda x: get_user_continuedays(x, df_name='activity', suffix='_lastweek'))\n",
    "        active_week_tmp = active_week.groupby(['user_id']).day.count().reset_index().rename(columns={'day':'user_lastweek_actcount'})\n",
    "        df_tmp = df_tmp.merge(active_hist_tmp, on='user_id',how='left')\n",
    "        df_tmp = df_tmp.merge(active_week_tmp, on='user_id',how='left')\n",
    "        df_tmp = df_tmp.merge(user_active, on='user_id', how='left')\n",
    "        df_tmp = df_tmp.merge(user_active_week, on='user_id', how='left')\n",
    "        \n",
    "        # 前2-6天（窗口）的统计量(1天 = 前1天当天， 7天 = lastweek(not hotel.))\n",
    "        for n in range(2,7):\n",
    "            user_launch_n_day_win = launch_hist[launch_hist.day >= start - n].groupby('user_id').apply(lambda x:get_user_continuedays(x, df_name='launch',suffix='_%sdaywin'%n))\n",
    "            user_video_n_day_win  = video_hist[video_hist.day >= start - n].groupby('user_id').apply(lambda x:get_user_continuedays(x, df_name='createvideo',suffix='_%sdaywin'%n))\n",
    "            user_active_n_day_win = activity[activity.day >= start - n].groupby('user_id').apply(lambda x:get_user_continuedays(x, df_name='activity',suffix='_%sdaywin'%n))\n",
    "            df_tmp = df_tmp.merge(user_launch_n_day_win, on='user_id', how='left')\n",
    "            df_tmp = df_tmp.merge(user_video_n_day_win,  on='user_id', how='left')\n",
    "            df_tmp = df_tmp.merge(user_active_n_day_win, on='user_id', how='left')\n",
    "        \n",
    "        df_tmp.fillna(0, inplace=True)\n",
    "        # 前1-7天 当天统计量\n",
    "        for n in range(1,8):\n",
    "            # 是否启动过\n",
    "            # 是否/计数 发布视频\n",
    "            # 是否/计数 进行activety\n",
    "            # 进行了哪几类activity，各多少\n",
    "            # 访问了哪几个page 各多少\n",
    "\n",
    "            user_launch_n_day_onday = launch_hist[launch_hist.day == start - n]\n",
    "            user_video_n_day_onday =  video_hist[video_hist.day == start - n]\n",
    "            user_active_n_day_onday = activity[activity.day == start - n]\n",
    "            user_n_day_launch_onday = user_launch_n_day_onday.groupby('user_id').day.count().reset_index().rename(columns={'day': 'user_%sdaybefore_launch'%n})\n",
    "            user_n_day_videocount_onday = user_video_n_day_onday.groupby('user_id').day.count().reset_index().rename(columns={'day': 'user_%sdaybefore_video_count'%n})\n",
    "            user_n_day_actcount_onday = user_active_n_day_onday.groupby('user_id').day.count().reset_index().rename(columns={'day': 'user_%sdaybefore_act_count'%n})\n",
    "            \n",
    "            df_tmp = df_tmp.merge(user_n_day_launch_onday, on='user_id', how='left').fillna(0)\n",
    "            df_tmp = df_tmp.merge(user_n_day_videocount_onday,  on='user_id', how='left').fillna(0)\n",
    "            df_tmp = df_tmp.merge(user_n_day_actcount_onday, on='user_id', how='left').fillna(0)\n",
    "            df_tmp['user_%sdaybefore_video'%n] = df_tmp['user_%sdaybefore_video_count'%n].map(lambda x:1 if x>0 else 0)\n",
    "            df_tmp['user_%sdaybefore_act'%n] = df_tmp['user_%sdaybefore_act_count'%n].map(lambda x:1 if x>0 else 0)\n",
    "            \n",
    "            user_n_day_activity_type_count_onday = user_active_n_day_onday.groupby(['user_id','action_type']).day.count().reset_index().pivot(index='user_id', columns='action_type', values='day').fillna(0)\n",
    "            for col in user_n_day_activity_type_count_onday.columns.tolist():\n",
    "                user_n_day_activity_type_count_onday.rename(columns={col: 'user_%sdaybefore_act_%s_count'%(n, col)},inplace=True)\n",
    "                user_n_day_activity_type_count_onday['user_%sdaybefore_act_%s'%(n, col)] = user_n_day_activity_type_count_onday['user_%sdaybefore_act_%s_count'%(n, col)].map(lambda x: int(x>0))\n",
    "            user_n_day_activity_type_count_onday.reset_index(inplace=True)\n",
    "                \n",
    "            user_n_day_page_count_onday = user_active_n_day_onday.groupby(['user_id', 'page']).day.count().reset_index().pivot(index='user_id',columns='page',values='day').fillna(0)\n",
    "            for col in user_n_day_page_count_onday.columns.tolist():\n",
    "                user_n_day_page_count_onday.rename(columns={col: 'user_%sdaybefore_act_page_%s_count'%(n, col)},inplace=True)\n",
    "                user_n_day_page_count_onday['user_%sdaybefore_act_page_%s'%(n, col)] = user_n_day_page_count_onday['user_%sdaybefore_act_page_%s_count'%(n, col)].map(lambda x: int(x>0))\n",
    "            user_n_day_page_count_onday.reset_index(inplace=True)\n",
    "            df_tmp = df_tmp.merge(user_n_day_activity_type_count_onday, on='user_id', how='left').fillna(0)\n",
    "            df_tmp = df_tmp.merge(user_n_day_page_count_onday, on='user_id', how='left').fillna(0)\n",
    "            \n",
    "        # 不同类型的行为数\n",
    "        for act in sorted(df_user_activity.action_type.unique()):\n",
    "            column_name1 = 'user_hist_act_%d_count'%act\n",
    "            column_name2 = 'user_lastweek_act_%d_count'%act\n",
    "            act_hist = activity[activity.action_type==act].groupby(['user_id']).day.count().reset_index().rename(columns={'day':column_name1})\n",
    "            act_lastweek = active_week[active_week.action_type==act].groupby(['user_id']).day.count().reset_index().rename(columns={'day':column_name2})\n",
    "            df_tmp = df_tmp.merge(act_hist, on='user_id',how='left')\n",
    "            df_tmp = df_tmp.merge(act_lastweek, on='user_id',how='left')\n",
    "        df_tmp.fillna(0,inplace=True)\n",
    "        df_tmp['user_hist_goodact_count'] = df_tmp['user_hist_act_0_count'] +  df_tmp['user_hist_act_1_count'] + df_tmp['user_hist_act_2_count']+ df_tmp['user_hist_act_3_count']\n",
    "        df_tmp['user_hist_badact_count'] = df_tmp['user_hist_act_4_count'] + df_tmp['user_hist_act_5_count']\n",
    "        df_tmp['user_hist_badact_div_good_act'] = df_tmp['user_hist_badact_count'] / df_tmp['user_hist_goodact_count']\n",
    "        df_tmp['user_lastweek_goodact_count'] = df_tmp['user_lastweek_act_0_count'] +  df_tmp['user_lastweek_act_1_count'] + df_tmp['user_lastweek_act_2_count']+ df_tmp['user_lastweek_act_3_count']\n",
    "        df_tmp['user_lastweek_badact_count'] = df_tmp['user_lastweek_act_4_count'] + df_tmp['user_lastweek_act_5_count']\n",
    "        df_tmp['user_lastweek_badact_div_good_act'] = df_tmp['user_lastweek_badact_count'] / df_tmp['user_lastweek_goodact_count']\n",
    "        \n",
    "        # 用户浏览不同page的次数\n",
    "        for page in sorted(df_user_activity.page.unique()):\n",
    "            column_name1 = 'user_hist_act_page_%s_count'%page\n",
    "            column_name2 = 'user_lastweek_act_page_%s_count'%page\n",
    "            page_hist = activity[activity.page == page].groupby(['user_id']).day.count().reset_index().rename(columns={'day':column_name1})\n",
    "            page_lastweek = active_week[active_week.page == page].groupby(['user_id']).day.count().reset_index().rename(columns={'day':column_name2})\n",
    "            df_tmp = df_tmp.merge(page_hist, on='user_id', how='left')\n",
    "            df_tmp = df_tmp.merge(page_lastweek, on='user_id', how='left')\n",
    "        # 用户发生行为的视频数unique count\n",
    "        user_active_video_uniquecount = activity.drop_duplicates(['user_id','video_id']).groupby(['user_id']).day.count().reset_index().rename(columns={'day':'user_hist_act_video_uniquecount'})\n",
    "        user_active_video_uniquecount_week = active_week.drop_duplicates(['user_id','video_id']).groupby(['user_id']).day.count().reset_index().rename(columns={'day':'user_lastweek_act_video_uniquecount'})\n",
    "        df_tmp = df_tmp.merge(user_active_video_uniquecount, on='user_id', how='left')\n",
    "        df_tmp = df_tmp.merge(user_active_video_uniquecount_week, on='user_id', how='left')\n",
    "        # 用户发生行为的作者数\n",
    "        user_active_author_count = activity.drop_duplicates(['user_id','author_id']).groupby(['user_id']).day.count().reset_index().rename(columns={'day':'user_hist_act_author_count'})\n",
    "        user_active_author_count_week = active_week.drop_duplicates(['user_id','author_id']).groupby(['user_id']).day.count().reset_index().rename(columns={'day':'user_lastweek_act_author_count'})\n",
    "        df_tmp = df_tmp.merge(user_active_author_count, on='user_id', how='left')\n",
    "        df_tmp = df_tmp.merge(user_active_author_count_week, on='user_id', how='left')\n",
    "        # 用户平均每个视频看几次、最多看几遍\n",
    "        user_video_act_counts_mean = activity.groupby(['user_id','video_id']).day.count().reset_index().groupby(['user_id']).day.mean().reset_index().rename(columns={'day':'user_hist_act_video_meancount'})\n",
    "        user_video_act_counts_max = activity.groupby(['user_id','video_id']).day.count().reset_index().groupby(['user_id']).day.max().reset_index().rename(columns={'day':'user_hist_act_video_maxcount'})\n",
    "        df_tmp = df_tmp.merge(user_video_act_counts_mean, on='user_id', how='left')\n",
    "        df_tmp = df_tmp.merge(user_video_act_counts_max, on='user_id', how='left')\n",
    "        df_tmp.fillna(0,inplace=True)\n",
    "        # 距离最后一次启动/上传/活动多少天\n",
    "        user_last_launch = launch_hist.groupby('user_id').day.max().reset_index().rename(columns={'day':'user_last_launch_date'})\n",
    "        user_last_video = video_hist.groupby('user_id').day.max().reset_index().rename(columns={'day':'user_last_video_date'})\n",
    "        user_last_active = activity.groupby('user_id').day.max().reset_index().rename(columns={'day':'user_last_act_date'})\n",
    "        df_tmp = df_tmp.merge(user_last_launch, on='user_id', how='left').fillna(-1)\n",
    "        df_tmp = df_tmp.merge(user_last_video, on='user_id', how='left').fillna(-1)\n",
    "        df_tmp = df_tmp.merge(user_last_active, on='user_id', how='left').fillna(-1)\n",
    "        df_tmp['user_last_launch_dist'] = df_tmp['user_last_launch_date'].map(lambda x: start - x if x!=-1 else -1)\n",
    "        df_tmp['user_last_video_dist'] = df_tmp['user_last_video_date'].map(lambda x:start - x if x!=-1 else -1)\n",
    "        df_tmp['user_last_act_dist'] = df_tmp['user_last_act_date'].map(lambda x:start - x if x!=-1 else -1)\n",
    "        # 用户视频的受关注情况, 历史/上周，及比例\n",
    "        df_video_act = activity.groupby(['author_id','action_type']).day.count().reset_index().pivot(index='author_id',columns='action_type',values='day').fillna(0)\n",
    "        df_video_act_week = active_week.groupby(['author_id','action_type']).day.count().reset_index().pivot(index='author_id',columns='action_type',values='day').fillna(0)\n",
    "        df_video_act['user_hist_video_goodact_sum'] = 0\n",
    "        df_video_act['user_hist_video_activity_sum'] = df_video_act.sum(axis=1)\n",
    "        df_video_act_week['user_lastweek_video_activity_sum'] = df_video_act_week.sum(axis=1)\n",
    "        df_video_act_week['user_lastweek_video_goodact_sum'] = 0\n",
    "        for col in df_video_act.columns:\n",
    "            if type(col) == str:\n",
    "                continue\n",
    "            if col < 4:\n",
    "                df_video_act['user_hist_video_goodact_sum'] += df_video_act[col]\n",
    "            df_video_act.rename(columns={col:'user_hist_video_activity_'+str(col)+'_count'},inplace=True)\n",
    "            df_video_act['user_hist_video_activity_'+str(col)+'_rate'] = df_video_act['user_hist_video_activity_'+str(col)+'_count'] / df_video_act['user_hist_video_activity_sum']\n",
    "        df_video_act.fillna(0, inplace=True)\n",
    "        df_video_act['user_hist_video_goodact_rate'] = df_video_act['user_hist_video_goodact_sum'] / df_video_act['user_hist_video_activity_sum']\n",
    "        for col in df_video_act_week.columns:\n",
    "            if type(col) == str:\n",
    "                continue\n",
    "            if col < 4:\n",
    "                df_video_act_week['user_lastweek_video_goodact_sum'] += df_video_act_week[col]\n",
    "            df_video_act_week.rename(columns={col:'user_lastweek_video_activity_'+str(col)+'_count'}, inplace=True)\n",
    "            df_video_act_week['user_lastweek_video_activity_'+str(col)+'_rate'] = df_video_act_week['user_lastweek_video_activity_'+str(col)+'_count'] / df_video_act_week['user_lastweek_video_activity_sum']\n",
    "        df_video_act_week.fillna(0, inplace=True)\n",
    "        df_video_act_week['user_lastweek_video_goodact_rate'] = df_video_act_week['user_lastweek_video_goodact_sum'] / df_video_act_week['user_lastweek_video_activity_sum']\n",
    "        df_video_act = df_video_act.reset_index()\n",
    "        df_video_act_week = df_video_act_week.reset_index()\n",
    "        df_tmp = df_tmp.merge(df_video_act, left_on='user_id', right_on='author_id', how='left').fillna(0)\n",
    "        del df_tmp['author_id']\n",
    "        df_tmp = df_tmp.merge(df_video_act_week, left_on='user_id', right_on='author_id', how='left').fillna(0)\n",
    "        del df_tmp['author_id']\n",
    "        # 用户视频出现在不同page的unique count/访问量count\n",
    "        video_unique_page_count = activity.drop_duplicates(['page','video_id']).groupby(['author_id','page']).day.count().reset_index().pivot(index='author_id',columns='page',values='day').fillna(0)\n",
    "        for col in video_unique_page_count.columns:\n",
    "            video_unique_page_count.rename(columns={col: 'user_video_page_'+str(col)+'_uniquecount'},inplace=True)\n",
    "        video_unique_page_count = video_unique_page_count.reset_index()\n",
    "        df_tmp = df_tmp.merge(video_unique_page_count, left_on='user_id', right_on='author_id', how='left').fillna(0)\n",
    "        del df_tmp['author_id']\n",
    "        video_page_count = activity.groupby(['author_id','page']).day.count().reset_index().pivot(index='author_id',columns='page',values='day').fillna(0)\n",
    "        for col in video_page_count.columns:\n",
    "            video_page_count.rename(columns={col:'user_video_page_'+str(col)+'_count'},inplace=True)\n",
    "        video_page_count = video_page_count.reset_index()\n",
    "        df_tmp = df_tmp.merge(video_page_count, left_on='user_id', right_on='author_id', how='left').fillna(0)\n",
    "        del df_tmp['author_id']\n",
    "        video_page_count_week = active_week.groupby(['author_id','page']).day.count().reset_index().pivot(index='author_id',columns='page',values='day').fillna(0)\n",
    "        for col in video_page_count_week.columns:\n",
    "            video_page_count_week.rename(columns={col:'user_video_page_'+str(col)+'_lastweek_count'}, inplace=True)\n",
    "        video_page_count_week = video_page_count_week.reset_index()\n",
    "        df_tmp = df_tmp.merge(video_page_count_week, left_on='user_id', right_on='author_id', how='left').fillna(0)\n",
    "        del df_tmp['author_id']\n",
    "        \n",
    "        # 0-1特征\n",
    "        df_tmp['user_hist_launch'] = df_tmp['user_hist_launchday'].map(lambda x: int(x>0))\n",
    "        df_tmp['user_lastweek_launch'] = df_tmp['user_lastweek_launchday'].map(lambda x: int(x>0))\n",
    "        df_tmp['user_hist_video'] = df_tmp['user_hist_videocount'].map(lambda x: int(x>0))\n",
    "        df_tmp['user_lastweek_video'] = df_tmp['user_lastweek_videocount'].map(lambda x: int(x>0))\n",
    "        df_tmp['user_hist_act'] = df_tmp['user_hist_actcount'].map(lambda x: int(x>0))\n",
    "        df_tmp['user_lastweek_act'] = df_tmp['user_lastweek_actcount'].map(lambda x: int(x>0))\n",
    "        df_tmp['user_hist_act_types'] = 0#todo\n",
    "        df_tmp['user_lastweek_act_types'] = 0\n",
    "        df_tmp['user_hist_video_activity_types'] = 0\n",
    "        df_tmp['user_lastweek_video_activity_types'] = 0\n",
    "        df_tmp['user_hist_page_types'] = 0\n",
    "        df_tmp['user_lastweek_page_types'] = 0\n",
    "        df_tmp['user_hist_video_page_types'] = 0\n",
    "        df_tmp['user_lastweek_video_page_types'] = 0\n",
    "        for act in sorted(df_user_activity.action_type.unique()):\n",
    "            if 'user_hist_act_%d_count'%act in df_tmp.columns:\n",
    "                df_tmp['user_hist_act_%d'%act] = df_tmp['user_hist_act_%d_count'%act].map(lambda x: int(x>0))\n",
    "                df_tmp['user_hist_act_types'] += df_tmp['user_hist_act_%d'%act]\n",
    "            if 'user_lastweek_act_%d_count'%act in df_tmp.columns:\n",
    "                df_tmp['user_lastweek_act_%d'%act] = df_tmp['user_lastweek_act_%d_count'%act].map(lambda x: int(x>0))\n",
    "                df_tmp['user_lastweek_act_types'] += df_tmp['user_lastweek_act_%d'%act]\n",
    "            if 'user_hist_video_activity_%s_count'%act in df_tmp.columns:\n",
    "                df_tmp['user_hist_video_activity_%s'%act] = df_tmp['user_hist_video_activity_%s_count'%act].map(lambda x: int(x>0))\n",
    "                df_tmp['user_hist_video_activity_types'] += df_tmp['user_hist_video_activity_%s'%act]\n",
    "            if 'user_lastweek_video_activity_%s_count'%act in df_tmp.columns:\n",
    "                df_tmp['user_lastweek_video_activity_%s'%act] = df_tmp['user_lastweek_video_activity_%s_count'%act].map(lambda x: int(x>0))\n",
    "                df_tmp['user_lastweek_video_activity_types'] += df_tmp['user_lastweek_video_activity_%s'%act]\n",
    "        \n",
    "        df_tmp['user_hist_badact'] = df_tmp['user_hist_badact_count'].map(lambda x:int(x>0))\n",
    "        \n",
    "        for page in sorted(df_user_activity.page.unique()):\n",
    "            if 'user_hist_act_page_%s_count'%page in df_tmp.columns:\n",
    "                df_tmp['user_hist_act_page_%s'%page] = df_tmp['user_hist_act_page_%s_count'%page].map(lambda x: int(x>0))\n",
    "                df_tmp['user_hist_page_types'] += df_tmp['user_hist_act_page_%s'%page]\n",
    "            if 'user_lastweek_act_page_%s_count'%page in df_tmp.columns:\n",
    "                df_tmp['user_lastweek_act_page_%s'%page] = df_tmp['user_lastweek_act_page_%s_count'%page].map(lambda x: int(x>0))\n",
    "                df_tmp['user_lastweek_page_types'] += df_tmp['user_lastweek_act_page_%s'%page]\n",
    "            if 'user_video_page_%s_count'%page in df_tmp.columns:\n",
    "                df_tmp['user_video_page_%s'%page] = df_tmp['user_video_page_%s_count'%page].map(lambda x: int(x>0))\n",
    "                df_tmp['user_hist_video_page_types'] += df_tmp['user_video_page_%s'%page]\n",
    "            if 'user_video_page_%s_lastweek_count'%page in df_tmp.columns:\n",
    "                df_tmp['user_video_page_%s_lastweek'%page] = df_tmp['user_video_page_%s_lastweek_count'%page].map(lambda x: int(x>0))\n",
    "                df_tmp['user_lastweek_video_page_types'] += df_tmp['user_video_page_%s_lastweek'%page]\n",
    "        df_tmp['user_hist_lastweek_act_types_dist'] = df_tmp['user_hist_act_types'] - df_tmp['user_lastweek_act_types']\n",
    "        df_tmp['user_hist_lastweek_video_activity_types_dist'] = df_tmp['user_hist_video_activity_types'] - df_tmp['user_lastweek_video_activity_types']\n",
    "        df_tmp['user_hist_lastweek_page_types_dist'] = df_tmp['user_hist_page_types'] - df_tmp['user_lastweek_page_types']\n",
    "        df_tmp['user_hist_lastweek_video_page_types_dist'] = df_tmp['user_hist_video_page_types'] - df_tmp['user_lastweek_video_page_types']\n",
    "        # check行数是否有问题\n",
    "        assert(df_tmp.shape[0]==origin_shape)\n",
    "        ret = pd.concat([df_tmp,ret])\n",
    "    return ret\n",
    "df_merge = get_history(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.merge(df_merge, on=['user_id','data_weeknum'],how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用频率特征\n",
    "df['user_hist_launch_freq'] = df['user_hist_launchday'] / df['user_reg_days']\n",
    "df['user_lastweek_launch_freq'] = df['user_lastweek_launchday'] / 7\n",
    "df.loc[df.user_reg_days<7, 'user_lastweek_launch_freq'] = df.loc[df.user_reg_days<7, 'user_hist_launch_freq']\n",
    "df['user_lastweek_hist_launch_freq_dist'] = df['user_lastweek_launch_freq'] - df['user_hist_launch_freq']\n",
    "\n",
    "df['user_hist_video_freq'] = df['user_hist_videocount'] / df['user_reg_days']\n",
    "df['user_lastweek_video_freq'] = df['user_lastweek_videocount'] / 7\n",
    "df.loc[df.user_reg_days<7, 'user_lastweek_video_freq'] = df.loc[df.user_reg_days<7, 'user_hist_video_freq']\n",
    "df['user_lastweek_hist_video_freq_dist'] = df['user_lastweek_video_freq'] - df['user_hist_video_freq']\n",
    "\n",
    "df['user_hist_act_freq'] = df['user_hist_actcount'] / df['user_reg_days']\n",
    "df['user_hist_act_0_freq'] = df['user_hist_act_0_count'] / df['user_reg_days']\n",
    "df['user_hist_act_1_freq'] = df['user_hist_act_1_count'] / df['user_reg_days']\n",
    "df['user_hist_act_2_freq'] = df['user_hist_act_2_count'] / df['user_reg_days']\n",
    "df['user_hist_act_3_freq'] = df['user_hist_act_3_count'] / df['user_reg_days']\n",
    "df['user_hist_act_4_freq'] = df['user_hist_act_4_count'] / df['user_reg_days']\n",
    "df['user_hist_act_5_freq'] = df['user_hist_act_5_count'] / df['user_reg_days']\n",
    "\n",
    "df['user_lastweek_act_freq'] = df['user_lastweek_actcount'] / 7\n",
    "df['user_lastweek_act_0_freq'] = df['user_lastweek_act_0_count'] / 7\n",
    "df['user_lastweek_act_1_freq'] = df['user_lastweek_act_1_count'] / 7\n",
    "df['user_lastweek_act_2_freq'] = df['user_lastweek_act_2_count'] / 7\n",
    "df['user_lastweek_act_3_freq'] = df['user_lastweek_act_3_count'] / 7\n",
    "df['user_lastweek_act_4_freq'] = df['user_lastweek_act_4_count'] / 7\n",
    "df['user_lastweek_act_5_freq'] = df['user_lastweek_act_5_count'] / 7\n",
    "\n",
    "df.loc[df.user_reg_days<7, 'user_lastweek_act_freq']   = df.loc[df.user_reg_days<7, 'user_hist_act_freq']\n",
    "df.loc[df.user_reg_days<7, 'user_lastweek_act_0_freq'] = df.loc[df.user_reg_days<7, 'user_hist_act_0_freq']\n",
    "df.loc[df.user_reg_days<7, 'user_lastweek_act_1_freq'] = df.loc[df.user_reg_days<7, 'user_hist_act_1_freq']\n",
    "df.loc[df.user_reg_days<7, 'user_lastweek_act_2_freq'] = df.loc[df.user_reg_days<7, 'user_hist_act_2_freq']\n",
    "df.loc[df.user_reg_days<7, 'user_lastweek_act_3_freq'] = df.loc[df.user_reg_days<7, 'user_hist_act_3_freq']\n",
    "df.loc[df.user_reg_days<7, 'user_lastweek_act_4_freq'] = df.loc[df.user_reg_days<7, 'user_hist_act_4_freq']\n",
    "df.loc[df.user_reg_days<7, 'user_lastweek_act_5_freq'] = df.loc[df.user_reg_days<7, 'user_hist_act_5_freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['user_last_launch_dist_morethan_histmax'] = (df.user_last_launch_dist > df.user_max_no_launch_days_hist).astype(int)\n",
    "df['user_last_launch_dist_morethan_histmean'] = (df.user_last_launch_dist > df.user_mean_no_launch_days_hist).astype(int)\n",
    "df['user_last_launch_dist_morethan_histmedian'] = (df.user_last_launch_dist > df.user_median_no_launch_days_hist).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['user_lastweek_act_types_hist_rate'] = (df['user_lastweek_act_types'] / df['user_hist_act_types']).fillna(0)\n",
    "df['user_lastweek_video_activity_types_hist_rate'] = (df['user_lastweek_video_activity_types'] / df['user_hist_video_activity_types']).fillna(0)\n",
    "df['user_lastweek_page_types_hist_rate'] = (df['user_lastweek_page_types'] / df['user_hist_page_types']).fillna(0)\n",
    "df['user_lastweek_video_page_types_hist_rate'] = (df['user_lastweek_video_page_types'] / df['user_hist_video_page_types']).fillna(0)\n",
    "\n",
    "df['user_lastweek_act_types_hist_dist'] = df['user_lastweek_act_types'] - df['user_hist_act_types']\n",
    "df['user_lastweek_video_activity_types_hist_dist'] = df['user_lastweek_video_activity_types'] - df['user_hist_video_activity_types']\n",
    "df['user_lastweek_page_types_hist_dist'] = df['user_lastweek_page_types'] - df['user_hist_page_types']\n",
    "df['user_lastweek_video_page_types_hist_dist'] = df['user_lastweek_video_page_types'] - df['user_hist_video_page_types']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['user_activity_div_launch_days_hist'] = df['user_activity_days_hist'] / df['user_launch_days_hist']\n",
    "df['user_createvideo_div_launch_days_hist'] = df['user_createvideo_days_hist'] / df['user_launch_days_hist']\n",
    "df['user_activity_div_launch_days_lastweek'] = df['user_activity_days_lastweek'] / df['user_launch_days_lastweek']\n",
    "df['user_createvideo_div_launch_days_lastweek'] = df['user_createvideo_days_lastweek'] / df['user_launch_days_lastweek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_lastweek_hist_launch_freq_dist exist.\n",
      "user_lastweek_hist_video_freq_dist exist.\n"
     ]
    }
   ],
   "source": [
    "# 差距特征\n",
    "for col in df.columns:\n",
    "    if 'lastweek' in col and 'hist' not in col and 'dist' not in col:\n",
    "        if col.replace('lastweek','hist') in df.columns:\n",
    "            colname = col.replace('lastweek','lastweek_hist') + '_dist'\n",
    "            if colname not in df.columns:\n",
    "                df[colname] = df[col] - df[col.replace('lastweek','hist')]\n",
    "            else:\n",
    "                print(colname, 'exist.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['user_lastweek_launch_days_div_hist'] = df['user_launch_days_lastweek'] / df['user_launch_days_hist']\n",
    "df['user_lastweek_video_days_div_hist'] = df['user_createvideo_days_lastweek'] / df['user_createvideo_days_hist']\n",
    "df['user_lastweek_video_count_div_hist'] = df['user_createvideo_times_lastweek'] / df['user_createvideo_times_hist']\n",
    "df['user_lastweek_act_days_dic_hist'] = df['user_activity_days_lastweek'] / df['user_activity_times_hist']\n",
    "df['user_lastweek_act_count_div_hist'] = df['user_activity_times_lastweek'] / df['user_activity_times_hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['user_hist_mean_launch_date_dist']  = df.data_weekstart - df['user_mean_launch_date_hist']\n",
    "df['user_hist_min_launch_date_dist']   = df.data_weekstart - df['user_min_launch_date_hist']\n",
    "df['user_hist_mean_createvideo_date_dist']  = df.data_weekstart - df['user_mean_createvideo_date_hist']\n",
    "df['user_hist_min_createvideo_date_dist']   = df.data_weekstart - df['user_min_createvideo_date_hist']\n",
    "df['user_hist_mean_activity_date_dist']  = df.data_weekstart - df['user_mean_activity_date_hist']\n",
    "df['user_hist_min_activity_date_dist']   = df.data_weekstart - df['user_min_activity_date_hist']\n",
    "\n",
    "df['user_lastweek_mean_launch_date_dist']  = df.data_weekstart - df['user_mean_launch_date_lastweek']\n",
    "df['user_lastweek_min_launch_date_dist']   = df.data_weekstart - df['user_min_launch_date_lastweek']\n",
    "df['user_lastweek_mean_createvideo_date_dist']  = df.data_weekstart - df['user_mean_createvideo_date_lastweek']\n",
    "df['user_lastweek_min_createvideo_date_dist']   = df.data_weekstart - df['user_min_createvideo_date_lastweek']\n",
    "df['user_lastweek_mean_activity_date_dist']  = df.data_weekstart - df['user_mean_activity_date_lastweek']\n",
    "df['user_lastweek_min_activity_date_dist']   = df.data_weekstart - df['user_min_activity_date_lastweek']\n",
    "\n",
    "df['user_launch_range_percent'] = df['user_range_launch_date_hist'] / df['user_reg_days']\n",
    "df['user_activity_range_percent'] = df['user_range_activity_date_hist'] / df['user_reg_days']\n",
    "df['user_createvideo_range_percent'] = df['user_range_activity_date_hist'] / df['user_reg_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.fillna(-1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('../features/baseline_features9.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
