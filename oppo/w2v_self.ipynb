{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import pickle\n",
    "import time\n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#每次可以输出多个变量\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14, 6\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#中文字体\n",
    "import matplotlib\n",
    "matplotlib.use('qt4agg')\n",
    "#指定默认字体\n",
    "matplotlib.rcParams['font.sans-serif'] = ['SimHei']\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "#解决负号'-'显示为方块的问题\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vectors(path, topn):  # read top n word vectors, i.e. top is 10000\n",
    "    lines_num, dim = 0, 0\n",
    "    vectors = {}\n",
    "    iw = []\n",
    "    wi = {}\n",
    "    with open(path, encoding='utf-8', errors='ignore') as f:\n",
    "        first_line = True\n",
    "        for line in f:\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "                dim = int(line.rstrip().split()[1])\n",
    "                continue\n",
    "            lines_num += 1\n",
    "            tokens = line.rstrip().split(' ')\n",
    "            vectors[tokens[0]] = np.asarray([float(x) for x in tokens[1:]])\n",
    "            iw.append(tokens[0])\n",
    "            if topn != 0 and lines_num >= topn:\n",
    "                break\n",
    "    for i, w in enumerate(iw):\n",
    "        wi[w] = i\n",
    "    return vectors, iw, wi, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100000, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./feature/df_feature4_ctr_extra.csv', encoding='utf-8', usecols=['prefix', 'title', 'query_prediction'])\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df.title.apply(lambda x: urllib.parse.unquote(x))\n",
    "df['prefix'] = df.prefix.apply(lambda x: urllib.parse.unquote(x))\n",
    "df['query_prediction'] = df.query_prediction.apply(lambda x: urllib.parse.unquote(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = read_vectors('./data/new/merge_sgns_bigram_char300.txt', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlaw_word(x):\n",
    "    tmp_list = list(jieba.cut(x))\n",
    "    outlaw_word = []\n",
    "    outlaw_letter = []\n",
    "    for word in tmp_list:\n",
    "        if word not in w2v[0]:\n",
    "            outlaw_word.append(word)\n",
    "    return outlaw_word\n",
    "\n",
    "def get_outlaw_letter(x):\n",
    "    tmp_list = list(jieba.cut(x))\n",
    "    outlaw_letter = []\n",
    "    for word in tmp_list:\n",
    "        if word not in w2v[0]:\n",
    "            for letter in word:\n",
    "                if letter not in w2v[0]:\n",
    "                    outlaw_letter.append(letter)\n",
    "    return outlaw_letter\n",
    "\n",
    "def get_dict_outlaw_word(x):\n",
    "    dic = eval(x)\n",
    "    outlaw_word = []\n",
    "    for key in dic.keys():\n",
    "        tmp_list = list(jieba.cut(key))\n",
    "        for word in tmp_list:\n",
    "            if word not in w2v[0]:\n",
    "                outlaw_word.append(word)\n",
    "    return outlaw_word\n",
    "\n",
    "def get_dict_outlaw_letter(x):\n",
    "    dic = eval(x)\n",
    "    outlaw_letter = []\n",
    "    for key in dic.keys():\n",
    "        tmp_list = list(jieba.cut(key))\n",
    "        for word in tmp_list:\n",
    "            if word not in w2v[0]:\n",
    "                for letter in word:\n",
    "                    if letter not in w2v[0]:\n",
    "                        outlaw_letter.append(letter)\n",
    "    return outlaw_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['prefix_outlaw_word'] = df.prefix.apply(get_outlaw_word)\n",
    "df['prefix_outlaw_letter'] = df.prefix.apply(get_outlaw_letter)\n",
    "df['title_outlaw_word'] = df.title.apply(get_outlaw_word)\n",
    "df['title_outlaw_letter'] = df.title.apply(get_outlaw_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['dict_outlaw_word'] = df.query_prediction.apply(get_dict_outlaw_word)\n",
    "df['dict_outlaw_letter'] = df.query_prediction.apply(get_dict_outlaw_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "prefix_outlaw_letter_set = set(reduce(operator.add, df.prefix_outlaw_letter.tolist()))\n",
    "title_outlaw_letter_set = set(reduce(operator.add, df.title_outlaw_letter.tolist()))\n",
    "dict_outlaw_letter_set = set(reduce(operator.add, df.dict_outlaw_letter.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " 'م',\n",
       " 'ن',\n",
       " 'ە',\n",
       " '䗪',\n",
       " '叇',\n",
       " '嚊',\n",
       " '圐',\n",
       " '媣',\n",
       " '庎',\n",
       " '怣',\n",
       " '汖',\n",
       " '糄',\n",
       " '蘡',\n",
       " '蝜',\n",
       " '蝲',\n",
       " '髈',\n",
       " '녕',\n",
       " '랑',\n",
       " '사',\n",
       " '세',\n",
       " '안',\n",
       " '요',\n",
       " '청',\n",
       " '춘',\n",
       " '하',\n",
       " '해'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " 'ئ',\n",
       " 'د',\n",
       " 'ز',\n",
       " 'م',\n",
       " 'ن',\n",
       " 'ى',\n",
       " 'ي',\n",
       " 'ە',\n",
       " 'จ',\n",
       " 'ด',\n",
       " 'ต',\n",
       " 'ถ',\n",
       " 'น',\n",
       " 'บ',\n",
       " 'ฟ',\n",
       " 'ม',\n",
       " 'ร',\n",
       " 'ว',\n",
       " 'อ',\n",
       " 'ั',\n",
       " 'ี',\n",
       " 'ึ',\n",
       " 'ู',\n",
       " 'เ',\n",
       " 'แ',\n",
       " 'ไ',\n",
       " '่',\n",
       " '้',\n",
       " '\\u3000',\n",
       " '䃠',\n",
       " '䗪',\n",
       " '厼',\n",
       " '叇',\n",
       " '嚊',\n",
       " '圐',\n",
       " '媣',\n",
       " '嫤',\n",
       " '庎',\n",
       " '怣',\n",
       " '朤',\n",
       " '殸',\n",
       " '汖',\n",
       " '瞼',\n",
       " '矆',\n",
       " '硂',\n",
       " '糄',\n",
       " '腅',\n",
       " '蔩',\n",
       " '蘡',\n",
       " '虋',\n",
       " '蝜',\n",
       " '豼',\n",
       " '錵',\n",
       " '髈',\n",
       " '鯗',\n",
       " '가',\n",
       " '각',\n",
       " '같',\n",
       " '건',\n",
       " '게',\n",
       " '고',\n",
       " '구',\n",
       " '급',\n",
       " '기',\n",
       " '까',\n",
       " '난',\n",
       " '네',\n",
       " '녀',\n",
       " '녕',\n",
       " '노',\n",
       " '농',\n",
       " '누',\n",
       " '니',\n",
       " '다',\n",
       " '대',\n",
       " '도',\n",
       " '동',\n",
       " '떨',\n",
       " '똑',\n",
       " '라',\n",
       " '랑',\n",
       " '래',\n",
       " '럽',\n",
       " '레',\n",
       " '로',\n",
       " '리',\n",
       " '림',\n",
       " '링',\n",
       " '마',\n",
       " '먼',\n",
       " '몽',\n",
       " '무',\n",
       " '물',\n",
       " '방',\n",
       " '뱀',\n",
       " '번',\n",
       " '벨',\n",
       " '병',\n",
       " '부',\n",
       " '비',\n",
       " '빈',\n",
       " '빛',\n",
       " '빠',\n",
       " '뻐',\n",
       " '뿐',\n",
       " '사',\n",
       " '삶',\n",
       " '삼',\n",
       " '상',\n",
       " '새',\n",
       " '세',\n",
       " '션',\n",
       " '소',\n",
       " '솔',\n",
       " '수',\n",
       " '순',\n",
       " '스',\n",
       " '슬',\n",
       " '시',\n",
       " '식',\n",
       " '신',\n",
       " '실',\n",
       " '심',\n",
       " '쓰',\n",
       " '씨',\n",
       " '아',\n",
       " '안',\n",
       " '암',\n",
       " '애',\n",
       " '야',\n",
       " '어',\n",
       " '없',\n",
       " '여',\n",
       " '옆',\n",
       " '예',\n",
       " '오',\n",
       " '요',\n",
       " '우',\n",
       " '운',\n",
       " '웃',\n",
       " '워',\n",
       " '원',\n",
       " '음',\n",
       " '응',\n",
       " '인',\n",
       " '있',\n",
       " '자',\n",
       " '잔',\n",
       " '잠',\n",
       " '장',\n",
       " '재',\n",
       " '조',\n",
       " '족',\n",
       " '주',\n",
       " '줄',\n",
       " '진',\n",
       " '질',\n",
       " '집',\n",
       " '짜',\n",
       " '청',\n",
       " '춘',\n",
       " '치',\n",
       " '케',\n",
       " '콘',\n",
       " '텅',\n",
       " '투',\n",
       " '트',\n",
       " '틀',\n",
       " '팔',\n",
       " '퍼',\n",
       " '하',\n",
       " '해',\n",
       " '향',\n",
       " '화',\n",
       " '律'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " '\\x91',\n",
       " '\\x98',\n",
       " 'ب',\n",
       " 'د',\n",
       " 'ز',\n",
       " 'س',\n",
       " 'ش',\n",
       " 'ق',\n",
       " 'ك',\n",
       " 'ل',\n",
       " 'م',\n",
       " 'ن',\n",
       " 'ى',\n",
       " 'ي',\n",
       " 'چ',\n",
       " 'ۇ',\n",
       " 'ە',\n",
       " '㖭',\n",
       " '㗊',\n",
       " '㚞',\n",
       " '㠭',\n",
       " '㡌',\n",
       " '㬵',\n",
       " '㵘',\n",
       " '䂳',\n",
       " '䓍',\n",
       " '䗪',\n",
       " '䨻',\n",
       " '䲜',\n",
       " '僺',\n",
       " '冸',\n",
       " '勥',\n",
       " '叇',\n",
       " '呍',\n",
       " '嚊',\n",
       " '圐',\n",
       " '奾',\n",
       " '妦',\n",
       " '姀',\n",
       " '婛',\n",
       " '媈',\n",
       " '媣',\n",
       " '嫝',\n",
       " '嫤',\n",
       " '嫴',\n",
       " '峓',\n",
       " '庎',\n",
       " '忈',\n",
       " '怣',\n",
       " '惗',\n",
       " '昮',\n",
       " '朤',\n",
       " '杋',\n",
       " '柛',\n",
       " '桋',\n",
       " '梚',\n",
       " '樰',\n",
       " '殅',\n",
       " '汃',\n",
       " '汖',\n",
       " '渂',\n",
       " '灪',\n",
       " '炏',\n",
       " '燜',\n",
       " '犾',\n",
       " '珻',\n",
       " '琾',\n",
       " '瑵',\n",
       " '璾',\n",
       " '瓃',\n",
       " '硣',\n",
       " '稥',\n",
       " '筣',\n",
       " '箉',\n",
       " '糄',\n",
       " '罳',\n",
       " '藌',\n",
       " '蘡',\n",
       " '蛦',\n",
       " '蜅',\n",
       " '蝜',\n",
       " '蟁',\n",
       " '詺',\n",
       " '豼',\n",
       " '郣',\n",
       " '髈',\n",
       " '鲏',\n",
       " '鴛',\n",
       " '鴦',\n",
       " '齫',\n",
       " '국',\n",
       " '녕',\n",
       " '랑',\n",
       " '사',\n",
       " '세',\n",
       " '안',\n",
       " '어',\n",
       " '요',\n",
       " '전',\n",
       " '중',\n",
       " '하',\n",
       " '해',\n",
       " '🐠',\n",
       " '🔑'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_outlaw_letter_set\n",
    "title_outlaw_letter_set\n",
    "dict_outlaw_letter_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>query_prediction</th>\n",
       "      <th>title</th>\n",
       "      <th>prefix_outlaw_word</th>\n",
       "      <th>prefix_outlaw_letter</th>\n",
       "      <th>title_outlaw_word</th>\n",
       "      <th>title_outlaw_letter</th>\n",
       "      <th>dict_outlaw_word</th>\n",
       "      <th>dict_outlaw_letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>小品</td>\n",
       "      <td>{'小品大全': '0.198', '小品搞笑大全': '0.066', '小品演员': '...</td>\n",
       "      <td>小品</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1368</td>\n",
       "      <td>{'13685367892': '0.124', '1368年': '0.086', '13...</td>\n",
       "      <td>HCG大于1368,正常吗</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[13685367892, 就够, 13688cc, 13688478100, 13688c...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1368</td>\n",
       "      <td>{'13685367892': '0.124', '1368年': '0.086', '13...</td>\n",
       "      <td>1368年</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[13685367892, 就够, 13688cc, 13688478100, 13688c...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>银耳</td>\n",
       "      <td>{'银耳红枣汤': '0.114', '银耳汤的做法': '0.059', '银耳的功效':...</td>\n",
       "      <td>银耳红枣汤的做法</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>月经量少</td>\n",
       "      <td>{'月经量少是什么原因': '0.569', '月经量少怎么办': '0.040', '月经...</td>\n",
       "      <td>月经量少怎么调理</td>\n",
       "      <td>[量少]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[量少]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[量少, 量少, 量少, 量少, 量少, 量少, 量少, 量少, 量少, 量少]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prefix                                   query_prediction          title  \\\n",
       "0     小品  {'小品大全': '0.198', '小品搞笑大全': '0.066', '小品演员': '...             小品   \n",
       "1   1368  {'13685367892': '0.124', '1368年': '0.086', '13...  HCG大于1368,正常吗   \n",
       "2   1368  {'13685367892': '0.124', '1368年': '0.086', '13...          1368年   \n",
       "3     银耳  {'银耳红枣汤': '0.114', '银耳汤的做法': '0.059', '银耳的功效':...       银耳红枣汤的做法   \n",
       "4   月经量少  {'月经量少是什么原因': '0.569', '月经量少怎么办': '0.040', '月经...       月经量少怎么调理   \n",
       "\n",
       "  prefix_outlaw_word prefix_outlaw_letter title_outlaw_word  \\\n",
       "0                 []                   []                []   \n",
       "1                 []                   []                []   \n",
       "2                 []                   []                []   \n",
       "3                 []                   []                []   \n",
       "4               [量少]                   []              [量少]   \n",
       "\n",
       "  title_outlaw_letter                                   dict_outlaw_word  \\\n",
       "0                  []                                                 []   \n",
       "1                  []  [13685367892, 就够, 13688cc, 13688478100, 13688c...   \n",
       "2                  []  [13685367892, 就够, 13688cc, 13688478100, 13688c...   \n",
       "3                  []                                                 []   \n",
       "4                  []           [量少, 量少, 量少, 量少, 量少, 量少, 量少, 量少, 量少, 量少]   \n",
       "\n",
       "  dict_outlaw_letter  \n",
       "0                 []  \n",
       "1                 []  \n",
       "2                 []  \n",
       "3                 []  \n",
       "4                 []  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = KeyedVectors.load_word2vec_format('C:/Users/ZERO/KaggleWork/kaggle/w2v/Tencent_AILab_ChineseEmbedding.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v = read_vectors('C:/Users/ZERO/KaggleWork/kaggle/w2v/merge_sgns_bigram_char300.txt', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dictionary(path):\n",
    "    vectors = []\n",
    "    with open(path, encoding='utf-8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            word = line.split('\\t')[0]\n",
    "            if (word != 'UNK') & (word != 'PAD'):\n",
    "                vectors.append(word)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = read_dictionary('./model/rnn/rnn/output/dictionary/words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d65820ec0a3438596d0ba624645e276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./model/rnn/rnn/output/dictionary/dict_char300', 'w', encoding='utf-8') as f:\n",
    "    for i in tqdm_notebook(dictionary):\n",
    "        if i in w2v[0]:\n",
    "            vector = '\\t'.join(np.array(w2v[0][i]).astype(str))\n",
    "            _ = f.write('%s\\t%s\\n' % (i, vector))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
